{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"19RwHdiOO-yrUZIY28SruJ_lRIRr3BJ0q","authorship_tag":"ABX9TyOIQT3FTyuoGtsIobw0dGRR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AX8b-cpgqWxs","executionInfo":{"status":"ok","timestamp":1662971966177,"user_tz":-540,"elapsed":56558,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"db975d49-5ac2-4bb8-b195-bc2d0d297014"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pysurvival\n","  Downloading pysurvival-0.1.2.tar.gz (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pysurvival) (3.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pysurvival) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pysurvival) (1.3.5)\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from pysurvival) (21.1.3)\n","Collecting progressbar\n","  Downloading progressbar-2.5.tar.gz (10 kB)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from pysurvival) (6.0.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pysurvival) (1.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pysurvival) (1.7.3)\n","Collecting sklearn\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pysurvival) (1.12.1+cu113)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pysurvival) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pysurvival) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pysurvival) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pysurvival) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->pysurvival) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->pysurvival) (1.15.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pysurvival) (2022.2.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pysurvival) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pysurvival) (1.1.0)\n","Building wheels for collected packages: pysurvival, progressbar, sklearn\n","  Building wheel for pysurvival (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pysurvival: filename=pysurvival-0.1.2-cp37-cp37m-linux_x86_64.whl size=3773556 sha256=7558d49c9cddd954f4e302ef57c4223f19c983ccd4cccf2e3384b868d0b9b4ee\n","  Stored in directory: /root/.cache/pip/wheels/1a/63/e2/32273d765a4e2f4ccac69c8adf97425ca80bab5d0c8447f120\n","  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12082 sha256=a0fe0df380cbf1dad21ac097622dd7a4ec938e4ef7ca6574439fef15f7bbc0fe\n","  Stored in directory: /root/.cache/pip/wheels/f0/fd/1f/3e35ed57e94cd8ced38dd46771f1f0f94f65fec548659ed855\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=43b4a709e5e4bd99715430f03e28358a2ab3ec4767b774ba33ee392e7adb9d9e\n","  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","Successfully built pysurvival progressbar sklearn\n","Installing collected packages: sklearn, progressbar, pysurvival\n","Successfully installed progressbar-2.5 pysurvival-0.1.2 sklearn-0.0\n"]}],"source":["!pip install pysurvival"]},{"cell_type":"markdown","source":["# Original"],"metadata":{"id":"FtxRFUrfaGtT"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"Avf6k6o_aGtU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. train_data _73.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"KvKgwgTijQqr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"UPMLxiG-jXED"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"grw1fLekjYvd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"mkV5s1zAjah3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"C33MWVZBjbyj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"IHeNbeK1aGtW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"oTWWNBEpaGtW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"ewVTuudgqdWp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662079749948,"user_tz":-540,"elapsed":4471,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"e48d989f-4a89-441c-ac56-ec0b2ef6473f","id":"59kxBPgPaGtW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 16927.064 - ||grad||^2 = 31518.89120 - ||diff_w|| = 14.60947\n"," * Iteration #2 - Loss = 4326.144 - ||grad||^2 = 16030.91540 - ||diff_w|| = 6.54366\n"," * Iteration #3 - Loss = 1361.492 - ||grad||^2 = 9014.43907 - ||diff_w|| = 3.52660\n"," * Iteration #4 - Loss = 456.777 - ||grad||^2 = 4960.26516 - ||diff_w|| = 1.74736\n"," * Iteration #5 - Loss = 207.525 - ||grad||^2 = 2463.37939 - ||diff_w|| = 0.69887\n"," * Iteration #6 - Loss = 161.870 - ||grad||^2 = 1124.99541 - ||diff_w|| = 0.33177\n"," * Iteration #7 - Loss = 156.809 - ||grad||^2 = 433.23240 - ||diff_w|| = 0.14839\n"," * Iteration #8 - Loss = 157.050 - ||grad||^2 = 157.19909 - ||diff_w|| = 0.06335\n"," * Iteration #9 - Loss = 157.266 - ||grad||^2 = 66.16266 - ||diff_w|| = 0.02839\n"," * Iteration #10 - Loss = 157.348 - ||grad||^2 = 29.36968 - ||diff_w|| = 0.01352\n"," * Iteration #11 - Loss = 157.359 - ||grad||^2 = 13.69255 - ||diff_w|| = 0.00661\n"," * Iteration #12 - Loss = 157.366 - ||grad||^2 = 6.53497 - ||diff_w|| = 0.00331\n"," * Iteration #13 - Loss = 157.363 - ||grad||^2 = 3.03574 - ||diff_w|| = 0.00174\n"," * Iteration #14 - Loss = 157.362 - ||grad||^2 = 1.54727 - ||diff_w|| = 0.00089\n"," * Iteration #15 - Loss = 157.363 - ||grad||^2 = 0.81441 - ||diff_w|| = 0.00047\n"," * Iteration #16 - Loss = 157.362 - ||grad||^2 = 0.39869 - ||diff_w|| = 0.00025\n"," * Iteration #17 - Loss = 157.364 - ||grad||^2 = 0.18759 - ||diff_w|| = 0.00015\n"," * Iteration #18 - Loss = 157.363 - ||grad||^2 = 0.11849 - ||diff_w|| = 0.00008\n"," * Iteration #19 - Loss = 157.364 - ||grad||^2 = 0.08313 - ||diff_w|| = 0.00005\n"," * Iteration #20 - Loss = 157.363 - ||grad||^2 = 0.05315 - ||diff_w|| = 0.00003\n"," * Iteration #21 - Loss = 157.364 - ||grad||^2 = 0.05831 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 157.363 - ||grad||^2 = 0.04836 - ||diff_w|| = 0.00002\n"," * Iteration #23 - Loss = 157.365 - ||grad||^2 = 0.06730 - ||diff_w|| = 0.00002\n"," * Iteration #24 - Loss = 157.362 - ||grad||^2 = 0.07325 - ||diff_w|| = 0.00002\n"," * Iteration #25 - Loss = 157.364 - ||grad||^2 = 0.04351 - ||diff_w|| = 0.00002\n"," * Iteration #26 - Loss = 157.363 - ||grad||^2 = 0.03978 - ||diff_w|| = 0.00002\n"," * Iteration #27 - Loss = 157.364 - ||grad||^2 = 0.05022 - ||diff_w|| = 0.00002\n"," * Iteration #28 - Loss = 157.363 - ||grad||^2 = 0.05115 - ||diff_w|| = 0.00002\n"," * Iteration #29 - Loss = 157.364 - ||grad||^2 = 0.04036 - ||diff_w|| = 0.00002\n"," * Iteration #30 - Loss = 157.363 - ||grad||^2 = 0.04127 - ||diff_w|| = 0.00002\n"," * Iteration #31 - Loss = 157.364 - ||grad||^2 = 0.04742 - ||diff_w|| = 0.00002\n"," * Iteration #32 - Loss = 157.363 - ||grad||^2 = 0.04404 - ||diff_w|| = 0.00002\n"," * Iteration #33 - Loss = 157.364 - ||grad||^2 = 0.03790 - ||diff_w|| = 0.00002\n"," * Iteration #34 - Loss = 157.363 - ||grad||^2 = 0.04855 - ||diff_w|| = 0.00002\n"," * Iteration #35 - Loss = 157.364 - ||grad||^2 = 0.05105 - ||diff_w|| = 0.00002\n"," * Iteration #36 - Loss = 157.363 - ||grad||^2 = 0.05202 - ||diff_w|| = 0.00002\n"," * Iteration #37 - Loss = 157.364 - ||grad||^2 = 0.04901 - ||diff_w|| = 0.00002\n"," * Iteration #38 - Loss = 157.363 - ||grad||^2 = 0.05510 - ||diff_w|| = 0.00002\n"," * Iteration #39 - Loss = 157.364 - ||grad||^2 = 0.05249 - ||diff_w|| = 0.00002\n"," * Iteration #40 - Loss = 157.363 - ||grad||^2 = 0.05718 - ||diff_w|| = 0.00002\n"," * Iteration #41 - Loss = 157.365 - ||grad||^2 = 0.07346 - ||diff_w|| = 0.00002\n"," * Iteration #42 - Loss = 157.362 - ||grad||^2 = 0.07881 - ||diff_w|| = 0.00002\n"," * Iteration #43 - Loss = 157.365 - ||grad||^2 = 0.07575 - ||diff_w|| = 0.00002\n"," * Iteration #44 - Loss = 157.362 - ||grad||^2 = 0.07152 - ||diff_w|| = 0.00002\n"," * Iteration #45 - Loss = 157.364 - ||grad||^2 = 0.05299 - ||diff_w|| = 0.00002\n"," * Iteration #46 - Loss = 157.363 - ||grad||^2 = 0.05532 - ||diff_w|| = 0.00002\n"," * Iteration #47 - Loss = 157.364 - ||grad||^2 = 0.04986 - ||diff_w|| = 0.00002\n"," * Iteration #48 - Loss = 157.363 - ||grad||^2 = 0.04663 - ||diff_w|| = 0.00002\n"," * Iteration #49 - Loss = 157.364 - ||grad||^2 = 0.03678 - ||diff_w|| = 0.00003\n"," * Iteration #50 - Loss = 157.364 - ||grad||^2 = 0.03434 - ||diff_w|| = 0.00002\n"," * Iteration #51 - Loss = 157.364 - ||grad||^2 = 0.03653 - ||diff_w|| = 0.00002\n"," * Iteration #52 - Loss = 157.363 - ||grad||^2 = 0.04152 - ||diff_w|| = 0.00002\n"," * Iteration #53 - Loss = 157.364 - ||grad||^2 = 0.04691 - ||diff_w|| = 0.00002\n"," * Iteration #54 - Loss = 157.363 - ||grad||^2 = 0.04456 - ||diff_w|| = 0.00002\n"," * Iteration #55 - Loss = 157.364 - ||grad||^2 = 0.03761 - ||diff_w|| = 0.00002\n"," * Iteration #56 - Loss = 157.363 - ||grad||^2 = 0.04856 - ||diff_w|| = 0.00002\n"," * Iteration #57 - Loss = 157.364 - ||grad||^2 = 0.05104 - ||diff_w|| = 0.00002\n"," * Iteration #58 - Loss = 157.363 - ||grad||^2 = 0.05204 - ||diff_w|| = 0.00002\n"," * Iteration #59 - Loss = 157.364 - ||grad||^2 = 0.04899 - ||diff_w|| = 0.00002\n"," * Iteration #60 - Loss = 157.363 - ||grad||^2 = 0.05511 - ||diff_w|| = 0.00002\n"," * Iteration #61 - Loss = 157.364 - ||grad||^2 = 0.05249 - ||diff_w|| = 0.00002\n"," * Iteration #62 - Loss = 157.363 - ||grad||^2 = 0.05718 - ||diff_w|| = 0.00002\n"," * Iteration #63 - Loss = 157.365 - ||grad||^2 = 0.07346 - ||diff_w|| = 0.00002\n"," * Iteration #64 - Loss = 157.362 - ||grad||^2 = 0.07882 - ||diff_w|| = 0.00002\n"," * Iteration #65 - Loss = 157.365 - ||grad||^2 = 0.07575 - ||diff_w|| = 0.00002\n"," * Iteration #66 - Loss = 157.362 - ||grad||^2 = 0.07152 - ||diff_w|| = 0.00002\n"," * Iteration #67 - Loss = 157.364 - ||grad||^2 = 0.05299 - ||diff_w|| = 0.00002\n"," * Iteration #68 - Loss = 157.363 - ||grad||^2 = 0.05532 - ||diff_w|| = 0.00002\n"," * Iteration #69 - Loss = 157.364 - ||grad||^2 = 0.04986 - ||diff_w|| = 0.00002\n"," * Iteration #70 - Loss = 157.363 - ||grad||^2 = 0.04663 - ||diff_w|| = 0.00002\n"," * Iteration #71 - Loss = 157.364 - ||grad||^2 = 0.03678 - ||diff_w|| = 0.00003\n"," * Iteration #72 - Loss = 157.364 - ||grad||^2 = 0.03434 - ||diff_w|| = 0.00002\n"," * Iteration #73 - Loss = 157.364 - ||grad||^2 = 0.03653 - ||diff_w|| = 0.00002\n"," * Iteration #74 - Loss = 157.363 - ||grad||^2 = 0.04152 - ||diff_w|| = 0.00002\n"," * Iteration #75 - Loss = 157.364 - ||grad||^2 = 0.04691 - ||diff_w|| = 0.00002\n"," * Iteration #76 - Loss = 157.363 - ||grad||^2 = 0.04456 - ||diff_w|| = 0.00002\n"," * Iteration #77 - Loss = 157.364 - ||grad||^2 = 0.03761 - ||diff_w|| = 0.00002\n"," * Iteration #78 - Loss = 157.363 - ||grad||^2 = 0.04856 - ||diff_w|| = 0.00002\n"," * Iteration #79 - Loss = 157.364 - ||grad||^2 = 0.05104 - ||diff_w|| = 0.00002\n"," * Iteration #80 - Loss = 157.363 - ||grad||^2 = 0.05204 - ||diff_w|| = 0.00002\n"," * Iteration #81 - Loss = 157.364 - ||grad||^2 = 0.04899 - ||diff_w|| = 0.00002\n"," * Iteration #82 - Loss = 157.363 - ||grad||^2 = 0.05511 - ||diff_w|| = 0.00002\n"," * Iteration #83 - Loss = 157.364 - ||grad||^2 = 0.05249 - ||diff_w|| = 0.00002\n"," * Iteration #84 - Loss = 157.363 - ||grad||^2 = 0.05718 - ||diff_w|| = 0.00002\n"," * Iteration #85 - Loss = 157.365 - ||grad||^2 = 0.07346 - ||diff_w|| = 0.00002\n"," * Iteration #86 - Loss = 157.362 - ||grad||^2 = 0.07882 - ||diff_w|| = 0.00002\n"," * Iteration #87 - Loss = 157.365 - ||grad||^2 = 0.07575 - ||diff_w|| = 0.00002\n"," * Iteration #88 - Loss = 157.362 - ||grad||^2 = 0.07152 - ||diff_w|| = 0.00002\n"," * Iteration #89 - Loss = 157.364 - ||grad||^2 = 0.05299 - ||diff_w|| = 0.00002\n"," * Iteration #90 - Loss = 157.363 - ||grad||^2 = 0.05532 - ||diff_w|| = 0.00002\n"," * Iteration #91 - Loss = 157.364 - ||grad||^2 = 0.04986 - ||diff_w|| = 0.00002\n"," * Iteration #92 - Loss = 157.363 - ||grad||^2 = 0.04663 - ||diff_w|| = 0.00002\n"," * Iteration #93 - Loss = 157.364 - ||grad||^2 = 0.03678 - ||diff_w|| = 0.00003\n"," * Iteration #94 - Loss = 157.364 - ||grad||^2 = 0.03434 - ||diff_w|| = 0.00002\n"," * Iteration #95 - Loss = 157.364 - ||grad||^2 = 0.03653 - ||diff_w|| = 0.00002\n"," * Iteration #96 - Loss = 157.363 - ||grad||^2 = 0.04152 - ||diff_w|| = 0.00002\n"," * Iteration #97 - Loss = 157.364 - ||grad||^2 = 0.04691 - ||diff_w|| = 0.00002\n"," * Iteration #98 - Loss = 157.363 - ||grad||^2 = 0.04456 - ||diff_w|| = 0.00002\n"," * Iteration #99 - Loss = 157.364 - ||grad||^2 = 0.03761 - ||diff_w|| = 0.00002\n"," * Iteration #100 - Loss = 157.363 - ||grad||^2 = 0.04856 - ||diff_w|| = 0.00002\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662079749949,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"88315983-b50d-42ce-9366-174f641d8215","id":"gobOyJBqaGtW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.836011\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"doqYBIZjaGtW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_original3.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662079751502,"user_tz":-540,"elapsed":1560,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"14ab0012-b4ba-44c3-854c-10dcbacdd7d3","id":"XrHJIJ7LaGtW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_original3.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-imbal-5000"],"metadata":{"id":"uh2-aZhcoqqm"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"jxqVREUMoqqm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-AR12/TGAN-syn-AR-one-of-all-5000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"XSFzMk9Doqqn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"vxFkVpMCoqqn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"T4zO2j5toqqn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"MW4rplanoqqn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"O67PFy0-oqqn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"QGBxKOc6oqqo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"WFvAHNoqoqqo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"fW2PVZM8q0YR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662080144853,"user_tz":-540,"elapsed":25319,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"a9f80869-e0d2-4636-f7a6-22fcf577194b","id":"4Mog8ctCoqqo"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 366513.137 - ||grad||^2 = 623268.55014 - ||diff_w|| = 16.81042\n"," * Iteration #2 - Loss = 92486.779 - ||grad||^2 = 315674.26546 - ||diff_w|| = 7.45467\n"," * Iteration #3 - Loss = 28304.694 - ||grad||^2 = 176614.77139 - ||diff_w|| = 4.04414\n"," * Iteration #4 - Loss = 8737.405 - ||grad||^2 = 98273.42776 - ||diff_w|| = 2.12753\n"," * Iteration #5 - Loss = 3014.306 - ||grad||^2 = 52666.79000 - ||diff_w|| = 1.00965\n"," * Iteration #6 - Loss = 1563.634 - ||grad||^2 = 27000.76318 - ||diff_w|| = 0.51704\n"," * Iteration #7 - Loss = 1345.118 - ||grad||^2 = 10080.58384 - ||diff_w|| = 0.27145\n"," * Iteration #8 - Loss = 1389.702 - ||grad||^2 = 2090.70360 - ||diff_w|| = 0.11440\n"," * Iteration #9 - Loss = 1394.102 - ||grad||^2 = 496.17070 - ||diff_w|| = 0.04188\n"," * Iteration #10 - Loss = 1394.035 - ||grad||^2 = 139.37463 - ||diff_w|| = 0.01671\n"," * Iteration #11 - Loss = 1394.124 - ||grad||^2 = 41.99066 - ||diff_w|| = 0.00727\n"," * Iteration #12 - Loss = 1394.135 - ||grad||^2 = 13.45534 - ||diff_w|| = 0.00345\n"," * Iteration #13 - Loss = 1394.143 - ||grad||^2 = 4.74004 - ||diff_w|| = 0.00174\n"," * Iteration #14 - Loss = 1394.147 - ||grad||^2 = 1.80240 - ||diff_w|| = 0.00091\n"," * Iteration #15 - Loss = 1394.145 - ||grad||^2 = 0.73674 - ||diff_w|| = 0.00049\n"," * Iteration #16 - Loss = 1394.150 - ||grad||^2 = 0.35161 - ||diff_w|| = 0.00026\n"," * Iteration #17 - Loss = 1394.149 - ||grad||^2 = 0.16059 - ||diff_w|| = 0.00015\n"," * Iteration #18 - Loss = 1394.148 - ||grad||^2 = 0.08871 - ||diff_w|| = 0.00008\n"," * Iteration #19 - Loss = 1394.149 - ||grad||^2 = 0.05787 - ||diff_w|| = 0.00005\n"," * Iteration #20 - Loss = 1394.148 - ||grad||^2 = 0.06338 - ||diff_w|| = 0.00003\n"," * Iteration #21 - Loss = 1394.150 - ||grad||^2 = 0.07079 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 1394.147 - ||grad||^2 = 0.07515 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 1394.150 - ||grad||^2 = 0.06729 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 1394.148 - ||grad||^2 = 0.06670 - ||diff_w|| = 0.00001\n"," * Iteration #25 - Loss = 1394.150 - ||grad||^2 = 0.07056 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 1394.148 - ||grad||^2 = 0.06300 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 1394.149 - ||grad||^2 = 0.06073 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 1394.148 - ||grad||^2 = 0.06563 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 1394.149 - ||grad||^2 = 0.07730 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 1394.148 - ||grad||^2 = 0.07341 - ||diff_w|| = 0.00001\n"," * Iteration #31 - Loss = 1394.149 - ||grad||^2 = 0.06384 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 1394.148 - ||grad||^2 = 0.06772 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 1394.150 - ||grad||^2 = 0.07453 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 1394.148 - ||grad||^2 = 0.07741 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 1394.150 - ||grad||^2 = 0.07424 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 1394.148 - ||grad||^2 = 0.07485 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 1394.150 - ||grad||^2 = 0.07183 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 1394.148 - ||grad||^2 = 0.05900 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 1394.149 - ||grad||^2 = 0.05784 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 1394.148 - ||grad||^2 = 0.07672 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 1394.149 - ||grad||^2 = 0.07848 - ||diff_w|| = 0.00001\n"," * Iteration #42 - Loss = 1394.148 - ||grad||^2 = 0.07225 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 1394.149 - ||grad||^2 = 0.06492 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 1394.148 - ||grad||^2 = 0.06755 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 1394.150 - ||grad||^2 = 0.07471 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 1394.148 - ||grad||^2 = 0.07723 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 1394.150 - ||grad||^2 = 0.07429 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 1394.148 - ||grad||^2 = 0.07481 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 1394.150 - ||grad||^2 = 0.07185 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 1394.148 - ||grad||^2 = 0.05900 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 1394.149 - ||grad||^2 = 0.05784 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 1394.148 - ||grad||^2 = 0.07671 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 1394.149 - ||grad||^2 = 0.07848 - ||diff_w|| = 0.00001\n"," * Iteration #54 - Loss = 1394.148 - ||grad||^2 = 0.07225 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 1394.149 - ||grad||^2 = 0.06492 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 1394.148 - ||grad||^2 = 0.06755 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 1394.150 - ||grad||^2 = 0.07471 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 1394.148 - ||grad||^2 = 0.07723 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 1394.150 - ||grad||^2 = 0.07429 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 1394.148 - ||grad||^2 = 0.07481 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 1394.150 - ||grad||^2 = 0.07185 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 1394.148 - ||grad||^2 = 0.05900 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 1394.149 - ||grad||^2 = 0.05784 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 1394.148 - ||grad||^2 = 0.07671 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 1394.149 - ||grad||^2 = 0.07848 - ||diff_w|| = 0.00001\n"," * Iteration #66 - Loss = 1394.148 - ||grad||^2 = 0.07225 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 1394.149 - ||grad||^2 = 0.06492 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 1394.148 - ||grad||^2 = 0.06755 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 1394.150 - ||grad||^2 = 0.07471 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 1394.148 - ||grad||^2 = 0.07723 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 1394.150 - ||grad||^2 = 0.07429 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 1394.148 - ||grad||^2 = 0.07481 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 1394.150 - ||grad||^2 = 0.07185 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 1394.148 - ||grad||^2 = 0.05900 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 1394.149 - ||grad||^2 = 0.05784 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 1394.148 - ||grad||^2 = 0.07671 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 1394.149 - ||grad||^2 = 0.07848 - ||diff_w|| = 0.00001\n"," * Iteration #78 - Loss = 1394.148 - ||grad||^2 = 0.07225 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 1394.149 - ||grad||^2 = 0.06492 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 1394.148 - ||grad||^2 = 0.06755 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 1394.150 - ||grad||^2 = 0.07471 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 1394.148 - ||grad||^2 = 0.07723 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 1394.150 - ||grad||^2 = 0.07429 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 1394.148 - ||grad||^2 = 0.07481 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 1394.150 - ||grad||^2 = 0.07185 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 1394.148 - ||grad||^2 = 0.05900 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 1394.149 - ||grad||^2 = 0.05784 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 1394.148 - ||grad||^2 = 0.07671 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 1394.149 - ||grad||^2 = 0.07848 - ||diff_w|| = 0.00001\n"," * Iteration #90 - Loss = 1394.148 - ||grad||^2 = 0.07225 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 1394.149 - ||grad||^2 = 0.06492 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 1394.148 - ||grad||^2 = 0.06755 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 1394.150 - ||grad||^2 = 0.07471 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 1394.148 - ||grad||^2 = 0.07723 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 1394.150 - ||grad||^2 = 0.07429 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 1394.148 - ||grad||^2 = 0.07481 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 1394.150 - ||grad||^2 = 0.07185 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 1394.148 - ||grad||^2 = 0.05900 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 1394.149 - ||grad||^2 = 0.05784 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 1394.148 - ||grad||^2 = 0.07671 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662080144854,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"ee8745dd-5160-4a98-e98f-b0d682830e10","id":"RO3DAu54oqqo"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.807182\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"X8pjI9dVoqqo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-5000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662080144854,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"8d82850b-cb3a-4a6a-bb54-984c9c27c547","id":"S2wsDEOtoqqo"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-5000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-imbal-10000"],"metadata":{"id":"gsQdRqDXx3nR"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"0ooaLzD9x3nc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-AR12/TGAN-syn-AR-one-of-all-10000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"7F0DCJP-x3nc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"NcA_lbL4x3nc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"6TSkQsepx3nc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"KiiC-A53x3nc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"-CcA6-khx3nc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"kmh4s-sox3nc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"pZPBNX0-x3nd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"iz7lb3rox3nd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662098695793,"user_tz":-540,"elapsed":87148,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"38edc504-1b20-456e-d20e-843765203005","id":"753bq_i8x3nd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 1037443.631 - ||grad||^2 = 1894568.07784 - ||diff_w|| = 16.48260\n"," * Iteration #2 - Loss = 262585.193 - ||grad||^2 = 959637.03330 - ||diff_w|| = 7.40218\n"," * Iteration #3 - Loss = 81146.646 - ||grad||^2 = 537044.80585 - ||diff_w|| = 4.03514\n"," * Iteration #4 - Loss = 26004.088 - ||grad||^2 = 297232.11536 - ||diff_w|| = 2.11561\n"," * Iteration #5 - Loss = 10048.978 - ||grad||^2 = 145638.78966 - ||diff_w|| = 0.96455\n"," * Iteration #6 - Loss = 6717.297 - ||grad||^2 = 64831.75050 - ||diff_w|| = 0.44760\n"," * Iteration #7 - Loss = 6391.183 - ||grad||^2 = 24195.43702 - ||diff_w|| = 0.20642\n"," * Iteration #8 - Loss = 6432.148 - ||grad||^2 = 7903.89709 - ||diff_w|| = 0.08304\n"," * Iteration #9 - Loss = 6440.281 - ||grad||^2 = 2632.38014 - ||diff_w|| = 0.03669\n"," * Iteration #10 - Loss = 6441.143 - ||grad||^2 = 966.69576 - ||diff_w|| = 0.01805\n"," * Iteration #11 - Loss = 6441.345 - ||grad||^2 = 385.67540 - ||diff_w|| = 0.00930\n"," * Iteration #12 - Loss = 6441.386 - ||grad||^2 = 164.52010 - ||diff_w|| = 0.00494\n"," * Iteration #13 - Loss = 6441.402 - ||grad||^2 = 74.61556 - ||diff_w|| = 0.00265\n"," * Iteration #14 - Loss = 6441.395 - ||grad||^2 = 34.91554 - ||diff_w|| = 0.00142\n"," * Iteration #15 - Loss = 6441.397 - ||grad||^2 = 16.92474 - ||diff_w|| = 0.00077\n"," * Iteration #16 - Loss = 6441.396 - ||grad||^2 = 8.35985 - ||diff_w|| = 0.00041\n"," * Iteration #17 - Loss = 6441.398 - ||grad||^2 = 4.10798 - ||diff_w|| = 0.00022\n"," * Iteration #18 - Loss = 6441.398 - ||grad||^2 = 2.09250 - ||diff_w|| = 0.00012\n"," * Iteration #19 - Loss = 6441.395 - ||grad||^2 = 1.02873 - ||diff_w|| = 0.00007\n"," * Iteration #20 - Loss = 6441.397 - ||grad||^2 = 0.54053 - ||diff_w|| = 0.00004\n"," * Iteration #21 - Loss = 6441.395 - ||grad||^2 = 0.29473 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 6441.397 - ||grad||^2 = 0.17580 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 6441.395 - ||grad||^2 = 0.10108 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 6441.397 - ||grad||^2 = 0.09901 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 6441.395 - ||grad||^2 = 0.09078 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 6441.397 - ||grad||^2 = 0.06827 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 6441.395 - ||grad||^2 = 0.07005 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 6441.397 - ||grad||^2 = 0.07291 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 6441.394 - ||grad||^2 = 0.07982 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 6441.398 - ||grad||^2 = 0.09189 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 6441.393 - ||grad||^2 = 0.11403 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 6441.398 - ||grad||^2 = 0.10501 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 6441.394 - ||grad||^2 = 0.09457 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 6441.397 - ||grad||^2 = 0.08702 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 6441.394 - ||grad||^2 = 0.10244 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 6441.398 - ||grad||^2 = 0.09091 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 6441.394 - ||grad||^2 = 0.08899 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 6441.397 - ||grad||^2 = 0.07852 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 6441.395 - ||grad||^2 = 0.07034 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 6441.397 - ||grad||^2 = 0.07673 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 6441.395 - ||grad||^2 = 0.08668 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 6441.397 - ||grad||^2 = 0.07750 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 6441.394 - ||grad||^2 = 0.10357 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 6441.398 - ||grad||^2 = 0.09390 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 6441.394 - ||grad||^2 = 0.08317 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 6441.397 - ||grad||^2 = 0.08795 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 6441.394 - ||grad||^2 = 0.08394 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 6441.397 - ||grad||^2 = 0.06692 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 6441.394 - ||grad||^2 = 0.08750 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 6441.398 - ||grad||^2 = 0.09075 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 6441.394 - ||grad||^2 = 0.08800 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 6441.398 - ||grad||^2 = 0.09813 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 6441.393 - ||grad||^2 = 0.12722 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 6441.398 - ||grad||^2 = 0.10386 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 6441.395 - ||grad||^2 = 0.08364 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 6441.397 - ||grad||^2 = 0.06535 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 6441.395 - ||grad||^2 = 0.04416 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 6441.396 - ||grad||^2 = 0.05473 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 6441.395 - ||grad||^2 = 0.06799 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 6441.398 - ||grad||^2 = 0.08930 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 6441.394 - ||grad||^2 = 0.10637 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 6441.397 - ||grad||^2 = 0.08333 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 6441.395 - ||grad||^2 = 0.08090 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 6441.397 - ||grad||^2 = 0.08358 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 6441.394 - ||grad||^2 = 0.11121 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 6441.398 - ||grad||^2 = 0.09870 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 6441.395 - ||grad||^2 = 0.09248 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 6441.397 - ||grad||^2 = 0.07501 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 6441.394 - ||grad||^2 = 0.08051 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 6441.397 - ||grad||^2 = 0.07424 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 6441.395 - ||grad||^2 = 0.05758 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 6441.397 - ||grad||^2 = 0.06139 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 6441.394 - ||grad||^2 = 0.09136 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 6441.397 - ||grad||^2 = 0.08206 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 6441.394 - ||grad||^2 = 0.09356 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 6441.397 - ||grad||^2 = 0.08108 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 6441.395 - ||grad||^2 = 0.06618 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 6441.397 - ||grad||^2 = 0.06616 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 6441.395 - ||grad||^2 = 0.07876 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 6441.397 - ||grad||^2 = 0.07958 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 6441.394 - ||grad||^2 = 0.08408 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 6441.397 - ||grad||^2 = 0.08074 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 6441.395 - ||grad||^2 = 0.06669 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 6441.397 - ||grad||^2 = 0.05834 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 6441.394 - ||grad||^2 = 0.07967 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 6441.397 - ||grad||^2 = 0.08077 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 6441.394 - ||grad||^2 = 0.07956 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 6441.397 - ||grad||^2 = 0.07427 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 6441.395 - ||grad||^2 = 0.07502 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 6441.397 - ||grad||^2 = 0.06574 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 6441.394 - ||grad||^2 = 0.09772 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 6441.398 - ||grad||^2 = 0.09848 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 6441.395 - ||grad||^2 = 0.08556 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 6441.397 - ||grad||^2 = 0.07061 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 6441.394 - ||grad||^2 = 0.08685 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 6441.398 - ||grad||^2 = 0.09665 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 6441.393 - ||grad||^2 = 0.11340 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 6441.398 - ||grad||^2 = 0.10190 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 6441.394 - ||grad||^2 = 0.08327 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 6441.397 - ||grad||^2 = 0.07432 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662098695794,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"4a14b014-3fcc-44cc-f5a0-efb708270839","id":"HQXMKnx_x3nd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.811919\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"OIC5xZPRx3nd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-10000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662098695794,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"c39cfc67-8219-49dd-da99-bad86b545136","id":"I-12akjqx3nd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-10000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-imbal-15000"],"metadata":{"id":"H-8auXslx66t"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"rB2IW9Bdx66t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-AR12/TGAN-syn-AR-one-of-all-15000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"XfuaPOA8x66u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"NUURWyWlx66u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"Q_OBfeHDx66u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"sG_CYLSyx66u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"ZYO4EN9nx66u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"cLV3PmtWx66u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"hMtt9B5hx66u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"vbOrM8Txx66u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662099002218,"user_tz":-540,"elapsed":181483,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"e46feb27-afca-47f9-93ab-74379d262927","id":"krGxJcggx66u"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 1112898.504 - ||grad||^2 = 1986264.42485 - ||diff_w|| = 16.46498\n"," * Iteration #2 - Loss = 302121.709 - ||grad||^2 = 1104407.62039 - ||diff_w|| = 6.63047\n"," * Iteration #3 - Loss = 94067.029 - ||grad||^2 = 614327.88572 - ||diff_w|| = 3.49475\n"," * Iteration #4 - Loss = 31809.090 - ||grad||^2 = 327158.62201 - ||diff_w|| = 1.64843\n"," * Iteration #5 - Loss = 15795.949 - ||grad||^2 = 159935.18984 - ||diff_w|| = 0.70927\n"," * Iteration #6 - Loss = 13298.749 - ||grad||^2 = 60992.35396 - ||diff_w|| = 0.31108\n"," * Iteration #7 - Loss = 13191.179 - ||grad||^2 = 19175.52951 - ||diff_w|| = 0.11864\n"," * Iteration #8 - Loss = 13150.443 - ||grad||^2 = 6576.44014 - ||diff_w|| = 0.04399\n"," * Iteration #9 - Loss = 13156.766 - ||grad||^2 = 1969.51740 - ||diff_w|| = 0.01436\n"," * Iteration #10 - Loss = 13157.906 - ||grad||^2 = 567.14488 - ||diff_w|| = 0.00491\n"," * Iteration #11 - Loss = 13158.285 - ||grad||^2 = 187.02534 - ||diff_w|| = 0.00215\n"," * Iteration #12 - Loss = 13158.268 - ||grad||^2 = 66.58170 - ||diff_w|| = 0.00102\n"," * Iteration #13 - Loss = 13158.265 - ||grad||^2 = 25.13061 - ||diff_w|| = 0.00051\n"," * Iteration #14 - Loss = 13158.283 - ||grad||^2 = 9.91616 - ||diff_w|| = 0.00027\n"," * Iteration #15 - Loss = 13158.280 - ||grad||^2 = 3.97741 - ||diff_w|| = 0.00014\n"," * Iteration #16 - Loss = 13158.284 - ||grad||^2 = 1.82043 - ||diff_w|| = 0.00008\n"," * Iteration #17 - Loss = 13158.285 - ||grad||^2 = 0.83429 - ||diff_w|| = 0.00004\n"," * Iteration #18 - Loss = 13158.285 - ||grad||^2 = 0.37834 - ||diff_w|| = 0.00002\n"," * Iteration #19 - Loss = 13158.282 - ||grad||^2 = 0.20077 - ||diff_w|| = 0.00001\n"," * Iteration #20 - Loss = 13158.285 - ||grad||^2 = 0.11660 - ||diff_w|| = 0.00001\n"," * Iteration #21 - Loss = 13158.282 - ||grad||^2 = 0.09293 - ||diff_w|| = 0.00000\n"," * Iteration #22 - Loss = 13158.285 - ||grad||^2 = 0.07341 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 13158.282 - ||grad||^2 = 0.07836 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 13158.285 - ||grad||^2 = 0.09199 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 13158.282 - ||grad||^2 = 0.10084 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 13158.286 - ||grad||^2 = 0.11907 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 13158.282 - ||grad||^2 = 0.11453 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 13158.286 - ||grad||^2 = 0.12347 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 13158.282 - ||grad||^2 = 0.12879 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 13158.286 - ||grad||^2 = 0.12667 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 13158.282 - ||grad||^2 = 0.11832 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 13158.286 - ||grad||^2 = 0.12426 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 13158.282 - ||grad||^2 = 0.11468 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 13158.286 - ||grad||^2 = 0.09711 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 13158.282 - ||grad||^2 = 0.10307 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 13158.285 - ||grad||^2 = 0.08899 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 13158.282 - ||grad||^2 = 0.08770 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 13158.286 - ||grad||^2 = 0.10517 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 13158.282 - ||grad||^2 = 0.11832 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 13158.286 - ||grad||^2 = 0.12629 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 13158.282 - ||grad||^2 = 0.11988 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 13158.286 - ||grad||^2 = 0.12240 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 13158.282 - ||grad||^2 = 0.12995 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 13158.286 - ||grad||^2 = 0.11695 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 13158.282 - ||grad||^2 = 0.09794 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 13158.285 - ||grad||^2 = 0.07384 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 13158.283 - ||grad||^2 = 0.09046 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 13158.285 - ||grad||^2 = 0.09568 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 13158.283 - ||grad||^2 = 0.09248 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 13158.285 - ||grad||^2 = 0.08430 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 13158.283 - ||grad||^2 = 0.07029 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 13158.285 - ||grad||^2 = 0.07730 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 13158.283 - ||grad||^2 = 0.10189 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 13158.286 - ||grad||^2 = 0.12434 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 13158.282 - ||grad||^2 = 0.11773 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 13158.286 - ||grad||^2 = 0.12343 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 13158.282 - ||grad||^2 = 0.12928 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 13158.286 - ||grad||^2 = 0.12899 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 13158.282 - ||grad||^2 = 0.11381 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 13158.285 - ||grad||^2 = 0.09680 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 13158.283 - ||grad||^2 = 0.09883 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 13158.285 - ||grad||^2 = 0.10580 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 13158.282 - ||grad||^2 = 0.10579 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 13158.286 - ||grad||^2 = 0.09654 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 13158.282 - ||grad||^2 = 0.11468 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 13158.286 - ||grad||^2 = 0.12852 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 13158.282 - ||grad||^2 = 0.11865 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 13158.286 - ||grad||^2 = 0.12306 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 13158.282 - ||grad||^2 = 0.12968 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 13158.286 - ||grad||^2 = 0.11711 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 13158.282 - ||grad||^2 = 0.09784 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 13158.285 - ||grad||^2 = 0.07390 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 13158.283 - ||grad||^2 = 0.09044 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 13158.285 - ||grad||^2 = 0.09570 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 13158.283 - ||grad||^2 = 0.09247 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 13158.285 - ||grad||^2 = 0.08431 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 13158.283 - ||grad||^2 = 0.07029 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 13158.285 - ||grad||^2 = 0.07730 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 13158.283 - ||grad||^2 = 0.10189 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 13158.286 - ||grad||^2 = 0.12434 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 13158.282 - ||grad||^2 = 0.11773 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 13158.286 - ||grad||^2 = 0.12343 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 13158.282 - ||grad||^2 = 0.12928 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 13158.286 - ||grad||^2 = 0.12899 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 13158.282 - ||grad||^2 = 0.11381 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 13158.285 - ||grad||^2 = 0.09680 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 13158.283 - ||grad||^2 = 0.09883 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 13158.285 - ||grad||^2 = 0.10580 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 13158.282 - ||grad||^2 = 0.10579 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 13158.286 - ||grad||^2 = 0.09654 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 13158.282 - ||grad||^2 = 0.11468 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 13158.286 - ||grad||^2 = 0.12852 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 13158.282 - ||grad||^2 = 0.11865 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 13158.286 - ||grad||^2 = 0.12306 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 13158.282 - ||grad||^2 = 0.12968 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 13158.286 - ||grad||^2 = 0.11711 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 13158.282 - ||grad||^2 = 0.09784 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 13158.285 - ||grad||^2 = 0.07390 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 13158.283 - ||grad||^2 = 0.09044 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 13158.285 - ||grad||^2 = 0.09570 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662099002218,"user_tz":-540,"elapsed":16,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"d5afc6df-cf53-4d16-83a6-0a3c904ca330","id":"TuDAtfpsx66v"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.807760\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"4Vx0yd8Dx66v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-15000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662099002219,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"804c78a8-2075-4d9c-d3bc-6655a617deaa","id":"3kxfxQlEx66v"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-15000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-imbal-20000"],"metadata":{"id":"q_B0_5H1x-AW"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"vvv0Pqomx-AW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-AR12/TGAN-syn-AR-one-of-all-20000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"UpJ6J8aWx-AW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"43fFp9YTx-AW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"QR5ovb9Mx-AX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"O6VvCMf3x-AX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"8FZ7rmYDx-AX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"F_mDIy6Xx-AX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"Hc_vDuI3x-AX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"lyX3AuW5x-AX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662099434953,"user_tz":-540,"elapsed":320974,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"c02091a9-e2c7-439e-f28f-aef0ddd7bfb2","id":"T7brmqYgx-AX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 2437019.685 - ||grad||^2 = 6138808.77249 - ||diff_w|| = 16.62814\n"," * Iteration #2 - Loss = 621739.470 - ||grad||^2 = 3188916.80616 - ||diff_w|| = 6.12318\n"," * Iteration #3 - Loss = 191859.842 - ||grad||^2 = 1773206.69386 - ||diff_w|| = 3.30465\n"," * Iteration #4 - Loss = 62761.770 - ||grad||^2 = 958056.88389 - ||diff_w|| = 1.64958\n"," * Iteration #5 - Loss = 28694.384 - ||grad||^2 = 492046.27346 - ||diff_w|| = 0.75561\n"," * Iteration #6 - Loss = 23534.985 - ||grad||^2 = 174087.14237 - ||diff_w|| = 0.37410\n"," * Iteration #7 - Loss = 23846.049 - ||grad||^2 = 36653.96390 - ||diff_w|| = 0.16886\n"," * Iteration #8 - Loss = 23825.316 - ||grad||^2 = 10227.87330 - ||diff_w|| = 0.07350\n"," * Iteration #9 - Loss = 23832.593 - ||grad||^2 = 3471.13124 - ||diff_w|| = 0.03565\n"," * Iteration #10 - Loss = 23833.037 - ||grad||^2 = 1343.32589 - ||diff_w|| = 0.01803\n"," * Iteration #11 - Loss = 23833.689 - ||grad||^2 = 576.16123 - ||diff_w|| = 0.00943\n"," * Iteration #12 - Loss = 23833.760 - ||grad||^2 = 266.36626 - ||diff_w|| = 0.00500\n"," * Iteration #13 - Loss = 23833.831 - ||grad||^2 = 130.47246 - ||diff_w|| = 0.00268\n"," * Iteration #14 - Loss = 23833.865 - ||grad||^2 = 68.35805 - ||diff_w|| = 0.00144\n"," * Iteration #15 - Loss = 23833.865 - ||grad||^2 = 35.52148 - ||diff_w|| = 0.00078\n"," * Iteration #16 - Loss = 23833.855 - ||grad||^2 = 18.67387 - ||diff_w|| = 0.00042\n"," * Iteration #17 - Loss = 23833.859 - ||grad||^2 = 9.76015 - ||diff_w|| = 0.00023\n"," * Iteration #18 - Loss = 23833.862 - ||grad||^2 = 4.90959 - ||diff_w|| = 0.00012\n"," * Iteration #19 - Loss = 23833.861 - ||grad||^2 = 2.50581 - ||diff_w|| = 0.00007\n"," * Iteration #20 - Loss = 23833.858 - ||grad||^2 = 1.32394 - ||diff_w|| = 0.00004\n"," * Iteration #21 - Loss = 23833.861 - ||grad||^2 = 0.66921 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 23833.860 - ||grad||^2 = 0.32791 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 23833.859 - ||grad||^2 = 0.20274 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 23833.861 - ||grad||^2 = 0.13280 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 23833.858 - ||grad||^2 = 0.09755 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 23833.862 - ||grad||^2 = 0.10989 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 23833.858 - ||grad||^2 = 0.09830 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 23833.861 - ||grad||^2 = 0.08307 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 23833.858 - ||grad||^2 = 0.10264 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 23833.862 - ||grad||^2 = 0.11738 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 23833.858 - ||grad||^2 = 0.09975 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 23833.861 - ||grad||^2 = 0.09154 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 23833.859 - ||grad||^2 = 0.08411 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 23833.861 - ||grad||^2 = 0.08665 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 23833.859 - ||grad||^2 = 0.09469 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 23833.861 - ||grad||^2 = 0.08053 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 23833.858 - ||grad||^2 = 0.08490 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 23833.862 - ||grad||^2 = 0.12156 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 23833.858 - ||grad||^2 = 0.11012 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 23833.861 - ||grad||^2 = 0.08279 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 23833.859 - ||grad||^2 = 0.09429 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 23833.861 - ||grad||^2 = 0.09199 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 23833.858 - ||grad||^2 = 0.09379 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 23833.861 - ||grad||^2 = 0.10895 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 23833.859 - ||grad||^2 = 0.09158 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 23833.861 - ||grad||^2 = 0.07528 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 23833.859 - ||grad||^2 = 0.09305 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 23833.862 - ||grad||^2 = 0.09935 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 23833.858 - ||grad||^2 = 0.09840 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 23833.861 - ||grad||^2 = 0.09000 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 23833.858 - ||grad||^2 = 0.09079 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 23833.862 - ||grad||^2 = 0.10799 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 23833.858 - ||grad||^2 = 0.10883 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 23833.862 - ||grad||^2 = 0.09961 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 23833.858 - ||grad||^2 = 0.09426 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 23833.861 - ||grad||^2 = 0.10101 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 23833.859 - ||grad||^2 = 0.09207 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 23833.861 - ||grad||^2 = 0.08372 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 23833.859 - ||grad||^2 = 0.10184 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 23833.861 - ||grad||^2 = 0.08800 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 23833.858 - ||grad||^2 = 0.08956 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 23833.862 - ||grad||^2 = 0.11938 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 23833.858 - ||grad||^2 = 0.10298 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 23833.861 - ||grad||^2 = 0.08299 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 23833.858 - ||grad||^2 = 0.10231 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 23833.862 - ||grad||^2 = 0.11738 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 23833.858 - ||grad||^2 = 0.09247 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 23833.861 - ||grad||^2 = 0.07615 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 23833.859 - ||grad||^2 = 0.06802 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 23833.861 - ||grad||^2 = 0.08156 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 23833.859 - ||grad||^2 = 0.09216 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 23833.861 - ||grad||^2 = 0.08632 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 23833.858 - ||grad||^2 = 0.09129 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 23833.862 - ||grad||^2 = 0.11842 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 23833.858 - ||grad||^2 = 0.10315 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 23833.861 - ||grad||^2 = 0.08228 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 23833.859 - ||grad||^2 = 0.09198 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 23833.861 - ||grad||^2 = 0.09716 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 23833.858 - ||grad||^2 = 0.09300 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 23833.861 - ||grad||^2 = 0.10363 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 23833.858 - ||grad||^2 = 0.09035 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 23833.861 - ||grad||^2 = 0.08930 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 23833.859 - ||grad||^2 = 0.09985 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 23833.861 - ||grad||^2 = 0.08596 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 23833.858 - ||grad||^2 = 0.07940 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 23833.861 - ||grad||^2 = 0.09879 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 23833.859 - ||grad||^2 = 0.09318 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 23833.861 - ||grad||^2 = 0.08314 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 23833.859 - ||grad||^2 = 0.10186 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 23833.861 - ||grad||^2 = 0.08804 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 23833.858 - ||grad||^2 = 0.08962 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 23833.862 - ||grad||^2 = 0.11934 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 23833.858 - ||grad||^2 = 0.10300 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 23833.861 - ||grad||^2 = 0.08083 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 23833.859 - ||grad||^2 = 0.09904 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 23833.862 - ||grad||^2 = 0.10448 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 23833.859 - ||grad||^2 = 0.08430 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 23833.861 - ||grad||^2 = 0.09632 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 23833.859 - ||grad||^2 = 0.08801 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 23833.861 - ||grad||^2 = 0.07095 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662099434954,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"7a7db978-b026-4c29-eb4d-b1f1ed3bd997","id":"oSqfZD-5x-AX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.808720\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"72RFqHyZx-AX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-20000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662099434954,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"b70885d5-d502-45f4-a947-cf701f541c76","id":"SfdeZ8TJx-AX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-20000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-imbal-25000"],"metadata":{"id":"N9hDOpvqzBPf"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"s97-K13AzBPq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-AR12/TGAN-syn-AR-one-of-all-25000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"cNyponS5zBPq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"R7RUavApzBPq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"v98Urqr7zBPq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"J3jtihnazBPq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"bPch67GbzBPq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"aP47PrclzBPr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"zvw35-ovzBPr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"Vm8gQeo5zBPr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662100184454,"user_tz":-540,"elapsed":500090,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"8078c910-62a8-432d-bb19-bd7bd93c0d51","id":"Yn0vyEJMzBPr"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 2814127.212 - ||grad||^2 = 4833649.93834 - ||diff_w|| = 15.82977\n"," * Iteration #2 - Loss = 723067.217 - ||grad||^2 = 2472309.47157 - ||diff_w|| = 7.08957\n"," * Iteration #3 - Loss = 230927.102 - ||grad||^2 = 1398193.60892 - ||diff_w|| = 3.80684\n"," * Iteration #4 - Loss = 81631.011 - ||grad||^2 = 748029.15248 - ||diff_w|| = 1.80554\n"," * Iteration #5 - Loss = 42054.725 - ||grad||^2 = 308560.72222 - ||diff_w|| = 0.66845\n"," * Iteration #6 - Loss = 36640.233 - ||grad||^2 = 110283.68664 - ||diff_w|| = 0.26914\n"," * Iteration #7 - Loss = 36548.139 - ||grad||^2 = 33169.36429 - ||diff_w|| = 0.11162\n"," * Iteration #8 - Loss = 36571.483 - ||grad||^2 = 10416.84657 - ||diff_w|| = 0.04535\n"," * Iteration #9 - Loss = 36573.801 - ||grad||^2 = 3338.40852 - ||diff_w|| = 0.01966\n"," * Iteration #10 - Loss = 36575.674 - ||grad||^2 = 1134.61448 - ||diff_w|| = 0.00938\n"," * Iteration #11 - Loss = 36576.094 - ||grad||^2 = 438.47282 - ||diff_w|| = 0.00474\n"," * Iteration #12 - Loss = 36576.210 - ||grad||^2 = 184.29919 - ||diff_w|| = 0.00249\n"," * Iteration #13 - Loss = 36576.246 - ||grad||^2 = 90.87085 - ||diff_w|| = 0.00132\n"," * Iteration #14 - Loss = 36576.262 - ||grad||^2 = 48.44675 - ||diff_w|| = 0.00071\n"," * Iteration #15 - Loss = 36576.262 - ||grad||^2 = 26.55864 - ||diff_w|| = 0.00038\n"," * Iteration #16 - Loss = 36576.274 - ||grad||^2 = 14.39217 - ||diff_w|| = 0.00021\n"," * Iteration #17 - Loss = 36576.270 - ||grad||^2 = 7.71314 - ||diff_w|| = 0.00011\n"," * Iteration #18 - Loss = 36576.271 - ||grad||^2 = 4.12882 - ||diff_w|| = 0.00006\n"," * Iteration #19 - Loss = 36576.271 - ||grad||^2 = 2.16106 - ||diff_w|| = 0.00003\n"," * Iteration #20 - Loss = 36576.271 - ||grad||^2 = 1.18355 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 36576.271 - ||grad||^2 = 0.67280 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 36576.271 - ||grad||^2 = 0.35405 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 36576.271 - ||grad||^2 = 0.22114 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 36576.270 - ||grad||^2 = 0.11058 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 36576.271 - ||grad||^2 = 0.10147 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 36576.271 - ||grad||^2 = 0.09032 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 36576.271 - ||grad||^2 = 0.07493 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 36576.271 - ||grad||^2 = 0.07762 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 36576.271 - ||grad||^2 = 0.08061 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 36576.271 - ||grad||^2 = 0.07090 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 36576.271 - ||grad||^2 = 0.06168 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 36576.271 - ||grad||^2 = 0.07143 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 36576.269 - ||grad||^2 = 0.09626 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 36576.273 - ||grad||^2 = 0.10317 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 36576.269 - ||grad||^2 = 0.08232 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 36576.272 - ||grad||^2 = 0.06669 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 36576.270 - ||grad||^2 = 0.07180 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 36576.272 - ||grad||^2 = 0.07936 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 36576.270 - ||grad||^2 = 0.08070 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 36576.272 - ||grad||^2 = 0.08203 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 36576.270 - ||grad||^2 = 0.09060 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 36576.272 - ||grad||^2 = 0.09381 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 36576.270 - ||grad||^2 = 0.07015 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 36576.272 - ||grad||^2 = 0.05429 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 36576.270 - ||grad||^2 = 0.09115 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 36576.272 - ||grad||^2 = 0.08125 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 36576.270 - ||grad||^2 = 0.06979 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 36576.272 - ||grad||^2 = 0.07439 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 36576.270 - ||grad||^2 = 0.08358 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 36576.272 - ||grad||^2 = 0.08880 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 36576.270 - ||grad||^2 = 0.06097 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 36576.271 - ||grad||^2 = 0.04843 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 36576.271 - ||grad||^2 = 0.08431 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 36576.271 - ||grad||^2 = 0.07295 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 36576.270 - ||grad||^2 = 0.06146 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 36576.272 - ||grad||^2 = 0.08550 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 36576.270 - ||grad||^2 = 0.08979 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 36576.272 - ||grad||^2 = 0.09405 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 36576.270 - ||grad||^2 = 0.07026 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 36576.272 - ||grad||^2 = 0.05458 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 36576.270 - ||grad||^2 = 0.09097 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 36576.272 - ||grad||^2 = 0.08115 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 36576.270 - ||grad||^2 = 0.06311 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 36576.272 - ||grad||^2 = 0.08341 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 36576.270 - ||grad||^2 = 0.10136 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 36576.272 - ||grad||^2 = 0.08181 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 36576.271 - ||grad||^2 = 0.06232 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 36576.270 - ||grad||^2 = 0.07148 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 36576.271 - ||grad||^2 = 0.08021 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 36576.271 - ||grad||^2 = 0.06511 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 36576.272 - ||grad||^2 = 0.06392 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 36576.270 - ||grad||^2 = 0.07714 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 36576.271 - ||grad||^2 = 0.08159 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 36576.271 - ||grad||^2 = 0.09513 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 36576.272 - ||grad||^2 = 0.07240 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 36576.270 - ||grad||^2 = 0.07046 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 36576.272 - ||grad||^2 = 0.08854 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 36576.270 - ||grad||^2 = 0.09615 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 36576.272 - ||grad||^2 = 0.08787 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 36576.270 - ||grad||^2 = 0.08397 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 36576.271 - ||grad||^2 = 0.08041 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 36576.271 - ||grad||^2 = 0.09522 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 36576.272 - ||grad||^2 = 0.07705 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 36576.270 - ||grad||^2 = 0.07984 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 36576.272 - ||grad||^2 = 0.08916 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 36576.270 - ||grad||^2 = 0.09482 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 36576.272 - ||grad||^2 = 0.08830 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 36576.270 - ||grad||^2 = 0.08392 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 36576.271 - ||grad||^2 = 0.08064 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 36576.270 - ||grad||^2 = 0.09402 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 36576.272 - ||grad||^2 = 0.08486 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 36576.270 - ||grad||^2 = 0.08128 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 36576.272 - ||grad||^2 = 0.09195 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 36576.269 - ||grad||^2 = 0.09720 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 36576.273 - ||grad||^2 = 0.11356 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 36576.270 - ||grad||^2 = 0.10110 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 36576.271 - ||grad||^2 = 0.07770 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 36576.271 - ||grad||^2 = 0.09316 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 36576.271 - ||grad||^2 = 0.07127 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 36576.271 - ||grad||^2 = 0.07168 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662100184454,"user_tz":-540,"elapsed":21,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"f91aba44-d764-4930-e46d-6bd1a10a6a6b","id":"QQVCMVNLzBPr"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.810524\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"DdzrkWmyzBPs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-25000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662100184456,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"57ed7361-1716-4115-9633-d355bd8a93ed","id":"V3LUlf5xzBPs"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-25000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-imbal-30000"],"metadata":{"id":"E1SoyuNHzLqd"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"PKQUAu51zLqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-AR12/TGAN-syn-AR-one-of-all-30000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"0qdBEEWnzLqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"e7NYiaQNzLqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"bOTx2sm0zLqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"lL361KaxzLqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"llVmWpLrzLqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"nmMXYj1NzLqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"LS0RYN6RzLqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"7ngA3exczLqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662101352650,"user_tz":-540,"elapsed":715191,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"6d3751e9-94ea-4962-99f3-a370ba1e723c","id":"dcP9-rcHzLqe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 5401176.483 - ||grad||^2 = 5517323.55263 - ||diff_w|| = 18.03908\n"," * Iteration #2 - Loss = 1381067.262 - ||grad||^2 = 2802365.13374 - ||diff_w|| = 7.44244\n"," * Iteration #3 - Loss = 436235.599 - ||grad||^2 = 1580232.20270 - ||diff_w|| = 4.04145\n"," * Iteration #4 - Loss = 149110.523 - ||grad||^2 = 888344.04550 - ||diff_w|| = 2.01322\n"," * Iteration #5 - Loss = 68014.754 - ||grad||^2 = 414177.57421 - ||diff_w|| = 0.74797\n"," * Iteration #6 - Loss = 52492.953 - ||grad||^2 = 187457.42968 - ||diff_w|| = 0.27492\n"," * Iteration #7 - Loss = 52121.647 - ||grad||^2 = 61358.20176 - ||diff_w|| = 0.10240\n"," * Iteration #8 - Loss = 52261.745 - ||grad||^2 = 16738.28469 - ||diff_w|| = 0.03142\n"," * Iteration #9 - Loss = 52288.762 - ||grad||^2 = 4468.21032 - ||diff_w|| = 0.01041\n"," * Iteration #10 - Loss = 52294.144 - ||grad||^2 = 1388.85996 - ||diff_w|| = 0.00424\n"," * Iteration #11 - Loss = 52295.955 - ||grad||^2 = 466.06688 - ||diff_w|| = 0.00197\n"," * Iteration #12 - Loss = 52296.363 - ||grad||^2 = 190.99031 - ||diff_w|| = 0.00099\n"," * Iteration #13 - Loss = 52296.470 - ||grad||^2 = 85.54996 - ||diff_w|| = 0.00053\n"," * Iteration #14 - Loss = 52296.512 - ||grad||^2 = 41.11921 - ||diff_w|| = 0.00028\n"," * Iteration #15 - Loss = 52296.504 - ||grad||^2 = 20.25036 - ||diff_w|| = 0.00015\n"," * Iteration #16 - Loss = 52296.513 - ||grad||^2 = 10.21770 - ||diff_w|| = 0.00008\n"," * Iteration #17 - Loss = 52296.511 - ||grad||^2 = 5.32553 - ||diff_w|| = 0.00005\n"," * Iteration #18 - Loss = 52296.512 - ||grad||^2 = 2.65114 - ||diff_w|| = 0.00003\n"," * Iteration #19 - Loss = 52296.512 - ||grad||^2 = 1.41848 - ||diff_w|| = 0.00001\n"," * Iteration #20 - Loss = 52296.512 - ||grad||^2 = 0.77427 - ||diff_w|| = 0.00001\n"," * Iteration #21 - Loss = 52296.512 - ||grad||^2 = 0.38839 - ||diff_w|| = 0.00000\n"," * Iteration #22 - Loss = 52296.511 - ||grad||^2 = 0.20527 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 52296.512 - ||grad||^2 = 0.15287 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 52296.510 - ||grad||^2 = 0.08395 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 52296.512 - ||grad||^2 = 0.07986 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 52296.511 - ||grad||^2 = 0.04464 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 52296.512 - ||grad||^2 = 0.05535 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 52296.511 - ||grad||^2 = 0.05719 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 52296.512 - ||grad||^2 = 0.05243 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 52296.511 - ||grad||^2 = 0.08920 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 52296.512 - ||grad||^2 = 0.07551 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 52296.511 - ||grad||^2 = 0.03575 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 52296.511 - ||grad||^2 = 0.07475 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 52296.512 - ||grad||^2 = 0.06122 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 52296.512 - ||grad||^2 = 0.03452 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 52296.511 - ||grad||^2 = 0.04412 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 52296.512 - ||grad||^2 = 0.04555 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 52296.511 - ||grad||^2 = 0.07103 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 52296.512 - ||grad||^2 = 0.07137 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 52296.511 - ||grad||^2 = 0.07067 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 52296.511 - ||grad||^2 = 0.04894 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 52296.512 - ||grad||^2 = 0.05118 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 52296.511 - ||grad||^2 = 0.07500 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 52296.511 - ||grad||^2 = 0.05607 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 52296.511 - ||grad||^2 = 0.04067 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 52296.512 - ||grad||^2 = 0.07102 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 52296.512 - ||grad||^2 = 0.05282 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 52296.511 - ||grad||^2 = 0.05029 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 52296.511 - ||grad||^2 = 0.05962 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 52296.512 - ||grad||^2 = 0.06503 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 52296.511 - ||grad||^2 = 0.04736 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 52296.512 - ||grad||^2 = 0.04654 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 52296.512 - ||grad||^2 = 0.04305 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 52296.512 - ||grad||^2 = 0.06032 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 52296.511 - ||grad||^2 = 0.05308 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 52296.512 - ||grad||^2 = 0.03755 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 52296.511 - ||grad||^2 = 0.04559 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 52296.512 - ||grad||^2 = 0.05878 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 52296.511 - ||grad||^2 = 0.08317 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 52296.512 - ||grad||^2 = 0.08133 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 52296.510 - ||grad||^2 = 0.06002 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 52296.512 - ||grad||^2 = 0.07673 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 52296.511 - ||grad||^2 = 0.05438 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 52296.512 - ||grad||^2 = 0.05397 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 52296.511 - ||grad||^2 = 0.07444 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 52296.512 - ||grad||^2 = 0.07392 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 52296.511 - ||grad||^2 = 0.06330 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 52296.512 - ||grad||^2 = 0.06316 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 52296.510 - ||grad||^2 = 0.06589 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 52296.513 - ||grad||^2 = 0.07131 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 52296.510 - ||grad||^2 = 0.06032 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 52296.512 - ||grad||^2 = 0.05445 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 52296.510 - ||grad||^2 = 0.08320 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 52296.513 - ||grad||^2 = 0.09256 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 52296.510 - ||grad||^2 = 0.10169 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 52296.512 - ||grad||^2 = 0.08479 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 52296.510 - ||grad||^2 = 0.05115 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 52296.513 - ||grad||^2 = 0.07896 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 52296.510 - ||grad||^2 = 0.07505 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 52296.512 - ||grad||^2 = 0.07277 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 52296.511 - ||grad||^2 = 0.09215 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 52296.512 - ||grad||^2 = 0.08498 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 52296.510 - ||grad||^2 = 0.08367 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 52296.513 - ||grad||^2 = 0.09395 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 52296.510 - ||grad||^2 = 0.08230 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 52296.513 - ||grad||^2 = 0.07882 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 52296.511 - ||grad||^2 = 0.05526 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 52296.512 - ||grad||^2 = 0.04089 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 52296.511 - ||grad||^2 = 0.05046 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 52296.512 - ||grad||^2 = 0.06114 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 52296.510 - ||grad||^2 = 0.08185 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 52296.513 - ||grad||^2 = 0.09746 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 52296.510 - ||grad||^2 = 0.08338 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 52296.513 - ||grad||^2 = 0.08401 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 52296.510 - ||grad||^2 = 0.07279 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 52296.512 - ||grad||^2 = 0.06238 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 52296.511 - ||grad||^2 = 0.08638 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 52296.513 - ||grad||^2 = 0.08487 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 52296.510 - ||grad||^2 = 0.07805 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 52296.512 - ||grad||^2 = 0.07124 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662101352651,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"8298cc00-9764-4d65-918c-83e890a0b051","id":"v9lkRpCmzLqe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.811341\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"w_BL8_j0zLqe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-30000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662101352651,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"c53718e2-48b8-4e73-a25f-be8023227573","id":"8p_oPtF0zLqe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-30000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-imbal-35000"],"metadata":{"id":"MvqNGXfg3H7Z"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"cbxYLgJR3H7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('//content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-AR12/TGAN-syn-AR-one-of-all-35000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"kHkzVPTp3H7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"IddqPnpH3H7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"lbgDErmf3H7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"idx_xdAu3H7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"8wTC23hr3H7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"HgjnA6LW3H7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"sLHC-0WP3H7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"jVK_b8pB3H7k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662102395950,"user_tz":-540,"elapsed":978654,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"9cd37382-9a68-4f11-bb9a-34f785f7bdfa","id":"TUBIDeif3H7k"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 6641973.397 - ||grad||^2 = 11563425.95038 - ||diff_w|| = 15.96463\n"," * Iteration #2 - Loss = 1687189.941 - ||grad||^2 = 5842693.79892 - ||diff_w|| = 7.16063\n"," * Iteration #3 - Loss = 526395.626 - ||grad||^2 = 3231211.73932 - ||diff_w|| = 3.87266\n"," * Iteration #4 - Loss = 178472.453 - ||grad||^2 = 1702821.93790 - ||diff_w|| = 1.93569\n"," * Iteration #5 - Loss = 88557.492 - ||grad||^2 = 842373.44488 - ||diff_w|| = 0.88290\n"," * Iteration #6 - Loss = 73086.757 - ||grad||^2 = 339420.44849 - ||diff_w|| = 0.42281\n"," * Iteration #7 - Loss = 72374.769 - ||grad||^2 = 90600.09982 - ||diff_w|| = 0.17014\n"," * Iteration #8 - Loss = 72594.476 - ||grad||^2 = 24108.25915 - ||diff_w|| = 0.06809\n"," * Iteration #9 - Loss = 72622.179 - ||grad||^2 = 7533.21429 - ||diff_w|| = 0.03036\n"," * Iteration #10 - Loss = 72630.223 - ||grad||^2 = 2585.54143 - ||diff_w|| = 0.01452\n"," * Iteration #11 - Loss = 72632.636 - ||grad||^2 = 909.12165 - ||diff_w|| = 0.00731\n"," * Iteration #12 - Loss = 72633.091 - ||grad||^2 = 324.40916 - ||diff_w|| = 0.00381\n"," * Iteration #13 - Loss = 72633.274 - ||grad||^2 = 120.10826 - ||diff_w|| = 0.00204\n"," * Iteration #14 - Loss = 72633.407 - ||grad||^2 = 46.97236 - ||diff_w|| = 0.00110\n"," * Iteration #15 - Loss = 72633.405 - ||grad||^2 = 18.44102 - ||diff_w|| = 0.00060\n"," * Iteration #16 - Loss = 72633.425 - ||grad||^2 = 7.94152 - ||diff_w|| = 0.00033\n"," * Iteration #17 - Loss = 72633.426 - ||grad||^2 = 3.68582 - ||diff_w|| = 0.00018\n"," * Iteration #18 - Loss = 72633.424 - ||grad||^2 = 1.71564 - ||diff_w|| = 0.00010\n"," * Iteration #19 - Loss = 72633.431 - ||grad||^2 = 0.71392 - ||diff_w|| = 0.00005\n"," * Iteration #20 - Loss = 72633.426 - ||grad||^2 = 0.46640 - ||diff_w|| = 0.00003\n"," * Iteration #21 - Loss = 72633.429 - ||grad||^2 = 0.19813 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 72633.426 - ||grad||^2 = 0.18004 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 72633.428 - ||grad||^2 = 0.09258 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 72633.426 - ||grad||^2 = 0.11951 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 72633.428 - ||grad||^2 = 0.10430 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 72633.427 - ||grad||^2 = 0.09641 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 72633.427 - ||grad||^2 = 0.09138 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 72633.427 - ||grad||^2 = 0.10517 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 72633.427 - ||grad||^2 = 0.10087 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 72633.427 - ||grad||^2 = 0.10923 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 72633.426 - ||grad||^2 = 0.09947 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 72633.429 - ||grad||^2 = 0.12658 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 72633.426 - ||grad||^2 = 0.11543 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 72633.427 - ||grad||^2 = 0.10805 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 72633.427 - ||grad||^2 = 0.09642 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 72633.428 - ||grad||^2 = 0.11221 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 72633.426 - ||grad||^2 = 0.10095 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 72633.428 - ||grad||^2 = 0.08895 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 72633.427 - ||grad||^2 = 0.09462 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 72633.428 - ||grad||^2 = 0.10528 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 72633.427 - ||grad||^2 = 0.10773 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 72633.427 - ||grad||^2 = 0.10271 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 72633.427 - ||grad||^2 = 0.09636 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 72633.428 - ||grad||^2 = 0.09093 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 72633.426 - ||grad||^2 = 0.09419 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 72633.428 - ||grad||^2 = 0.11746 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 72633.426 - ||grad||^2 = 0.10346 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 72633.427 - ||grad||^2 = 0.09808 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 72633.427 - ||grad||^2 = 0.09619 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 72633.427 - ||grad||^2 = 0.08784 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 72633.427 - ||grad||^2 = 0.09752 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 72633.427 - ||grad||^2 = 0.10285 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 72633.427 - ||grad||^2 = 0.10083 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 72633.427 - ||grad||^2 = 0.10775 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 72633.428 - ||grad||^2 = 0.11651 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 72633.427 - ||grad||^2 = 0.08578 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 72633.427 - ||grad||^2 = 0.08664 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 72633.427 - ||grad||^2 = 0.09866 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 72633.428 - ||grad||^2 = 0.09516 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 72633.427 - ||grad||^2 = 0.10568 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 72633.427 - ||grad||^2 = 0.10076 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 72633.427 - ||grad||^2 = 0.09742 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 72633.427 - ||grad||^2 = 0.10962 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 72633.427 - ||grad||^2 = 0.10971 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 72633.427 - ||grad||^2 = 0.09408 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 72633.428 - ||grad||^2 = 0.11249 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 72633.426 - ||grad||^2 = 0.11329 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 72633.428 - ||grad||^2 = 0.08939 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 72633.427 - ||grad||^2 = 0.09187 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 72633.427 - ||grad||^2 = 0.09406 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 72633.427 - ||grad||^2 = 0.08948 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 72633.427 - ||grad||^2 = 0.10386 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 72633.428 - ||grad||^2 = 0.11975 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 72633.427 - ||grad||^2 = 0.09494 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 72633.427 - ||grad||^2 = 0.08759 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 72633.427 - ||grad||^2 = 0.09742 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 72633.428 - ||grad||^2 = 0.09609 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 72633.427 - ||grad||^2 = 0.10464 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 72633.427 - ||grad||^2 = 0.10359 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 72633.427 - ||grad||^2 = 0.09142 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 72633.427 - ||grad||^2 = 0.09410 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 72633.427 - ||grad||^2 = 0.11623 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 72633.428 - ||grad||^2 = 0.12141 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 72633.427 - ||grad||^2 = 0.10821 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 72633.427 - ||grad||^2 = 0.09769 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 72633.428 - ||grad||^2 = 0.08457 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 72633.427 - ||grad||^2 = 0.09495 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 72633.427 - ||grad||^2 = 0.10045 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 72633.427 - ||grad||^2 = 0.09606 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 72633.428 - ||grad||^2 = 0.10399 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 72633.426 - ||grad||^2 = 0.09997 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 72633.428 - ||grad||^2 = 0.09691 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 72633.426 - ||grad||^2 = 0.09666 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 72633.427 - ||grad||^2 = 0.09860 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 72633.427 - ||grad||^2 = 0.09010 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 72633.427 - ||grad||^2 = 0.09904 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 72633.427 - ||grad||^2 = 0.10370 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 72633.427 - ||grad||^2 = 0.09237 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 72633.428 - ||grad||^2 = 0.09089 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 72633.427 - ||grad||^2 = 0.09852 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662102395950,"user_tz":-540,"elapsed":19,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"eecbd000-c6b8-48ef-f2ff-643006470c15","id":"cX6IQFMQ3H7k"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.809235\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"C-gmlA6O3H7k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-35000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662102395951,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"e706973c-33fd-4885-cf57-bfbfe203e916","id":"6PfP8oRm3H7k"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-35000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-imbal-40000"],"metadata":{"id":"YT_9Cnb73Ihq"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"PEJDAMGt3Ihq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-AR12/TGAN-syn-AR-one-of-all-40000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"xxaFLsqm3Ihq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"j45o41023Ihr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"1nmDC--V3Ihr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"O77BI6v13Ihr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"2q-8IJ2I3Ihr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"M_6TMg3O3Ihr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"_-l6bN493Ihr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"cs-mJfjO3Ihr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662103934423,"user_tz":-540,"elapsed":1279506,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"7206d166-759f-4bc9-c5e3-835c7bacfbae","id":"jrv6M8CG3Ihr"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 10308385.192 - ||grad||^2 = 17074543.92509 - ||diff_w|| = 16.43558\n"," * Iteration #2 - Loss = 2873111.744 - ||grad||^2 = 9614405.28066 - ||diff_w|| = 6.82797\n"," * Iteration #3 - Loss = 881934.302 - ||grad||^2 = 5357465.25841 - ||diff_w|| = 3.68179\n"," * Iteration #4 - Loss = 283335.045 - ||grad||^2 = 2889476.59256 - ||diff_w|| = 1.81828\n"," * Iteration #5 - Loss = 125945.200 - ||grad||^2 = 1456919.50874 - ||diff_w|| = 0.81098\n"," * Iteration #6 - Loss = 96993.183 - ||grad||^2 = 629854.15032 - ||diff_w|| = 0.40479\n"," * Iteration #7 - Loss = 94226.800 - ||grad||^2 = 240699.88717 - ||diff_w|| = 0.17678\n"," * Iteration #8 - Loss = 94191.273 - ||grad||^2 = 83877.74519 - ||diff_w|| = 0.06726\n"," * Iteration #9 - Loss = 94242.709 - ||grad||^2 = 25148.70106 - ||diff_w|| = 0.02437\n"," * Iteration #10 - Loss = 94276.307 - ||grad||^2 = 7485.98525 - ||diff_w|| = 0.00889\n"," * Iteration #11 - Loss = 94286.761 - ||grad||^2 = 2720.73645 - ||diff_w|| = 0.00387\n"," * Iteration #12 - Loss = 94288.143 - ||grad||^2 = 1096.96792 - ||diff_w|| = 0.00197\n"," * Iteration #13 - Loss = 94288.726 - ||grad||^2 = 473.78333 - ||diff_w|| = 0.00103\n"," * Iteration #14 - Loss = 94288.774 - ||grad||^2 = 216.38378 - ||diff_w|| = 0.00055\n"," * Iteration #15 - Loss = 94288.821 - ||grad||^2 = 104.94661 - ||diff_w|| = 0.00029\n"," * Iteration #16 - Loss = 94288.835 - ||grad||^2 = 51.58587 - ||diff_w|| = 0.00016\n"," * Iteration #17 - Loss = 94288.835 - ||grad||^2 = 25.53738 - ||diff_w|| = 0.00009\n"," * Iteration #18 - Loss = 94288.841 - ||grad||^2 = 12.84036 - ||diff_w|| = 0.00005\n"," * Iteration #19 - Loss = 94288.844 - ||grad||^2 = 6.41849 - ||diff_w|| = 0.00003\n"," * Iteration #20 - Loss = 94288.841 - ||grad||^2 = 3.18487 - ||diff_w|| = 0.00001\n"," * Iteration #21 - Loss = 94288.842 - ||grad||^2 = 1.63740 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 94288.840 - ||grad||^2 = 0.82257 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 94288.844 - ||grad||^2 = 0.49535 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 94288.839 - ||grad||^2 = 0.20608 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 94288.844 - ||grad||^2 = 0.21027 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 94288.840 - ||grad||^2 = 0.11151 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 94288.843 - ||grad||^2 = 0.11592 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 94288.840 - ||grad||^2 = 0.09101 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 94288.843 - ||grad||^2 = 0.08922 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 94288.840 - ||grad||^2 = 0.08843 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 94288.843 - ||grad||^2 = 0.09651 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 94288.841 - ||grad||^2 = 0.09181 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 94288.843 - ||grad||^2 = 0.09455 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 94288.841 - ||grad||^2 = 0.09031 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 94288.842 - ||grad||^2 = 0.08383 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 94288.841 - ||grad||^2 = 0.07761 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 94288.843 - ||grad||^2 = 0.09679 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 94288.840 - ||grad||^2 = 0.09783 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 94288.843 - ||grad||^2 = 0.08584 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 94288.841 - ||grad||^2 = 0.08847 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 94288.843 - ||grad||^2 = 0.08733 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 94288.841 - ||grad||^2 = 0.08950 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 94288.843 - ||grad||^2 = 0.09192 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 94288.841 - ||grad||^2 = 0.09333 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 94288.842 - ||grad||^2 = 0.08422 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 94288.841 - ||grad||^2 = 0.07970 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 94288.843 - ||grad||^2 = 0.09577 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 94288.840 - ||grad||^2 = 0.09885 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 94288.843 - ||grad||^2 = 0.08563 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 94288.841 - ||grad||^2 = 0.08851 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 94288.843 - ||grad||^2 = 0.08712 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 94288.841 - ||grad||^2 = 0.08950 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 94288.843 - ||grad||^2 = 0.09188 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 94288.841 - ||grad||^2 = 0.09337 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 94288.842 - ||grad||^2 = 0.08421 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 94288.841 - ||grad||^2 = 0.07970 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 94288.843 - ||grad||^2 = 0.09577 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 94288.840 - ||grad||^2 = 0.09885 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 94288.843 - ||grad||^2 = 0.08563 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 94288.841 - ||grad||^2 = 0.08851 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 94288.843 - ||grad||^2 = 0.08712 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 94288.841 - ||grad||^2 = 0.08950 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 94288.843 - ||grad||^2 = 0.09188 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 94288.841 - ||grad||^2 = 0.09337 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 94288.842 - ||grad||^2 = 0.08421 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 94288.841 - ||grad||^2 = 0.07970 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 94288.843 - ||grad||^2 = 0.09577 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 94288.840 - ||grad||^2 = 0.09885 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 94288.843 - ||grad||^2 = 0.08563 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 94288.841 - ||grad||^2 = 0.08851 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 94288.843 - ||grad||^2 = 0.08712 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 94288.841 - ||grad||^2 = 0.08950 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 94288.843 - ||grad||^2 = 0.09188 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 94288.841 - ||grad||^2 = 0.09337 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 94288.842 - ||grad||^2 = 0.08421 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 94288.841 - ||grad||^2 = 0.07970 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 94288.843 - ||grad||^2 = 0.09577 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 94288.840 - ||grad||^2 = 0.09885 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 94288.843 - ||grad||^2 = 0.08563 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 94288.841 - ||grad||^2 = 0.08851 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 94288.843 - ||grad||^2 = 0.08712 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 94288.841 - ||grad||^2 = 0.08950 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 94288.843 - ||grad||^2 = 0.09188 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 94288.841 - ||grad||^2 = 0.09337 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 94288.842 - ||grad||^2 = 0.08421 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 94288.841 - ||grad||^2 = 0.07970 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 94288.843 - ||grad||^2 = 0.09577 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 94288.840 - ||grad||^2 = 0.09885 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 94288.843 - ||grad||^2 = 0.08563 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 94288.841 - ||grad||^2 = 0.08851 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 94288.843 - ||grad||^2 = 0.08712 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 94288.841 - ||grad||^2 = 0.08950 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 94288.843 - ||grad||^2 = 0.09188 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 94288.841 - ||grad||^2 = 0.09337 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 94288.842 - ||grad||^2 = 0.08421 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 94288.841 - ||grad||^2 = 0.07970 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 94288.843 - ||grad||^2 = 0.09577 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 94288.840 - ||grad||^2 = 0.09885 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 94288.843 - ||grad||^2 = 0.08563 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 94288.841 - ||grad||^2 = 0.08851 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662103934423,"user_tz":-540,"elapsed":21,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"01fc753f-a17d-492b-a2c9-766bbf2f63ad","id":"IfGbx4663Ihs"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.809564\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"I3_E522b3Ihs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-40000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662103934424,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"385a9827-a033-4ea0-ec21-223ca6c27c7e","id":"Ko4x5E1v3Ihs"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-40000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-imbal-45000"],"metadata":{"id":"YNh117Fv3UpJ"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"1y8RxEI-3UpJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-AR12/TGAN-syn-AR-one-of-all-45000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"3ebgomBu3UpJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"jqsJC2G03UpJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"2ustf6bN3UpJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"HdBtlyBE3UpK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"PGASXcZ-3UpK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"roOls5-y3UpK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"1_Mqpc8E3UpK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"ieDI6NQ43UpK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662165440049,"user_tz":-540,"elapsed":1461666,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"06bde0b6-11ee-4f21-dfa7-af4307d06acc","id":"-X_5as7V3UpK"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 47084893.526 - ||grad||^2 = 75031729.52377 - ||diff_w|| = 16.19928\n"," * Iteration #2 - Loss = 11871731.519 - ||grad||^2 = 37951189.63233 - ||diff_w|| = 7.27697\n"," * Iteration #3 - Loss = 3632200.108 - ||grad||^2 = 21218610.33017 - ||diff_w|| = 3.97565\n"," * Iteration #4 - Loss = 1119828.480 - ||grad||^2 = 11858357.77672 - ||diff_w|| = 2.12916\n"," * Iteration #5 - Loss = 368282.680 - ||grad||^2 = 6390286.99202 - ||diff_w|| = 1.07676\n"," * Iteration #6 - Loss = 164246.698 - ||grad||^2 = 3270090.28114 - ||diff_w|| = 0.52811\n"," * Iteration #7 - Loss = 121858.601 - ||grad||^2 = 1479715.59509 - ||diff_w|| = 0.27064\n"," * Iteration #8 - Loss = 120560.720 - ||grad||^2 = 471823.83652 - ||diff_w|| = 0.11612\n"," * Iteration #9 - Loss = 121358.949 - ||grad||^2 = 130170.02764 - ||diff_w|| = 0.04584\n"," * Iteration #10 - Loss = 121353.921 - ||grad||^2 = 35057.78439 - ||diff_w|| = 0.01702\n"," * Iteration #11 - Loss = 121387.922 - ||grad||^2 = 8265.86683 - ||diff_w|| = 0.00529\n"," * Iteration #12 - Loss = 121394.754 - ||grad||^2 = 2590.75229 - ||diff_w|| = 0.00226\n"," * Iteration #13 - Loss = 121395.205 - ||grad||^2 = 904.30569 - ||diff_w|| = 0.00105\n"," * Iteration #14 - Loss = 121395.325 - ||grad||^2 = 333.03382 - ||diff_w|| = 0.00053\n"," * Iteration #15 - Loss = 121395.401 - ||grad||^2 = 128.78277 - ||diff_w|| = 0.00027\n"," * Iteration #16 - Loss = 121395.426 - ||grad||^2 = 52.94353 - ||diff_w|| = 0.00015\n"," * Iteration #17 - Loss = 121395.435 - ||grad||^2 = 22.55968 - ||diff_w|| = 0.00008\n"," * Iteration #18 - Loss = 121395.428 - ||grad||^2 = 10.06458 - ||diff_w|| = 0.00004\n"," * Iteration #19 - Loss = 121395.432 - ||grad||^2 = 4.74106 - ||diff_w|| = 0.00002\n"," * Iteration #20 - Loss = 121395.429 - ||grad||^2 = 2.34114 - ||diff_w|| = 0.00001\n"," * Iteration #21 - Loss = 121395.434 - ||grad||^2 = 1.14867 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 121395.435 - ||grad||^2 = 0.54583 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 121395.434 - ||grad||^2 = 0.31246 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 121395.434 - ||grad||^2 = 0.14165 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 121395.433 - ||grad||^2 = 0.06717 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 121395.434 - ||grad||^2 = 0.04898 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 121395.433 - ||grad||^2 = 0.03231 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 121395.434 - ||grad||^2 = 0.01809 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 121395.433 - ||grad||^2 = 0.01969 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 121395.434 - ||grad||^2 = 0.02812 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 121395.434 - ||grad||^2 = 0.02025 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 121395.434 - ||grad||^2 = 0.01271 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 121395.434 - ||grad||^2 = 0.01500 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 121395.434 - ||grad||^2 = 0.02764 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 121395.434 - ||grad||^2 = 0.02052 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 121395.434 - ||grad||^2 = 0.01279 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 121395.433 - ||grad||^2 = 0.01652 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 121395.434 - ||grad||^2 = 0.03106 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 121395.433 - ||grad||^2 = 0.02292 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 121395.434 - ||grad||^2 = 0.01731 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 121395.433 - ||grad||^2 = 0.01820 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 121395.434 - ||grad||^2 = 0.02766 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 121395.434 - ||grad||^2 = 0.02074 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 121395.434 - ||grad||^2 = 0.01257 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 121395.434 - ||grad||^2 = 0.01515 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 121395.434 - ||grad||^2 = 0.02756 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 121395.434 - ||grad||^2 = 0.02056 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 121395.434 - ||grad||^2 = 0.01277 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 121395.433 - ||grad||^2 = 0.01651 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 121395.434 - ||grad||^2 = 0.03106 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 121395.433 - ||grad||^2 = 0.02292 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 121395.434 - ||grad||^2 = 0.01731 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 121395.433 - ||grad||^2 = 0.01820 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 121395.434 - ||grad||^2 = 0.02766 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 121395.434 - ||grad||^2 = 0.02074 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 121395.434 - ||grad||^2 = 0.01257 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 121395.434 - ||grad||^2 = 0.01515 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 121395.434 - ||grad||^2 = 0.02756 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 121395.434 - ||grad||^2 = 0.02056 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 121395.434 - ||grad||^2 = 0.01277 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 121395.433 - ||grad||^2 = 0.01651 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 121395.434 - ||grad||^2 = 0.03106 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 121395.433 - ||grad||^2 = 0.02292 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 121395.434 - ||grad||^2 = 0.01731 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 121395.433 - ||grad||^2 = 0.01820 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 121395.434 - ||grad||^2 = 0.02766 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 121395.434 - ||grad||^2 = 0.02074 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 121395.434 - ||grad||^2 = 0.01257 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 121395.434 - ||grad||^2 = 0.01515 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 121395.434 - ||grad||^2 = 0.02756 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 121395.434 - ||grad||^2 = 0.02056 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 121395.434 - ||grad||^2 = 0.01277 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 121395.433 - ||grad||^2 = 0.01651 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 121395.434 - ||grad||^2 = 0.03106 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 121395.433 - ||grad||^2 = 0.02292 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 121395.434 - ||grad||^2 = 0.01731 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 121395.433 - ||grad||^2 = 0.01820 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 121395.434 - ||grad||^2 = 0.02766 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 121395.434 - ||grad||^2 = 0.02074 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 121395.434 - ||grad||^2 = 0.01257 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 121395.434 - ||grad||^2 = 0.01515 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 121395.434 - ||grad||^2 = 0.02756 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 121395.434 - ||grad||^2 = 0.02056 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 121395.434 - ||grad||^2 = 0.01277 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 121395.433 - ||grad||^2 = 0.01651 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 121395.434 - ||grad||^2 = 0.03106 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 121395.433 - ||grad||^2 = 0.02292 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 121395.434 - ||grad||^2 = 0.01731 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 121395.433 - ||grad||^2 = 0.01820 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 121395.434 - ||grad||^2 = 0.02766 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 121395.434 - ||grad||^2 = 0.02074 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 121395.434 - ||grad||^2 = 0.01257 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 121395.434 - ||grad||^2 = 0.01515 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 121395.434 - ||grad||^2 = 0.02756 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 121395.434 - ||grad||^2 = 0.02056 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 121395.434 - ||grad||^2 = 0.01277 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 121395.433 - ||grad||^2 = 0.01651 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 121395.434 - ||grad||^2 = 0.03106 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 121395.433 - ||grad||^2 = 0.02292 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 121395.434 - ||grad||^2 = 0.01731 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662165440050,"user_tz":-540,"elapsed":21,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"c57cb69b-a01a-4c54-e6d9-f9c866b17e25","id":"-h87RHtN3UpK"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.810222\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"f8V26ZJH3UpK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-45000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662165440566,"user_tz":-540,"elapsed":520,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"ced9fc9c-defe-4e94-dbd8-df63f5cc8fab","id":"o7jSb_tL3UpK"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-45000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-imbal-50000"],"metadata":{"id":"IJhq4zj83biB"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"tBym7xLR3biC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-AR12/TGAN-syn-AR-one-of-all-50000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"c7fBgAoh3biC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"yRNlQXRz3biC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"Q0tZXtTc3biD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"vocCRpqM3biD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"qvfDnQYN3biD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"nrdf9CUf3biD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"LzCmIRnR3biD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"b8IsJLBV3biD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662167301124,"user_tz":-540,"elapsed":1811805,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"12ea83ff-6812-4ec0-c913-28169e25c1cc","id":"8JGVOSnU3biD"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 29391470.428 - ||grad||^2 = 50024734.22640 - ||diff_w|| = 16.25078\n"," * Iteration #2 - Loss = 7404865.244 - ||grad||^2 = 25257550.99939 - ||diff_w|| = 7.30033\n"," * Iteration #3 - Loss = 2263005.907 - ||grad||^2 = 14050738.91335 - ||diff_w|| = 3.98300\n"," * Iteration #4 - Loss = 703056.727 - ||grad||^2 = 7730104.09819 - ||diff_w|| = 2.08552\n"," * Iteration #5 - Loss = 253584.873 - ||grad||^2 = 3992389.37087 - ||diff_w|| = 0.93287\n"," * Iteration #6 - Loss = 154586.046 - ||grad||^2 = 1828511.38705 - ||diff_w|| = 0.43548\n"," * Iteration #7 - Loss = 143985.523 - ||grad||^2 = 607842.98405 - ||diff_w|| = 0.21831\n"," * Iteration #8 - Loss = 144563.742 - ||grad||^2 = 175819.69929 - ||diff_w|| = 0.08961\n"," * Iteration #9 - Loss = 144703.272 - ||grad||^2 = 53133.13515 - ||diff_w|| = 0.03100\n"," * Iteration #10 - Loss = 144761.765 - ||grad||^2 = 16716.56826 - ||diff_w|| = 0.01149\n"," * Iteration #11 - Loss = 144769.875 - ||grad||^2 = 5482.69553 - ||diff_w|| = 0.00483\n"," * Iteration #12 - Loss = 144772.642 - ||grad||^2 = 1845.26599 - ||diff_w|| = 0.00219\n"," * Iteration #13 - Loss = 144773.463 - ||grad||^2 = 647.26068 - ||diff_w|| = 0.00107\n"," * Iteration #14 - Loss = 144773.796 - ||grad||^2 = 253.26490 - ||diff_w|| = 0.00055\n"," * Iteration #15 - Loss = 144773.800 - ||grad||^2 = 111.33952 - ||diff_w|| = 0.00028\n"," * Iteration #16 - Loss = 144773.861 - ||grad||^2 = 56.10900 - ||diff_w|| = 0.00015\n"," * Iteration #17 - Loss = 144773.850 - ||grad||^2 = 29.46853 - ||diff_w|| = 0.00008\n"," * Iteration #18 - Loss = 144773.864 - ||grad||^2 = 15.84649 - ||diff_w|| = 0.00004\n"," * Iteration #19 - Loss = 144773.862 - ||grad||^2 = 8.54838 - ||diff_w|| = 0.00002\n"," * Iteration #20 - Loss = 144773.863 - ||grad||^2 = 4.59607 - ||diff_w|| = 0.00001\n"," * Iteration #21 - Loss = 144773.865 - ||grad||^2 = 2.43642 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 144773.864 - ||grad||^2 = 1.28329 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 144773.865 - ||grad||^2 = 0.65782 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 144773.866 - ||grad||^2 = 0.37424 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 144773.865 - ||grad||^2 = 0.18882 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 144773.866 - ||grad||^2 = 0.10655 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 144773.864 - ||grad||^2 = 0.08011 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 144773.866 - ||grad||^2 = 0.10605 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 144773.864 - ||grad||^2 = 0.09714 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 144773.867 - ||grad||^2 = 0.09928 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 144773.863 - ||grad||^2 = 0.10298 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 144773.867 - ||grad||^2 = 0.10491 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 144773.863 - ||grad||^2 = 0.09997 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 144773.866 - ||grad||^2 = 0.09242 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 144773.864 - ||grad||^2 = 0.08123 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 144773.867 - ||grad||^2 = 0.08712 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 144773.864 - ||grad||^2 = 0.07847 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 144773.867 - ||grad||^2 = 0.07415 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 144773.863 - ||grad||^2 = 0.08431 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 144773.868 - ||grad||^2 = 0.09897 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 144773.863 - ||grad||^2 = 0.10978 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 144773.867 - ||grad||^2 = 0.12684 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 144773.864 - ||grad||^2 = 0.10063 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 144773.866 - ||grad||^2 = 0.08964 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 144773.863 - ||grad||^2 = 0.09042 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 144773.867 - ||grad||^2 = 0.10642 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 144773.863 - ||grad||^2 = 0.10327 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 144773.867 - ||grad||^2 = 0.11535 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 144773.864 - ||grad||^2 = 0.10044 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 144773.866 - ||grad||^2 = 0.08787 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 144773.864 - ||grad||^2 = 0.07768 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 144773.866 - ||grad||^2 = 0.08663 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 144773.864 - ||grad||^2 = 0.07995 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 144773.867 - ||grad||^2 = 0.09713 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 144773.863 - ||grad||^2 = 0.10038 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 144773.867 - ||grad||^2 = 0.10353 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 144773.863 - ||grad||^2 = 0.10773 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 144773.867 - ||grad||^2 = 0.10681 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 144773.863 - ||grad||^2 = 0.10967 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 144773.867 - ||grad||^2 = 0.11309 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 144773.863 - ||grad||^2 = 0.10801 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 144773.867 - ||grad||^2 = 0.10902 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 144773.863 - ||grad||^2 = 0.10151 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 144773.867 - ||grad||^2 = 0.10800 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 144773.863 - ||grad||^2 = 0.09788 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 144773.867 - ||grad||^2 = 0.11104 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 144773.863 - ||grad||^2 = 0.11473 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 144773.867 - ||grad||^2 = 0.10691 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 144773.863 - ||grad||^2 = 0.11067 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 144773.867 - ||grad||^2 = 0.10078 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 144773.863 - ||grad||^2 = 0.09402 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 144773.867 - ||grad||^2 = 0.11225 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 144773.863 - ||grad||^2 = 0.10216 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 144773.867 - ||grad||^2 = 0.10581 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 144773.863 - ||grad||^2 = 0.10853 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 144773.867 - ||grad||^2 = 0.10528 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 144773.863 - ||grad||^2 = 0.11056 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 144773.867 - ||grad||^2 = 0.09224 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 144773.863 - ||grad||^2 = 0.10557 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 144773.867 - ||grad||^2 = 0.11992 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 144773.863 - ||grad||^2 = 0.10527 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 144773.867 - ||grad||^2 = 0.10498 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 144773.862 - ||grad||^2 = 0.11358 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 144773.868 - ||grad||^2 = 0.10493 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 144773.863 - ||grad||^2 = 0.10096 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 144773.867 - ||grad||^2 = 0.11310 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 144773.864 - ||grad||^2 = 0.09703 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 144773.866 - ||grad||^2 = 0.10138 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 144773.864 - ||grad||^2 = 0.10116 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 144773.867 - ||grad||^2 = 0.09264 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 144773.863 - ||grad||^2 = 0.10068 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 144773.867 - ||grad||^2 = 0.11703 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 144773.863 - ||grad||^2 = 0.10283 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 144773.867 - ||grad||^2 = 0.10539 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 144773.863 - ||grad||^2 = 0.10414 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 144773.867 - ||grad||^2 = 0.10370 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 144773.863 - ||grad||^2 = 0.11546 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 144773.867 - ||grad||^2 = 0.12193 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 144773.863 - ||grad||^2 = 0.10398 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 144773.867 - ||grad||^2 = 0.10527 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662167301124,"user_tz":-540,"elapsed":20,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"a5731b3a-fb13-4f63-efc4-9da76256881e","id":"1VvstSV_3biE"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.811208\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"Ms0aTiJp3biE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-50000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662167301124,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"7816061c-2255-4f26-bc04-37d26d4686ed","id":"YS8rPWo83biE"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-imbal-50000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-bal-5000"],"metadata":{"id":"o_wKi8JsOara"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"Zx_Dj2UPOarb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('//content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-bala-AR12/TGAN-syn-balanceAR-all-in-one-5000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"Ki_f2yEIOarc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"RUdPRRWYOarc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"Qak5Es3DOarc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"Nk1SJ2XsOard"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"_3ZPE43oOard"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"JcQuBarZOard"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"_8JKLOFhOare"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"GTa14X2lOare"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662441429779,"user_tz":-540,"elapsed":25391,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"cf3b2892-ab7f-4efb-c809-9fa9355dcf99","id":"7Nep-0AbOare"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 224510.776 - ||grad||^2 = 244451.76548 - ||diff_w|| = 19.68979\n"," * Iteration #2 - Loss = 57629.245 - ||grad||^2 = 126217.82593 - ||diff_w|| = 8.82544\n"," * Iteration #3 - Loss = 18358.963 - ||grad||^2 = 72992.52614 - ||diff_w|| = 4.76811\n"," * Iteration #4 - Loss = 6373.831 - ||grad||^2 = 41910.76844 - ||diff_w|| = 2.36247\n"," * Iteration #5 - Loss = 3024.120 - ||grad||^2 = 18596.54884 - ||diff_w|| = 0.93165\n"," * Iteration #6 - Loss = 2383.743 - ||grad||^2 = 7218.71708 - ||diff_w|| = 0.36032\n"," * Iteration #7 - Loss = 2320.974 - ||grad||^2 = 2886.37890 - ||diff_w|| = 0.15738\n"," * Iteration #8 - Loss = 2314.951 - ||grad||^2 = 1099.32474 - ||diff_w|| = 0.07090\n"," * Iteration #9 - Loss = 2314.749 - ||grad||^2 = 405.87516 - ||diff_w|| = 0.03144\n"," * Iteration #10 - Loss = 2314.880 - ||grad||^2 = 148.86797 - ||diff_w|| = 0.01432\n"," * Iteration #11 - Loss = 2315.027 - ||grad||^2 = 53.25067 - ||diff_w|| = 0.00676\n"," * Iteration #12 - Loss = 2315.040 - ||grad||^2 = 19.40307 - ||diff_w|| = 0.00333\n"," * Iteration #13 - Loss = 2315.060 - ||grad||^2 = 7.50639 - ||diff_w|| = 0.00169\n"," * Iteration #14 - Loss = 2315.066 - ||grad||^2 = 3.07781 - ||diff_w|| = 0.00089\n"," * Iteration #15 - Loss = 2315.059 - ||grad||^2 = 1.28913 - ||diff_w|| = 0.00048\n"," * Iteration #16 - Loss = 2315.062 - ||grad||^2 = 0.56910 - ||diff_w|| = 0.00026\n"," * Iteration #17 - Loss = 2315.061 - ||grad||^2 = 0.23284 - ||diff_w|| = 0.00014\n"," * Iteration #18 - Loss = 2315.062 - ||grad||^2 = 0.12926 - ||diff_w|| = 0.00008\n"," * Iteration #19 - Loss = 2315.060 - ||grad||^2 = 0.06900 - ||diff_w|| = 0.00004\n"," * Iteration #20 - Loss = 2315.063 - ||grad||^2 = 0.07559 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 2315.060 - ||grad||^2 = 0.06669 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 2315.062 - ||grad||^2 = 0.05326 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 2315.060 - ||grad||^2 = 0.05650 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 2315.063 - ||grad||^2 = 0.06788 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 2315.060 - ||grad||^2 = 0.06785 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 2315.062 - ||grad||^2 = 0.06785 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 2315.060 - ||grad||^2 = 0.06198 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 2315.063 - ||grad||^2 = 0.06504 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 2315.060 - ||grad||^2 = 0.06745 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 2315.062 - ||grad||^2 = 0.05121 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 2315.060 - ||grad||^2 = 0.05824 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 2315.063 - ||grad||^2 = 0.06737 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 2315.060 - ||grad||^2 = 0.06806 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 2315.062 - ||grad||^2 = 0.06384 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 2315.060 - ||grad||^2 = 0.06176 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 2315.063 - ||grad||^2 = 0.06972 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 2315.060 - ||grad||^2 = 0.06728 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 2315.063 - ||grad||^2 = 0.06388 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 2315.060 - ||grad||^2 = 0.05585 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 2315.062 - ||grad||^2 = 0.04947 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 2315.060 - ||grad||^2 = 0.06109 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 2315.063 - ||grad||^2 = 0.06945 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 2315.060 - ||grad||^2 = 0.06681 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 2315.062 - ||grad||^2 = 0.07495 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 2315.060 - ||grad||^2 = 0.06436 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 2315.063 - ||grad||^2 = 0.05919 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 2315.060 - ||grad||^2 = 0.06663 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 2315.062 - ||grad||^2 = 0.05140 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 2315.060 - ||grad||^2 = 0.05778 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 2315.063 - ||grad||^2 = 0.06755 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 2315.060 - ||grad||^2 = 0.06794 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 2315.062 - ||grad||^2 = 0.06387 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 2315.060 - ||grad||^2 = 0.06175 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 2315.063 - ||grad||^2 = 0.06975 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 2315.060 - ||grad||^2 = 0.06727 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 2315.063 - ||grad||^2 = 0.06388 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 2315.060 - ||grad||^2 = 0.05585 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 2315.062 - ||grad||^2 = 0.04947 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 2315.060 - ||grad||^2 = 0.06109 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 2315.063 - ||grad||^2 = 0.06945 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 2315.060 - ||grad||^2 = 0.06681 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 2315.062 - ||grad||^2 = 0.07495 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 2315.060 - ||grad||^2 = 0.06436 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 2315.063 - ||grad||^2 = 0.05919 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 2315.060 - ||grad||^2 = 0.06663 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 2315.062 - ||grad||^2 = 0.05140 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 2315.060 - ||grad||^2 = 0.05778 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 2315.063 - ||grad||^2 = 0.06755 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 2315.060 - ||grad||^2 = 0.06794 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 2315.062 - ||grad||^2 = 0.06387 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 2315.060 - ||grad||^2 = 0.06175 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 2315.063 - ||grad||^2 = 0.06975 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 2315.060 - ||grad||^2 = 0.06727 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 2315.063 - ||grad||^2 = 0.06388 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 2315.060 - ||grad||^2 = 0.05585 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 2315.062 - ||grad||^2 = 0.04947 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 2315.060 - ||grad||^2 = 0.06109 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 2315.063 - ||grad||^2 = 0.06945 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 2315.060 - ||grad||^2 = 0.06681 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 2315.062 - ||grad||^2 = 0.07495 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 2315.060 - ||grad||^2 = 0.06436 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 2315.063 - ||grad||^2 = 0.05919 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 2315.060 - ||grad||^2 = 0.06663 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 2315.062 - ||grad||^2 = 0.05140 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 2315.060 - ||grad||^2 = 0.05778 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 2315.063 - ||grad||^2 = 0.06755 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 2315.060 - ||grad||^2 = 0.06794 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 2315.062 - ||grad||^2 = 0.06387 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 2315.060 - ||grad||^2 = 0.06175 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 2315.063 - ||grad||^2 = 0.06975 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 2315.060 - ||grad||^2 = 0.06727 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 2315.063 - ||grad||^2 = 0.06388 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 2315.060 - ||grad||^2 = 0.05585 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 2315.062 - ||grad||^2 = 0.04947 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 2315.060 - ||grad||^2 = 0.06109 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 2315.063 - ||grad||^2 = 0.06945 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 2315.060 - ||grad||^2 = 0.06681 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 2315.062 - ||grad||^2 = 0.07495 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 2315.060 - ||grad||^2 = 0.06436 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 2315.063 - ||grad||^2 = 0.05919 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662441429779,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"40ccd469-aed1-4740-c4d8-1273307876a0","id":"KiWAtHZ_Oare"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.829151\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"sycZcEgiOare"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-5000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662441430155,"user_tz":-540,"elapsed":378,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"a515d858-cec2-4a7b-89b3-20cbbc6580b9","id":"Jtgzt7kIOare"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-5000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-bal-10000"],"metadata":{"id":"ihweQnzuOp6j"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"rqrCKtJIOp6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('//content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-bala-AR12/TGAN-syn-balanceAR-all-in-one-10000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"MXhys0AfOp6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"M828xN5uOp6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"YxvRlWtrOp6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"1q6nZY2COp6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"U09dF8WIOp6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"oGlnyZHYOp6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"fOTMjLfiOp6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"DWAx4wSaOp6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Zc6JC4-Op6k","executionInfo":{"status":"ok","timestamp":1662441587682,"user_tz":-540,"elapsed":84296,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"3c8b744e-03c3-40a9-c780-3321a5b83339"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 607933.691 - ||grad||^2 = 885780.07928 - ||diff_w|| = 14.24531\n"," * Iteration #2 - Loss = 159232.596 - ||grad||^2 = 462922.68343 - ||diff_w|| = 6.36933\n"," * Iteration #3 - Loss = 52791.159 - ||grad||^2 = 272734.20389 - ||diff_w|| = 3.38912\n"," * Iteration #4 - Loss = 19963.826 - ||grad||^2 = 157614.96015 - ||diff_w|| = 1.54245\n"," * Iteration #5 - Loss = 10728.212 - ||grad||^2 = 63650.93927 - ||diff_w|| = 0.46589\n"," * Iteration #6 - Loss = 9161.648 - ||grad||^2 = 19891.62542 - ||diff_w|| = 0.17196\n"," * Iteration #7 - Loss = 9086.566 - ||grad||^2 = 8039.12211 - ||diff_w|| = 0.07742\n"," * Iteration #8 - Loss = 9081.070 - ||grad||^2 = 3034.86461 - ||diff_w|| = 0.03376\n"," * Iteration #9 - Loss = 9080.209 - ||grad||^2 = 1189.43457 - ||diff_w|| = 0.01421\n"," * Iteration #10 - Loss = 9079.982 - ||grad||^2 = 533.12503 - ||diff_w|| = 0.00673\n"," * Iteration #11 - Loss = 9079.725 - ||grad||^2 = 249.76003 - ||diff_w|| = 0.00334\n"," * Iteration #12 - Loss = 9079.654 - ||grad||^2 = 127.30930 - ||diff_w|| = 0.00169\n"," * Iteration #13 - Loss = 9079.639 - ||grad||^2 = 64.83938 - ||diff_w|| = 0.00088\n"," * Iteration #14 - Loss = 9079.616 - ||grad||^2 = 33.27417 - ||diff_w|| = 0.00047\n"," * Iteration #15 - Loss = 9079.612 - ||grad||^2 = 17.10313 - ||diff_w|| = 0.00025\n"," * Iteration #16 - Loss = 9079.608 - ||grad||^2 = 8.87171 - ||diff_w|| = 0.00013\n"," * Iteration #17 - Loss = 9079.603 - ||grad||^2 = 4.52207 - ||diff_w|| = 0.00007\n"," * Iteration #18 - Loss = 9079.600 - ||grad||^2 = 2.34451 - ||diff_w|| = 0.00004\n"," * Iteration #19 - Loss = 9079.602 - ||grad||^2 = 1.29560 - ||diff_w|| = 0.00002\n"," * Iteration #20 - Loss = 9079.600 - ||grad||^2 = 0.64935 - ||diff_w|| = 0.00001\n"," * Iteration #21 - Loss = 9079.601 - ||grad||^2 = 0.36930 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 9079.601 - ||grad||^2 = 0.20069 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 9079.600 - ||grad||^2 = 0.13360 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 9079.601 - ||grad||^2 = 0.08403 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 9079.600 - ||grad||^2 = 0.08133 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 9079.601 - ||grad||^2 = 0.10292 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 9079.600 - ||grad||^2 = 0.10407 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 9079.601 - ||grad||^2 = 0.08989 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 9079.600 - ||grad||^2 = 0.07795 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 9079.601 - ||grad||^2 = 0.09886 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 9079.600 - ||grad||^2 = 0.10633 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 9079.600 - ||grad||^2 = 0.07443 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 9079.601 - ||grad||^2 = 0.05271 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 9079.600 - ||grad||^2 = 0.03713 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 9079.600 - ||grad||^2 = 0.03830 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 9079.600 - ||grad||^2 = 0.03229 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 9079.601 - ||grad||^2 = 0.07060 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 9079.601 - ||grad||^2 = 0.09740 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 9079.600 - ||grad||^2 = 0.07856 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 9079.601 - ||grad||^2 = 0.08195 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 9079.600 - ||grad||^2 = 0.07228 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 9079.601 - ||grad||^2 = 0.06277 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 9079.600 - ||grad||^2 = 0.07761 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 9079.600 - ||grad||^2 = 0.04640 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 9079.600 - ||grad||^2 = 0.02576 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 9079.600 - ||grad||^2 = 0.05043 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 9079.600 - ||grad||^2 = 0.03878 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 9079.600 - ||grad||^2 = 0.04708 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 9079.601 - ||grad||^2 = 0.07981 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 9079.601 - ||grad||^2 = 0.09995 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 9079.600 - ||grad||^2 = 0.10520 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 9079.600 - ||grad||^2 = 0.09017 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 9079.601 - ||grad||^2 = 0.09203 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 9079.601 - ||grad||^2 = 0.05766 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 9079.599 - ||grad||^2 = 0.04467 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 9079.601 - ||grad||^2 = 0.03329 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 9079.600 - ||grad||^2 = 0.04348 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 9079.601 - ||grad||^2 = 0.04319 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 9079.599 - ||grad||^2 = 0.05917 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 9079.602 - ||grad||^2 = 0.09071 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 9079.599 - ||grad||^2 = 0.08994 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 9079.602 - ||grad||^2 = 0.07567 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 9079.599 - ||grad||^2 = 0.09296 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 9079.602 - ||grad||^2 = 0.08751 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 9079.599 - ||grad||^2 = 0.06279 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 9079.601 - ||grad||^2 = 0.05906 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 9079.600 - ||grad||^2 = 0.05121 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 9079.601 - ||grad||^2 = 0.04437 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 9079.599 - ||grad||^2 = 0.07406 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 9079.602 - ||grad||^2 = 0.08934 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 9079.599 - ||grad||^2 = 0.07207 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 9079.602 - ||grad||^2 = 0.08772 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 9079.599 - ||grad||^2 = 0.09630 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 9079.602 - ||grad||^2 = 0.07853 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 9079.600 - ||grad||^2 = 0.05827 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 9079.601 - ||grad||^2 = 0.05736 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 9079.600 - ||grad||^2 = 0.07238 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 9079.601 - ||grad||^2 = 0.07214 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 9079.600 - ||grad||^2 = 0.05958 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 9079.602 - ||grad||^2 = 0.06592 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 9079.599 - ||grad||^2 = 0.09731 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 9079.602 - ||grad||^2 = 0.08410 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 9079.599 - ||grad||^2 = 0.08688 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 9079.602 - ||grad||^2 = 0.08996 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 9079.599 - ||grad||^2 = 0.07124 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 9079.601 - ||grad||^2 = 0.04820 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 9079.600 - ||grad||^2 = 0.04594 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 9079.601 - ||grad||^2 = 0.04249 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 9079.599 - ||grad||^2 = 0.05935 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 9079.602 - ||grad||^2 = 0.09085 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 9079.599 - ||grad||^2 = 0.09008 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 9079.602 - ||grad||^2 = 0.07562 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 9079.599 - ||grad||^2 = 0.09299 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 9079.602 - ||grad||^2 = 0.08749 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 9079.599 - ||grad||^2 = 0.06281 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 9079.601 - ||grad||^2 = 0.05906 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 9079.600 - ||grad||^2 = 0.05121 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 9079.601 - ||grad||^2 = 0.04437 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 9079.599 - ||grad||^2 = 0.07406 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 9079.602 - ||grad||^2 = 0.08933 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WXNDhozUOp6k","executionInfo":{"status":"ok","timestamp":1662441587682,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"0e2769e5-26f1-400f-ca5d-175528c40a72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.828831\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"WCYkETNoOp6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-10000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TRIaXyqFOp6k","executionInfo":{"status":"ok","timestamp":1662441588056,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"b454bbc3-8538-40fe-dc58-a8141b3ae9cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-10000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-bal-15000"],"metadata":{"id":"hgEfTX1fOxBd"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"MhJ9u_zGOxBe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('//content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-bala-AR12/TGAN-syn-balanceAR-all-in-one-15000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"5T8_6W0TOxBe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"gU5rCjsYOxBe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"Ycg8OmsUOxBe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"GOYWELvqOxBe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"K2fQHYcUOxBe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"5U5Bw_q_OxBf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"IzkkqptLOxBf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"mWHwOPEGOxBf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6nU93nEcOxBf","executionInfo":{"status":"ok","timestamp":1662441868751,"user_tz":-540,"elapsed":179780,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"7f7c3e98-8bce-4e12-9346-adbf2360aade"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 2730292.212 - ||grad||^2 = 4449011.00198 - ||diff_w|| = 15.31328\n"," * Iteration #2 - Loss = 691668.998 - ||grad||^2 = 2254843.31014 - ||diff_w|| = 6.86710\n"," * Iteration #3 - Loss = 213340.985 - ||grad||^2 = 1258438.70540 - ||diff_w|| = 3.71780\n"," * Iteration #4 - Loss = 68175.352 - ||grad||^2 = 682708.07315 - ||diff_w|| = 1.87694\n"," * Iteration #5 - Loss = 28573.760 - ||grad||^2 = 332114.83956 - ||diff_w|| = 0.77577\n"," * Iteration #6 - Loss = 21462.682 - ||grad||^2 = 140214.79859 - ||diff_w|| = 0.36143\n"," * Iteration #7 - Loss = 20652.048 - ||grad||^2 = 48358.12991 - ||diff_w|| = 0.16251\n"," * Iteration #8 - Loss = 20552.344 - ||grad||^2 = 16548.06794 - ||diff_w|| = 0.06844\n"," * Iteration #9 - Loss = 20540.234 - ||grad||^2 = 5883.01360 - ||diff_w|| = 0.02652\n"," * Iteration #10 - Loss = 20539.398 - ||grad||^2 = 2286.50540 - ||diff_w|| = 0.01035\n"," * Iteration #11 - Loss = 20537.731 - ||grad||^2 = 939.58506 - ||diff_w|| = 0.00430\n"," * Iteration #12 - Loss = 20537.248 - ||grad||^2 = 414.33750 - ||diff_w|| = 0.00190\n"," * Iteration #13 - Loss = 20537.032 - ||grad||^2 = 189.24489 - ||diff_w|| = 0.00090\n"," * Iteration #14 - Loss = 20536.975 - ||grad||^2 = 88.91434 - ||diff_w|| = 0.00044\n"," * Iteration #15 - Loss = 20536.947 - ||grad||^2 = 43.29294 - ||diff_w|| = 0.00023\n"," * Iteration #16 - Loss = 20536.929 - ||grad||^2 = 21.36577 - ||diff_w|| = 0.00012\n"," * Iteration #17 - Loss = 20536.926 - ||grad||^2 = 10.76955 - ||diff_w|| = 0.00006\n"," * Iteration #18 - Loss = 20536.916 - ||grad||^2 = 5.23371 - ||diff_w|| = 0.00003\n"," * Iteration #19 - Loss = 20536.913 - ||grad||^2 = 2.48647 - ||diff_w|| = 0.00002\n"," * Iteration #20 - Loss = 20536.913 - ||grad||^2 = 1.22899 - ||diff_w|| = 0.00001\n"," * Iteration #21 - Loss = 20536.913 - ||grad||^2 = 0.65036 - ||diff_w|| = 0.00000\n"," * Iteration #22 - Loss = 20536.913 - ||grad||^2 = 0.31939 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 20536.912 - ||grad||^2 = 0.13916 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 20536.913 - ||grad||^2 = 0.09010 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 20536.912 - ||grad||^2 = 0.03655 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 20536.913 - ||grad||^2 = 0.03907 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 20536.912 - ||grad||^2 = 0.02123 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 20536.913 - ||grad||^2 = 0.01997 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 20536.912 - ||grad||^2 = 0.01643 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 20536.914 - ||grad||^2 = 0.03885 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 20536.912 - ||grad||^2 = 0.03142 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 20536.913 - ||grad||^2 = 0.01951 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 20536.912 - ||grad||^2 = 0.02586 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 20536.914 - ||grad||^2 = 0.05387 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 20536.911 - ||grad||^2 = 0.06409 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 20536.914 - ||grad||^2 = 0.05291 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 20536.911 - ||grad||^2 = 0.04991 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 20536.914 - ||grad||^2 = 0.04709 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 20536.911 - ||grad||^2 = 0.05698 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 20536.914 - ||grad||^2 = 0.05689 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 20536.912 - ||grad||^2 = 0.03423 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 20536.913 - ||grad||^2 = 0.02728 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 20536.912 - ||grad||^2 = 0.02612 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 20536.913 - ||grad||^2 = 0.01932 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 20536.912 - ||grad||^2 = 0.01734 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 20536.913 - ||grad||^2 = 0.02803 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 20536.912 - ||grad||^2 = 0.02111 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 20536.913 - ||grad||^2 = 0.02290 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 20536.912 - ||grad||^2 = 0.01856 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 20536.913 - ||grad||^2 = 0.02854 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 20536.912 - ||grad||^2 = 0.02132 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 20536.913 - ||grad||^2 = 0.01734 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 20536.912 - ||grad||^2 = 0.01695 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 20536.914 - ||grad||^2 = 0.04219 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 20536.911 - ||grad||^2 = 0.04351 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 20536.914 - ||grad||^2 = 0.04085 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 20536.911 - ||grad||^2 = 0.05561 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 20536.914 - ||grad||^2 = 0.04705 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 20536.911 - ||grad||^2 = 0.05625 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 20536.914 - ||grad||^2 = 0.05050 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 20536.911 - ||grad||^2 = 0.05365 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 20536.914 - ||grad||^2 = 0.06064 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 20536.911 - ||grad||^2 = 0.04811 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 20536.913 - ||grad||^2 = 0.03764 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 20536.912 - ||grad||^2 = 0.02884 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 20536.913 - ||grad||^2 = 0.02851 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 20536.912 - ||grad||^2 = 0.02607 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 20536.914 - ||grad||^2 = 0.05458 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 20536.911 - ||grad||^2 = 0.06340 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 20536.914 - ||grad||^2 = 0.05290 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 20536.911 - ||grad||^2 = 0.05002 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 20536.914 - ||grad||^2 = 0.04698 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 20536.911 - ||grad||^2 = 0.04657 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 20536.914 - ||grad||^2 = 0.04672 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 20536.911 - ||grad||^2 = 0.05350 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 20536.914 - ||grad||^2 = 0.05169 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 20536.911 - ||grad||^2 = 0.05728 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 20536.914 - ||grad||^2 = 0.04480 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 20536.911 - ||grad||^2 = 0.04276 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 20536.914 - ||grad||^2 = 0.05813 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 20536.911 - ||grad||^2 = 0.05923 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 20536.914 - ||grad||^2 = 0.04506 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 20536.912 - ||grad||^2 = 0.02465 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 20536.912 - ||grad||^2 = 0.01708 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 20536.913 - ||grad||^2 = 0.01526 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 20536.913 - ||grad||^2 = 0.01728 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 20536.912 - ||grad||^2 = 0.02055 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 20536.913 - ||grad||^2 = 0.02845 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 20536.912 - ||grad||^2 = 0.02211 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 20536.912 - ||grad||^2 = 0.01654 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 20536.913 - ||grad||^2 = 0.02677 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 20536.912 - ||grad||^2 = 0.04115 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 20536.914 - ||grad||^2 = 0.05175 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 20536.911 - ||grad||^2 = 0.04988 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 20536.914 - ||grad||^2 = 0.04866 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 20536.912 - ||grad||^2 = 0.03800 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 20536.913 - ||grad||^2 = 0.03808 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 20536.912 - ||grad||^2 = 0.02822 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 20536.913 - ||grad||^2 = 0.02858 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 20536.912 - ||grad||^2 = 0.03719 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-0ikyw7mOxBf","executionInfo":{"status":"ok","timestamp":1662441868751,"user_tz":-540,"elapsed":16,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"64ee35ce-a06f-4a5d-c4ef-105340e60317"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.831292\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"RJ3uLErQOxBf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-15000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TBwCeTmGOxBf","executionInfo":{"status":"ok","timestamp":1662441868753,"user_tz":-540,"elapsed":16,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"22278af6-2faf-40ff-a0ab-e129773556d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-15000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-bal-20000"],"metadata":{"id":"yzB9UWFZO3Qc"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"LAa0CHRbO3Qd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('//content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-bala-AR12/TGAN-syn-balanceAR-all-in-one-20000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"_aARc2kOO3Qe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"Z-iGYeg3O3Qe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"uZeFLSjKO3Qe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"iC_P4alNO3Qe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"Y1PgQoKFO3Qe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"v_laLg1wO3Qf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"maNv1b5oO3Qf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"Cu8vPMeeO3Qf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kaOKQK_-O3Qf","executionInfo":{"status":"ok","timestamp":1662442228844,"user_tz":-540,"elapsed":322581,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"a1ac83c3-ead0-4cb8-f175-c3383f1a8df7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 3048455.282 - ||grad||^2 = 6224360.02327 - ||diff_w|| = 14.32122\n"," * Iteration #2 - Loss = 774595.981 - ||grad||^2 = 3162981.75133 - ||diff_w|| = 6.39161\n"," * Iteration #3 - Loss = 242397.825 - ||grad||^2 = 1763339.95828 - ||diff_w|| = 3.37600\n"," * Iteration #4 - Loss = 83864.950 - ||grad||^2 = 945843.67720 - ||diff_w|| = 1.54992\n"," * Iteration #5 - Loss = 43800.229 - ||grad||^2 = 476706.00065 - ||diff_w|| = 0.67930\n"," * Iteration #6 - Loss = 37219.386 - ||grad||^2 = 188254.31099 - ||diff_w|| = 0.33241\n"," * Iteration #7 - Loss = 36561.844 - ||grad||^2 = 66424.08732 - ||diff_w|| = 0.13910\n"," * Iteration #8 - Loss = 36356.485 - ||grad||^2 = 23612.60097 - ||diff_w|| = 0.05567\n"," * Iteration #9 - Loss = 36360.952 - ||grad||^2 = 7783.21745 - ||diff_w|| = 0.02163\n"," * Iteration #10 - Loss = 36367.148 - ||grad||^2 = 2413.42350 - ||diff_w|| = 0.00767\n"," * Iteration #11 - Loss = 36368.823 - ||grad||^2 = 837.96493 - ||diff_w|| = 0.00303\n"," * Iteration #12 - Loss = 36368.649 - ||grad||^2 = 330.05114 - ||diff_w|| = 0.00138\n"," * Iteration #13 - Loss = 36368.505 - ||grad||^2 = 136.48301 - ||diff_w|| = 0.00066\n"," * Iteration #14 - Loss = 36368.443 - ||grad||^2 = 62.47812 - ||diff_w|| = 0.00034\n"," * Iteration #15 - Loss = 36368.430 - ||grad||^2 = 31.05866 - ||diff_w|| = 0.00018\n"," * Iteration #16 - Loss = 36368.420 - ||grad||^2 = 15.81267 - ||diff_w|| = 0.00010\n"," * Iteration #17 - Loss = 36368.415 - ||grad||^2 = 7.89198 - ||diff_w|| = 0.00005\n"," * Iteration #18 - Loss = 36368.411 - ||grad||^2 = 4.03375 - ||diff_w|| = 0.00003\n"," * Iteration #19 - Loss = 36368.413 - ||grad||^2 = 2.05238 - ||diff_w|| = 0.00001\n"," * Iteration #20 - Loss = 36368.410 - ||grad||^2 = 1.01992 - ||diff_w|| = 0.00001\n"," * Iteration #21 - Loss = 36368.410 - ||grad||^2 = 0.53703 - ||diff_w|| = 0.00000\n"," * Iteration #22 - Loss = 36368.411 - ||grad||^2 = 0.31070 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 36368.410 - ||grad||^2 = 0.18173 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 36368.411 - ||grad||^2 = 0.09392 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 36368.409 - ||grad||^2 = 0.07422 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 36368.411 - ||grad||^2 = 0.07521 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 36368.409 - ||grad||^2 = 0.08134 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 36368.411 - ||grad||^2 = 0.09406 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 36368.409 - ||grad||^2 = 0.08601 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 36368.411 - ||grad||^2 = 0.08386 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 36368.409 - ||grad||^2 = 0.08979 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 36368.410 - ||grad||^2 = 0.07613 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 36368.410 - ||grad||^2 = 0.07272 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 36368.410 - ||grad||^2 = 0.06077 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 36368.410 - ||grad||^2 = 0.04714 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 36368.410 - ||grad||^2 = 0.04640 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 36368.410 - ||grad||^2 = 0.05092 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 36368.410 - ||grad||^2 = 0.05771 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 36368.410 - ||grad||^2 = 0.06982 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 36368.410 - ||grad||^2 = 0.07785 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 36368.409 - ||grad||^2 = 0.08339 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 36368.411 - ||grad||^2 = 0.09710 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 36368.409 - ||grad||^2 = 0.09502 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 36368.410 - ||grad||^2 = 0.06248 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 36368.410 - ||grad||^2 = 0.06527 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 36368.410 - ||grad||^2 = 0.05610 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 36368.410 - ||grad||^2 = 0.05690 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 36368.410 - ||grad||^2 = 0.07414 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 36368.409 - ||grad||^2 = 0.06930 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 36368.411 - ||grad||^2 = 0.08760 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 36368.409 - ||grad||^2 = 0.08839 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 36368.410 - ||grad||^2 = 0.06797 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 36368.410 - ||grad||^2 = 0.06705 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 36368.410 - ||grad||^2 = 0.05866 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 36368.410 - ||grad||^2 = 0.06039 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 36368.410 - ||grad||^2 = 0.07253 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 36368.410 - ||grad||^2 = 0.07421 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 36368.410 - ||grad||^2 = 0.05977 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 36368.410 - ||grad||^2 = 0.05242 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 36368.410 - ||grad||^2 = 0.05337 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 36368.410 - ||grad||^2 = 0.06823 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 36368.410 - ||grad||^2 = 0.07182 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 36368.409 - ||grad||^2 = 0.08166 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 36368.411 - ||grad||^2 = 0.09735 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 36368.409 - ||grad||^2 = 0.09489 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 36368.410 - ||grad||^2 = 0.06766 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 36368.410 - ||grad||^2 = 0.06805 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 36368.410 - ||grad||^2 = 0.05996 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 36368.410 - ||grad||^2 = 0.04738 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 36368.411 - ||grad||^2 = 0.06482 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 36368.409 - ||grad||^2 = 0.05748 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 36368.410 - ||grad||^2 = 0.06793 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 36368.410 - ||grad||^2 = 0.07429 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 36368.410 - ||grad||^2 = 0.06074 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 36368.410 - ||grad||^2 = 0.06502 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 36368.411 - ||grad||^2 = 0.07323 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 36368.409 - ||grad||^2 = 0.08072 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 36368.411 - ||grad||^2 = 0.08727 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 36368.409 - ||grad||^2 = 0.07952 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 36368.410 - ||grad||^2 = 0.07319 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 36368.410 - ||grad||^2 = 0.06700 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 36368.410 - ||grad||^2 = 0.05708 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 36368.410 - ||grad||^2 = 0.05423 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 36368.410 - ||grad||^2 = 0.05442 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 36368.410 - ||grad||^2 = 0.07046 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 36368.410 - ||grad||^2 = 0.07718 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 36368.409 - ||grad||^2 = 0.08386 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 36368.411 - ||grad||^2 = 0.09696 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 36368.409 - ||grad||^2 = 0.09510 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 36368.410 - ||grad||^2 = 0.06238 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 36368.410 - ||grad||^2 = 0.06530 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 36368.410 - ||grad||^2 = 0.05608 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 36368.410 - ||grad||^2 = 0.05691 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 36368.410 - ||grad||^2 = 0.07413 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 36368.409 - ||grad||^2 = 0.06931 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 36368.411 - ||grad||^2 = 0.08760 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 36368.409 - ||grad||^2 = 0.08839 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 36368.410 - ||grad||^2 = 0.06796 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 36368.410 - ||grad||^2 = 0.06705 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 36368.410 - ||grad||^2 = 0.05866 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p9ZwuC1uO3Qf","executionInfo":{"status":"ok","timestamp":1662442228845,"user_tz":-540,"elapsed":25,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"dd4a7fca-4b6f-455b-98bb-7c33d80d3c9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.829328\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"Ue9fiVAwO3Qf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-20000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kB2j618QO3Qf","executionInfo":{"status":"ok","timestamp":1662442228845,"user_tz":-540,"elapsed":19,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"7d57751c-edd0-482b-f418-1fb7a69d8921"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-20000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-bal-25000"],"metadata":{"id":"XVs0WgYXPCud"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"BS7p9Io8PCud"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('//content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-bala-AR12/TGAN-syn-balanceAR-all-in-one-25000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"YAErhv4SPCue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"-bXajf20PCue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"p8dc9_2EPCue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"Avp4tVcxPCue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"mU9ra49DPCue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"ECdu7K9UPCue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"O-gCIV9cPCue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"n0zO5qmlPCue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ZjuSsIFPCue","executionInfo":{"status":"ok","timestamp":1662442797920,"user_tz":-540,"elapsed":508426,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"a5463071-0027-4999-ead9-e508414823f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 4941513.516 - ||grad||^2 = 8740792.46278 - ||diff_w|| = 16.00825\n"," * Iteration #2 - Loss = 1266781.383 - ||grad||^2 = 4517305.23222 - ||diff_w|| = 6.39477\n"," * Iteration #3 - Loss = 399018.183 - ||grad||^2 = 2551443.93539 - ||diff_w|| = 3.46474\n"," * Iteration #4 - Loss = 137090.188 - ||grad||^2 = 1384643.43991 - ||diff_w|| = 1.70925\n"," * Iteration #5 - Loss = 69538.968 - ||grad||^2 = 605142.37187 - ||diff_w|| = 0.64597\n"," * Iteration #6 - Loss = 59804.540 - ||grad||^2 = 259868.08840 - ||diff_w|| = 0.28746\n"," * Iteration #7 - Loss = 58850.402 - ||grad||^2 = 102973.92609 - ||diff_w|| = 0.13490\n"," * Iteration #8 - Loss = 58788.339 - ||grad||^2 = 38719.73678 - ||diff_w|| = 0.06188\n"," * Iteration #9 - Loss = 58760.902 - ||grad||^2 = 15151.96975 - ||diff_w|| = 0.02931\n"," * Iteration #10 - Loss = 58754.881 - ||grad||^2 = 6350.17720 - ||diff_w|| = 0.01478\n"," * Iteration #11 - Loss = 58752.515 - ||grad||^2 = 2823.76823 - ||diff_w|| = 0.00768\n"," * Iteration #12 - Loss = 58751.488 - ||grad||^2 = 1306.76894 - ||diff_w|| = 0.00405\n"," * Iteration #13 - Loss = 58751.160 - ||grad||^2 = 623.26472 - ||diff_w|| = 0.00217\n"," * Iteration #14 - Loss = 58750.937 - ||grad||^2 = 307.94632 - ||diff_w|| = 0.00117\n"," * Iteration #15 - Loss = 58750.908 - ||grad||^2 = 154.76313 - ||diff_w|| = 0.00064\n"," * Iteration #16 - Loss = 58750.857 - ||grad||^2 = 77.99515 - ||diff_w|| = 0.00035\n"," * Iteration #17 - Loss = 58750.843 - ||grad||^2 = 39.63346 - ||diff_w|| = 0.00019\n"," * Iteration #18 - Loss = 58750.824 - ||grad||^2 = 20.20717 - ||diff_w|| = 0.00010\n"," * Iteration #19 - Loss = 58750.824 - ||grad||^2 = 10.38714 - ||diff_w|| = 0.00006\n"," * Iteration #20 - Loss = 58750.820 - ||grad||^2 = 5.31003 - ||diff_w|| = 0.00003\n"," * Iteration #21 - Loss = 58750.820 - ||grad||^2 = 2.75090 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 58750.819 - ||grad||^2 = 1.43513 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 58750.820 - ||grad||^2 = 0.75491 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 58750.819 - ||grad||^2 = 0.39810 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 58750.819 - ||grad||^2 = 0.21700 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 58750.819 - ||grad||^2 = 0.11067 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 58750.820 - ||grad||^2 = 0.06763 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 58750.818 - ||grad||^2 = 0.04514 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 58750.820 - ||grad||^2 = 0.05697 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 58750.818 - ||grad||^2 = 0.04371 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 58750.820 - ||grad||^2 = 0.04074 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 58750.819 - ||grad||^2 = 0.02524 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 58750.819 - ||grad||^2 = 0.02081 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 58750.819 - ||grad||^2 = 0.03998 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 58750.819 - ||grad||^2 = 0.03682 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 58750.818 - ||grad||^2 = 0.03523 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 58750.820 - ||grad||^2 = 0.05285 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 58750.818 - ||grad||^2 = 0.04713 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 58750.820 - ||grad||^2 = 0.03471 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 58750.819 - ||grad||^2 = 0.03898 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 58750.820 - ||grad||^2 = 0.04039 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 58750.818 - ||grad||^2 = 0.03891 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 58750.820 - ||grad||^2 = 0.03372 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 58750.819 - ||grad||^2 = 0.02452 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 58750.819 - ||grad||^2 = 0.02086 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 58750.819 - ||grad||^2 = 0.03904 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 58750.819 - ||grad||^2 = 0.03718 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 58750.818 - ||grad||^2 = 0.03514 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 58750.820 - ||grad||^2 = 0.05291 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 58750.818 - ||grad||^2 = 0.04711 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 58750.820 - ||grad||^2 = 0.03472 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 58750.819 - ||grad||^2 = 0.03895 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 58750.820 - ||grad||^2 = 0.04040 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 58750.818 - ||grad||^2 = 0.03891 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 58750.820 - ||grad||^2 = 0.03372 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 58750.819 - ||grad||^2 = 0.02452 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 58750.819 - ||grad||^2 = 0.02086 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 58750.819 - ||grad||^2 = 0.03904 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 58750.819 - ||grad||^2 = 0.03718 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 58750.818 - ||grad||^2 = 0.03514 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 58750.820 - ||grad||^2 = 0.05291 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 58750.818 - ||grad||^2 = 0.04711 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 58750.820 - ||grad||^2 = 0.03472 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 58750.819 - ||grad||^2 = 0.03895 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 58750.820 - ||grad||^2 = 0.04040 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 58750.818 - ||grad||^2 = 0.03891 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 58750.820 - ||grad||^2 = 0.03372 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 58750.819 - ||grad||^2 = 0.02452 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 58750.819 - ||grad||^2 = 0.02086 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 58750.819 - ||grad||^2 = 0.03904 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 58750.819 - ||grad||^2 = 0.03718 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 58750.818 - ||grad||^2 = 0.03514 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 58750.820 - ||grad||^2 = 0.05291 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 58750.818 - ||grad||^2 = 0.04711 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 58750.820 - ||grad||^2 = 0.03472 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 58750.819 - ||grad||^2 = 0.03895 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 58750.820 - ||grad||^2 = 0.04040 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 58750.818 - ||grad||^2 = 0.03891 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 58750.820 - ||grad||^2 = 0.03372 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 58750.819 - ||grad||^2 = 0.02452 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 58750.819 - ||grad||^2 = 0.02086 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 58750.819 - ||grad||^2 = 0.03904 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 58750.819 - ||grad||^2 = 0.03718 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 58750.818 - ||grad||^2 = 0.03514 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 58750.820 - ||grad||^2 = 0.05291 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 58750.818 - ||grad||^2 = 0.04711 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 58750.820 - ||grad||^2 = 0.03472 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 58750.819 - ||grad||^2 = 0.03895 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 58750.820 - ||grad||^2 = 0.04040 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 58750.818 - ||grad||^2 = 0.03891 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 58750.820 - ||grad||^2 = 0.03372 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 58750.819 - ||grad||^2 = 0.02452 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 58750.819 - ||grad||^2 = 0.02086 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 58750.819 - ||grad||^2 = 0.03904 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 58750.819 - ||grad||^2 = 0.03718 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 58750.818 - ||grad||^2 = 0.03514 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 58750.820 - ||grad||^2 = 0.05291 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 58750.818 - ||grad||^2 = 0.04711 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 58750.820 - ||grad||^2 = 0.03472 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 58750.819 - ||grad||^2 = 0.03895 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B9hXLHpfPCue","executionInfo":{"status":"ok","timestamp":1662442797921,"user_tz":-540,"elapsed":22,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"9c373bc5-f0f1-4af7-b3a3-f6cfb1090e21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.829097\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"94zer6zZPCue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-25000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dD6aJZ9NPCuf","executionInfo":{"status":"ok","timestamp":1662442797921,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"e0c95783-4d62-45e8-b686-3603d5a044cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-25000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-bal-30000"],"metadata":{"id":"iWWE7a2cPIf6"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"GKzWXXuYPIf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('//content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-bala-AR12/TGAN-syn-balanceAR-all-in-one-30000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"hBh1TlzBPIf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"x52ZrouDPIf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"EMEmof3sPIf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"VJe0FFvcPIf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"BFM1jF2FPIf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"QsJ9B7QSPIf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"8ybMFDvRPIf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"JHYKTj06PIf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Tq3amgEPIf7","executionInfo":{"status":"ok","timestamp":1662443584456,"user_tz":-540,"elapsed":729186,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"72323e25-1ee3-4cd7-d305-c80b51421a95"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 12850433.167 - ||grad||^2 = 22183218.61383 - ||diff_w|| = 15.25584\n"," * Iteration #2 - Loss = 3269009.179 - ||grad||^2 = 11297951.34272 - ||diff_w|| = 6.83850\n"," * Iteration #3 - Loss = 1017914.772 - ||grad||^2 = 6372091.17640 - ||diff_w|| = 3.69278\n"," * Iteration #4 - Loss = 327744.597 - ||grad||^2 = 3544762.41354 - ||diff_w|| = 1.90102\n"," * Iteration #5 - Loss = 126228.406 - ||grad||^2 = 1652505.48772 - ||diff_w|| = 0.84188\n"," * Iteration #6 - Loss = 86022.732 - ||grad||^2 = 752819.65775 - ||diff_w|| = 0.36415\n"," * Iteration #7 - Loss = 80543.423 - ||grad||^2 = 299902.28540 - ||diff_w|| = 0.15934\n"," * Iteration #8 - Loss = 80621.713 - ||grad||^2 = 102153.31298 - ||diff_w|| = 0.06197\n"," * Iteration #9 - Loss = 80681.996 - ||grad||^2 = 35662.84857 - ||diff_w|| = 0.02493\n"," * Iteration #10 - Loss = 80671.865 - ||grad||^2 = 13660.40833 - ||diff_w|| = 0.01177\n"," * Iteration #11 - Loss = 80667.113 - ||grad||^2 = 5695.92374 - ||diff_w|| = 0.00611\n"," * Iteration #12 - Loss = 80663.639 - ||grad||^2 = 2536.31573 - ||diff_w|| = 0.00323\n"," * Iteration #13 - Loss = 80662.944 - ||grad||^2 = 1179.05462 - ||diff_w|| = 0.00173\n"," * Iteration #14 - Loss = 80662.496 - ||grad||^2 = 565.69008 - ||diff_w|| = 0.00093\n"," * Iteration #15 - Loss = 80662.307 - ||grad||^2 = 276.83787 - ||diff_w|| = 0.00050\n"," * Iteration #16 - Loss = 80662.216 - ||grad||^2 = 137.44071 - ||diff_w|| = 0.00027\n"," * Iteration #17 - Loss = 80662.160 - ||grad||^2 = 69.01653 - ||diff_w|| = 0.00015\n"," * Iteration #18 - Loss = 80662.136 - ||grad||^2 = 34.88252 - ||diff_w|| = 0.00008\n"," * Iteration #19 - Loss = 80662.124 - ||grad||^2 = 17.56907 - ||diff_w|| = 0.00004\n"," * Iteration #20 - Loss = 80662.126 - ||grad||^2 = 9.07354 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 80662.118 - ||grad||^2 = 4.56692 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 80662.118 - ||grad||^2 = 2.35800 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 80662.118 - ||grad||^2 = 1.24435 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 80662.118 - ||grad||^2 = 0.65204 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 80662.118 - ||grad||^2 = 0.37417 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 80662.118 - ||grad||^2 = 0.20465 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 80662.117 - ||grad||^2 = 0.09451 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 80662.117 - ||grad||^2 = 0.05103 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 80662.117 - ||grad||^2 = 0.04118 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 80662.118 - ||grad||^2 = 0.03593 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 80662.116 - ||grad||^2 = 0.04205 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 80662.118 - ||grad||^2 = 0.05004 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 80662.118 - ||grad||^2 = 0.08227 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 80662.118 - ||grad||^2 = 0.06589 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 80662.117 - ||grad||^2 = 0.06970 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 80662.118 - ||grad||^2 = 0.06493 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 80662.118 - ||grad||^2 = 0.05391 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 80662.117 - ||grad||^2 = 0.05058 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 80662.117 - ||grad||^2 = 0.05491 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 80662.118 - ||grad||^2 = 0.07158 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 80662.117 - ||grad||^2 = 0.08718 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 80662.118 - ||grad||^2 = 0.06174 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 80662.118 - ||grad||^2 = 0.05711 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 80662.117 - ||grad||^2 = 0.05600 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 80662.119 - ||grad||^2 = 0.07443 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 80662.117 - ||grad||^2 = 0.06599 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 80662.118 - ||grad||^2 = 0.05615 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 80662.117 - ||grad||^2 = 0.05690 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 80662.118 - ||grad||^2 = 0.05366 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 80662.117 - ||grad||^2 = 0.05052 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 80662.117 - ||grad||^2 = 0.04539 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 80662.118 - ||grad||^2 = 0.04958 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 80662.117 - ||grad||^2 = 0.07005 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 80662.118 - ||grad||^2 = 0.06293 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 80662.117 - ||grad||^2 = 0.07216 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 80662.118 - ||grad||^2 = 0.07352 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 80662.118 - ||grad||^2 = 0.07858 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 80662.117 - ||grad||^2 = 0.06813 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 80662.118 - ||grad||^2 = 0.05641 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 80662.117 - ||grad||^2 = 0.05960 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 80662.118 - ||grad||^2 = 0.07092 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 80662.117 - ||grad||^2 = 0.05561 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 80662.118 - ||grad||^2 = 0.06136 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 80662.117 - ||grad||^2 = 0.05964 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 80662.118 - ||grad||^2 = 0.07259 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 80662.117 - ||grad||^2 = 0.06514 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 80662.118 - ||grad||^2 = 0.03921 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 80662.117 - ||grad||^2 = 0.04907 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 80662.118 - ||grad||^2 = 0.04395 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 80662.117 - ||grad||^2 = 0.03557 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 80662.117 - ||grad||^2 = 0.04196 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 80662.118 - ||grad||^2 = 0.05673 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 80662.118 - ||grad||^2 = 0.07975 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 80662.118 - ||grad||^2 = 0.06389 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 80662.117 - ||grad||^2 = 0.07065 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 80662.118 - ||grad||^2 = 0.07472 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 80662.117 - ||grad||^2 = 0.06436 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 80662.118 - ||grad||^2 = 0.04873 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 80662.117 - ||grad||^2 = 0.04523 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 80662.118 - ||grad||^2 = 0.04976 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 80662.117 - ||grad||^2 = 0.06934 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 80662.118 - ||grad||^2 = 0.06303 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 80662.117 - ||grad||^2 = 0.07202 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 80662.118 - ||grad||^2 = 0.07360 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 80662.118 - ||grad||^2 = 0.07853 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 80662.117 - ||grad||^2 = 0.06819 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 80662.118 - ||grad||^2 = 0.05639 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 80662.117 - ||grad||^2 = 0.05960 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 80662.118 - ||grad||^2 = 0.07091 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 80662.117 - ||grad||^2 = 0.05561 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 80662.118 - ||grad||^2 = 0.06136 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 80662.117 - ||grad||^2 = 0.05964 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 80662.118 - ||grad||^2 = 0.07259 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 80662.117 - ||grad||^2 = 0.06514 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 80662.118 - ||grad||^2 = 0.03921 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 80662.117 - ||grad||^2 = 0.04907 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 80662.118 - ||grad||^2 = 0.04395 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 80662.117 - ||grad||^2 = 0.03557 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 80662.117 - ||grad||^2 = 0.04196 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 80662.118 - ||grad||^2 = 0.05673 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Szy96o3PIf8","executionInfo":{"status":"ok","timestamp":1662443584456,"user_tz":-540,"elapsed":25,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"e2e43ba8-5344-45e3-fba0-db257031680d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.830297\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"dXOQZl40PIf8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-30000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjyEeqOCPIf8","executionInfo":{"status":"ok","timestamp":1662443584456,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"a5dc06f7-4f4a-4a86-d0a7-da212504914b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-30000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-bal-35000"],"metadata":{"id":"i4n-x2QSPNXH"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"s0mqP3-UPNXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('//content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-bala-AR12/TGAN-syn-balanceAR-all-in-one-35000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"9FllB3H5PNXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"NAOm9_uSPNXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"rryHsYWdPNXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"EZ95gYH-PNXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"UQBnDeKOPNXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"r3_mAUMiPNXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"45QxuN0-PNXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"bHy-wULnPNXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3nzQg6LKPNXJ","executionInfo":{"status":"ok","timestamp":1662444784546,"user_tz":-540,"elapsed":991511,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"eec70f40-4dcf-4884-90f1-12c467040053"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 9914751.950 - ||grad||^2 = 15175693.83176 - ||diff_w|| = 19.07061\n"," * Iteration #2 - Loss = 2538373.982 - ||grad||^2 = 7708938.01978 - ||diff_w|| = 8.54852\n"," * Iteration #3 - Loss = 804381.959 - ||grad||^2 = 4312523.04383 - ||diff_w|| = 4.60904\n"," * Iteration #4 - Loss = 277819.511 - ||grad||^2 = 2309097.97135 - ||diff_w|| = 2.23292\n"," * Iteration #5 - Loss = 136825.814 - ||grad||^2 = 1078372.73627 - ||diff_w|| = 0.78046\n"," * Iteration #6 - Loss = 114336.663 - ||grad||^2 = 444922.49786 - ||diff_w|| = 0.28368\n"," * Iteration #7 - Loss = 112764.835 - ||grad||^2 = 147322.86196 - ||diff_w|| = 0.11306\n"," * Iteration #8 - Loss = 112482.321 - ||grad||^2 = 50840.51580 - ||diff_w|| = 0.04580\n"," * Iteration #9 - Loss = 112482.417 - ||grad||^2 = 16989.62173 - ||diff_w|| = 0.01801\n"," * Iteration #10 - Loss = 112488.074 - ||grad||^2 = 5806.24787 - ||diff_w|| = 0.00732\n"," * Iteration #11 - Loss = 112489.464 - ||grad||^2 = 2142.77532 - ||diff_w|| = 0.00324\n"," * Iteration #12 - Loss = 112490.062 - ||grad||^2 = 834.76533 - ||diff_w|| = 0.00155\n"," * Iteration #13 - Loss = 112490.056 - ||grad||^2 = 340.74831 - ||diff_w|| = 0.00078\n"," * Iteration #14 - Loss = 112489.998 - ||grad||^2 = 146.86122 - ||diff_w|| = 0.00041\n"," * Iteration #15 - Loss = 112489.968 - ||grad||^2 = 67.01920 - ||diff_w|| = 0.00022\n"," * Iteration #16 - Loss = 112489.964 - ||grad||^2 = 33.27283 - ||diff_w|| = 0.00012\n"," * Iteration #17 - Loss = 112489.947 - ||grad||^2 = 16.67839 - ||diff_w|| = 0.00006\n"," * Iteration #18 - Loss = 112489.944 - ||grad||^2 = 8.57916 - ||diff_w|| = 0.00003\n"," * Iteration #19 - Loss = 112489.943 - ||grad||^2 = 4.41671 - ||diff_w|| = 0.00002\n"," * Iteration #20 - Loss = 112489.941 - ||grad||^2 = 2.14545 - ||diff_w|| = 0.00001\n"," * Iteration #21 - Loss = 112489.939 - ||grad||^2 = 1.13947 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 112489.941 - ||grad||^2 = 0.57876 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 112489.939 - ||grad||^2 = 0.30492 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 112489.940 - ||grad||^2 = 0.18734 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 112489.939 - ||grad||^2 = 0.10953 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 112489.940 - ||grad||^2 = 0.08178 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 112489.939 - ||grad||^2 = 0.05493 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 112489.940 - ||grad||^2 = 0.05133 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 112489.938 - ||grad||^2 = 0.07905 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 112489.941 - ||grad||^2 = 0.10210 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 112489.938 - ||grad||^2 = 0.08660 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 112489.940 - ||grad||^2 = 0.05205 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 112489.939 - ||grad||^2 = 0.05130 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 112489.940 - ||grad||^2 = 0.06178 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 112489.939 - ||grad||^2 = 0.08106 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 112489.941 - ||grad||^2 = 0.08810 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 112489.938 - ||grad||^2 = 0.08258 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 112489.940 - ||grad||^2 = 0.06652 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 112489.939 - ||grad||^2 = 0.05224 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 112489.940 - ||grad||^2 = 0.04728 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 112489.939 - ||grad||^2 = 0.05673 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 112489.940 - ||grad||^2 = 0.07762 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 112489.939 - ||grad||^2 = 0.08709 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 112489.940 - ||grad||^2 = 0.05170 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 112489.939 - ||grad||^2 = 0.06373 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 112489.941 - ||grad||^2 = 0.06085 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 112489.939 - ||grad||^2 = 0.06079 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 112489.941 - ||grad||^2 = 0.07301 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 112489.939 - ||grad||^2 = 0.09086 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 112489.941 - ||grad||^2 = 0.06609 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 112489.939 - ||grad||^2 = 0.06605 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 112489.941 - ||grad||^2 = 0.06117 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 112489.939 - ||grad||^2 = 0.05748 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 112489.940 - ||grad||^2 = 0.06207 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 112489.939 - ||grad||^2 = 0.07087 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 112489.940 - ||grad||^2 = 0.05185 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 112489.939 - ||grad||^2 = 0.05969 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 112489.941 - ||grad||^2 = 0.07483 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 112489.939 - ||grad||^2 = 0.05479 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 112489.941 - ||grad||^2 = 0.05549 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 112489.938 - ||grad||^2 = 0.09325 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 112489.941 - ||grad||^2 = 0.10316 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 112489.938 - ||grad||^2 = 0.08878 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 112489.941 - ||grad||^2 = 0.06222 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 112489.939 - ||grad||^2 = 0.06175 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 112489.941 - ||grad||^2 = 0.08090 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 112489.938 - ||grad||^2 = 0.09788 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 112489.941 - ||grad||^2 = 0.06686 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 112489.939 - ||grad||^2 = 0.06553 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 112489.940 - ||grad||^2 = 0.05572 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 112489.940 - ||grad||^2 = 0.05622 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 112489.940 - ||grad||^2 = 0.05357 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 112489.939 - ||grad||^2 = 0.06329 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 112489.939 - ||grad||^2 = 0.07614 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 112489.940 - ||grad||^2 = 0.07434 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 112489.940 - ||grad||^2 = 0.05693 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 112489.939 - ||grad||^2 = 0.05940 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 112489.941 - ||grad||^2 = 0.05893 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 112489.939 - ||grad||^2 = 0.06915 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 112489.941 - ||grad||^2 = 0.08557 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 112489.938 - ||grad||^2 = 0.09848 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 112489.941 - ||grad||^2 = 0.07619 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 112489.939 - ||grad||^2 = 0.07010 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 112489.941 - ||grad||^2 = 0.07073 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 112489.939 - ||grad||^2 = 0.06698 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 112489.940 - ||grad||^2 = 0.05653 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 112489.939 - ||grad||^2 = 0.08337 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 112489.940 - ||grad||^2 = 0.08189 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 112489.939 - ||grad||^2 = 0.04974 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 112489.940 - ||grad||^2 = 0.04521 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 112489.939 - ||grad||^2 = 0.06635 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 112489.940 - ||grad||^2 = 0.05363 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 112489.939 - ||grad||^2 = 0.05221 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 112489.940 - ||grad||^2 = 0.04816 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 112489.939 - ||grad||^2 = 0.06552 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 112489.941 - ||grad||^2 = 0.07176 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 112489.939 - ||grad||^2 = 0.06518 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 112489.940 - ||grad||^2 = 0.05594 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 112489.940 - ||grad||^2 = 0.05635 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 112489.940 - ||grad||^2 = 0.05345 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KT-Lp1TyPNXJ","executionInfo":{"status":"ok","timestamp":1662444784547,"user_tz":-540,"elapsed":26,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"d0652575-369b-472d-c60a-2dc748418fec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.829115\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"pvS8BahCPNXJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-35000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5KSoEshmPNXJ","executionInfo":{"status":"ok","timestamp":1662444784547,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"1f3e96c5-3052-466d-d1cd-ea93fb8e969b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-35000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-bal-40000"],"metadata":{"id":"qzS0YIM2PRVd"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"k64anLNRPRVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('//content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-bala-AR12/TGAN-syn-balanceAR-all-in-one-40000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"oJaT3Se4PRVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"nisX67cSPRVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"4pqqc84GPRVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"uwLwsT89PRVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"Gplc_3jRPRVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"1LvsaYjSPRVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"17ChMoutPRVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"MWzuKlagPRVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YsJk1urQPRVe","executionInfo":{"status":"ok","timestamp":1662450340078,"user_tz":-540,"elapsed":1363210,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"5801aa2b-e041-4608-da5a-8134c30b236d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 16129307.255 - ||grad||^2 = 22817339.42563 - ||diff_w|| = 18.03262\n"," * Iteration #2 - Loss = 4092296.446 - ||grad||^2 = 11552486.81270 - ||diff_w|| = 8.07817\n"," * Iteration #3 - Loss = 1276502.520 - ||grad||^2 = 6435031.35490 - ||diff_w|| = 4.34839\n"," * Iteration #4 - Loss = 429765.323 - ||grad||^2 = 3501192.90576 - ||diff_w|| = 2.14198\n"," * Iteration #5 - Loss = 199907.425 - ||grad||^2 = 1778987.06589 - ||diff_w|| = 0.90157\n"," * Iteration #6 - Loss = 157439.284 - ||grad||^2 = 738277.39330 - ||diff_w|| = 0.42635\n"," * Iteration #7 - Loss = 153371.576 - ||grad||^2 = 252594.83933 - ||diff_w|| = 0.19264\n"," * Iteration #8 - Loss = 152715.390 - ||grad||^2 = 89794.76638 - ||diff_w|| = 0.08168\n"," * Iteration #9 - Loss = 152699.873 - ||grad||^2 = 30787.72191 - ||diff_w|| = 0.03419\n"," * Iteration #10 - Loss = 152713.492 - ||grad||^2 = 10425.51700 - ||diff_w|| = 0.01469\n"," * Iteration #11 - Loss = 152729.801 - ||grad||^2 = 3631.35394 - ||diff_w|| = 0.00652\n"," * Iteration #12 - Loss = 152733.276 - ||grad||^2 = 1297.53479 - ||diff_w|| = 0.00305\n"," * Iteration #13 - Loss = 152734.193 - ||grad||^2 = 481.58021 - ||diff_w|| = 0.00150\n"," * Iteration #14 - Loss = 152734.370 - ||grad||^2 = 199.03043 - ||diff_w|| = 0.00076\n"," * Iteration #15 - Loss = 152734.481 - ||grad||^2 = 87.56130 - ||diff_w|| = 0.00040\n"," * Iteration #16 - Loss = 152734.478 - ||grad||^2 = 43.93557 - ||diff_w|| = 0.00021\n"," * Iteration #17 - Loss = 152734.501 - ||grad||^2 = 24.19971 - ||diff_w|| = 0.00011\n"," * Iteration #18 - Loss = 152734.479 - ||grad||^2 = 12.75994 - ||diff_w|| = 0.00006\n"," * Iteration #19 - Loss = 152734.481 - ||grad||^2 = 6.85904 - ||diff_w|| = 0.00003\n"," * Iteration #20 - Loss = 152734.480 - ||grad||^2 = 3.59989 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 152734.476 - ||grad||^2 = 1.82441 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 152734.478 - ||grad||^2 = 1.00408 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 152734.477 - ||grad||^2 = 0.48835 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 152734.478 - ||grad||^2 = 0.29777 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 152734.477 - ||grad||^2 = 0.12842 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 152734.477 - ||grad||^2 = 0.09513 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 152734.476 - ||grad||^2 = 0.05343 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 152734.477 - ||grad||^2 = 0.05370 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 152734.477 - ||grad||^2 = 0.03997 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 152734.477 - ||grad||^2 = 0.04075 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 152734.477 - ||grad||^2 = 0.03709 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 152734.477 - ||grad||^2 = 0.01822 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 152734.477 - ||grad||^2 = 0.02673 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 152734.477 - ||grad||^2 = 0.01695 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 152734.477 - ||grad||^2 = 0.01166 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 152734.477 - ||grad||^2 = 0.01256 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 152734.477 - ||grad||^2 = 0.03176 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 152734.477 - ||grad||^2 = 0.04277 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 152734.477 - ||grad||^2 = 0.04008 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 152734.477 - ||grad||^2 = 0.04015 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 152734.477 - ||grad||^2 = 0.03787 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 152734.477 - ||grad||^2 = 0.01879 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 152734.477 - ||grad||^2 = 0.01427 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 152734.477 - ||grad||^2 = 0.01305 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 152734.477 - ||grad||^2 = 0.02378 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 152734.476 - ||grad||^2 = 0.04276 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 152734.477 - ||grad||^2 = 0.03848 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 152734.477 - ||grad||^2 = 0.05686 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 152734.477 - ||grad||^2 = 0.04495 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 152734.477 - ||grad||^2 = 0.03587 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 152734.477 - ||grad||^2 = 0.02012 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 152734.477 - ||grad||^2 = 0.01436 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 152734.477 - ||grad||^2 = 0.01324 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 152734.477 - ||grad||^2 = 0.02367 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 152734.476 - ||grad||^2 = 0.04277 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 152734.477 - ||grad||^2 = 0.03854 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 152734.477 - ||grad||^2 = 0.05682 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 152734.477 - ||grad||^2 = 0.04497 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 152734.477 - ||grad||^2 = 0.03586 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 152734.477 - ||grad||^2 = 0.02012 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 152734.477 - ||grad||^2 = 0.01436 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 152734.477 - ||grad||^2 = 0.01325 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 152734.477 - ||grad||^2 = 0.02367 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 152734.476 - ||grad||^2 = 0.04277 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 152734.477 - ||grad||^2 = 0.03854 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 152734.477 - ||grad||^2 = 0.05682 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 152734.477 - ||grad||^2 = 0.04497 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 152734.477 - ||grad||^2 = 0.03586 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 152734.477 - ||grad||^2 = 0.02012 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 152734.477 - ||grad||^2 = 0.01436 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 152734.477 - ||grad||^2 = 0.01325 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 152734.477 - ||grad||^2 = 0.02367 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 152734.476 - ||grad||^2 = 0.04277 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 152734.477 - ||grad||^2 = 0.03854 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 152734.477 - ||grad||^2 = 0.05682 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 152734.477 - ||grad||^2 = 0.04497 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 152734.477 - ||grad||^2 = 0.03586 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 152734.477 - ||grad||^2 = 0.02012 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 152734.477 - ||grad||^2 = 0.01436 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 152734.477 - ||grad||^2 = 0.01325 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 152734.477 - ||grad||^2 = 0.02367 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 152734.476 - ||grad||^2 = 0.04277 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 152734.477 - ||grad||^2 = 0.03854 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 152734.477 - ||grad||^2 = 0.05682 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 152734.477 - ||grad||^2 = 0.04497 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 152734.477 - ||grad||^2 = 0.03586 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 152734.477 - ||grad||^2 = 0.02012 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 152734.477 - ||grad||^2 = 0.01436 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 152734.477 - ||grad||^2 = 0.01325 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 152734.477 - ||grad||^2 = 0.02367 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 152734.476 - ||grad||^2 = 0.04277 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 152734.477 - ||grad||^2 = 0.03854 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 152734.477 - ||grad||^2 = 0.05682 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 152734.477 - ||grad||^2 = 0.04497 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 152734.477 - ||grad||^2 = 0.03586 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 152734.477 - ||grad||^2 = 0.02012 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 152734.477 - ||grad||^2 = 0.01436 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 152734.477 - ||grad||^2 = 0.01325 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 152734.477 - ||grad||^2 = 0.02367 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 152734.476 - ||grad||^2 = 0.04277 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mt_NWQ_sPRVe","executionInfo":{"status":"ok","timestamp":1662450340078,"user_tz":-540,"elapsed":21,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"0562bbbb-3272-4685-9da3-4f22afccb1f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.829435\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"IwFYD0INPRVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-40000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8DYb-d-LPRVf","executionInfo":{"status":"ok","timestamp":1662450340080,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"9bf24d0d-28a1-491a-d39b-6ea49d797724"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-40000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-bal-45000"],"metadata":{"id":"wGaYYQm9QlWZ"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"I71dZS6SQlWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('//content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-bala-AR12/TGAN-syn-balanceAR-all-in-one-45000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"buYqOR3sQlWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"nsMFxn3UQlWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"wIH7B_9bQlWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"t8pC2059QlWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"IBW9NixXQlWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"f6l2g5C9QlWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"HdG_gHTEQlWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"rX_LdwuyQlWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"id":"F9lchazHQlWb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662506317227,"user_tz":-540,"elapsed":1685205,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"9ce58286-614a-41fe-c16e-a783f04c2568"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 29271655.605 - ||grad||^2 = 51648552.23965 - ||diff_w|| = 13.39003\n"," * Iteration #2 - Loss = 7421617.604 - ||grad||^2 = 26230286.62403 - ||diff_w|| = 6.01272\n"," * Iteration #3 - Loss = 2297956.826 - ||grad||^2 = 14706946.70873 - ||diff_w|| = 3.27013\n"," * Iteration #4 - Loss = 737798.459 - ||grad||^2 = 8099435.40354 - ||diff_w|| = 1.67426\n"," * Iteration #5 - Loss = 292883.635 - ||grad||^2 = 3966690.51166 - ||diff_w|| = 0.71689\n"," * Iteration #6 - Loss = 202056.518 - ||grad||^2 = 1923336.15156 - ||diff_w|| = 0.35075\n"," * Iteration #7 - Loss = 190619.342 - ||grad||^2 = 765375.64112 - ||diff_w|| = 0.17373\n"," * Iteration #8 - Loss = 191505.560 - ||grad||^2 = 247306.43291 - ||diff_w|| = 0.06917\n"," * Iteration #9 - Loss = 191599.638 - ||grad||^2 = 79983.35402 - ||diff_w|| = 0.02448\n"," * Iteration #10 - Loss = 191551.412 - ||grad||^2 = 26836.91132 - ||diff_w|| = 0.00975\n"," * Iteration #11 - Loss = 191545.970 - ||grad||^2 = 9360.67170 - ||diff_w|| = 0.00429\n"," * Iteration #12 - Loss = 191542.503 - ||grad||^2 = 3471.02860 - ||diff_w|| = 0.00201\n"," * Iteration #13 - Loss = 191541.347 - ||grad||^2 = 1516.61717 - ||diff_w|| = 0.00101\n"," * Iteration #14 - Loss = 191541.023 - ||grad||^2 = 739.37875 - ||diff_w|| = 0.00052\n"," * Iteration #15 - Loss = 191540.844 - ||grad||^2 = 375.53570 - ||diff_w|| = 0.00028\n"," * Iteration #16 - Loss = 191540.730 - ||grad||^2 = 196.87829 - ||diff_w|| = 0.00015\n"," * Iteration #17 - Loss = 191540.711 - ||grad||^2 = 103.76321 - ||diff_w|| = 0.00008\n"," * Iteration #18 - Loss = 191540.686 - ||grad||^2 = 54.53586 - ||diff_w|| = 0.00004\n"," * Iteration #19 - Loss = 191540.676 - ||grad||^2 = 28.62990 - ||diff_w|| = 0.00002\n"," * Iteration #20 - Loss = 191540.668 - ||grad||^2 = 15.15218 - ||diff_w|| = 0.00001\n"," * Iteration #21 - Loss = 191540.666 - ||grad||^2 = 7.93812 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 191540.664 - ||grad||^2 = 4.20909 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 191540.664 - ||grad||^2 = 2.21050 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 191540.664 - ||grad||^2 = 1.16720 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 191540.663 - ||grad||^2 = 0.61424 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 191540.663 - ||grad||^2 = 0.34557 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 191540.662 - ||grad||^2 = 0.15801 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 191540.664 - ||grad||^2 = 0.13717 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 191540.662 - ||grad||^2 = 0.05130 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 191540.664 - ||grad||^2 = 0.06597 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 191540.662 - ||grad||^2 = 0.05727 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 191540.664 - ||grad||^2 = 0.06247 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 191540.662 - ||grad||^2 = 0.06465 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 191540.664 - ||grad||^2 = 0.06216 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 191540.662 - ||grad||^2 = 0.05141 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 191540.664 - ||grad||^2 = 0.05448 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 191540.662 - ||grad||^2 = 0.05707 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 191540.664 - ||grad||^2 = 0.04987 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 191540.661 - ||grad||^2 = 0.07687 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 191540.664 - ||grad||^2 = 0.06795 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 191540.663 - ||grad||^2 = 0.04194 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 191540.663 - ||grad||^2 = 0.03576 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 191540.663 - ||grad||^2 = 0.03479 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 191540.663 - ||grad||^2 = 0.03854 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 191540.663 - ||grad||^2 = 0.04659 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 191540.663 - ||grad||^2 = 0.03556 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 191540.662 - ||grad||^2 = 0.06205 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 191540.664 - ||grad||^2 = 0.06346 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 191540.662 - ||grad||^2 = 0.05101 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 191540.664 - ||grad||^2 = 0.05735 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 191540.662 - ||grad||^2 = 0.06347 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 191540.664 - ||grad||^2 = 0.05560 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 191540.662 - ||grad||^2 = 0.04985 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 191540.664 - ||grad||^2 = 0.04331 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 191540.662 - ||grad||^2 = 0.05973 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 191540.664 - ||grad||^2 = 0.05423 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 191540.662 - ||grad||^2 = 0.05005 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 191540.664 - ||grad||^2 = 0.04739 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 191540.662 - ||grad||^2 = 0.07260 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 191540.664 - ||grad||^2 = 0.06268 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 191540.662 - ||grad||^2 = 0.03253 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 191540.664 - ||grad||^2 = 0.04758 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 191540.661 - ||grad||^2 = 0.08150 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 191540.664 - ||grad||^2 = 0.06181 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 191540.662 - ||grad||^2 = 0.03152 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 191540.664 - ||grad||^2 = 0.04384 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 191540.662 - ||grad||^2 = 0.06672 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 191540.664 - ||grad||^2 = 0.05856 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 191540.662 - ||grad||^2 = 0.05299 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 191540.664 - ||grad||^2 = 0.05601 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 191540.662 - ||grad||^2 = 0.07685 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 191540.664 - ||grad||^2 = 0.05809 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 191540.663 - ||grad||^2 = 0.04369 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 191540.663 - ||grad||^2 = 0.04798 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 191540.662 - ||grad||^2 = 0.06345 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 191540.664 - ||grad||^2 = 0.05263 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 191540.663 - ||grad||^2 = 0.02846 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 191540.663 - ||grad||^2 = 0.04303 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 191540.663 - ||grad||^2 = 0.04630 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 191540.663 - ||grad||^2 = 0.04004 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 191540.663 - ||grad||^2 = 0.02894 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 191540.663 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 191540.662 - ||grad||^2 = 0.05405 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 191540.664 - ||grad||^2 = 0.04496 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 191540.663 - ||grad||^2 = 0.02258 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 191540.663 - ||grad||^2 = 0.02762 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 191540.663 - ||grad||^2 = 0.02640 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 191540.663 - ||grad||^2 = 0.02835 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 191540.662 - ||grad||^2 = 0.04676 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 191540.664 - ||grad||^2 = 0.05596 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 191540.662 - ||grad||^2 = 0.05808 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 191540.663 - ||grad||^2 = 0.03664 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 191540.663 - ||grad||^2 = 0.04409 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 191540.663 - ||grad||^2 = 0.03114 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 191540.662 - ||grad||^2 = 0.05822 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 191540.664 - ||grad||^2 = 0.07120 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 191540.662 - ||grad||^2 = 0.06403 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 191540.664 - ||grad||^2 = 0.06324 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 191540.662 - ||grad||^2 = 0.03375 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 191540.664 - ||grad||^2 = 0.04851 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"id":"Ac4UyZ9yQlWb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662506317227,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"20b2088a-1430-49d4-ad24-00747ee87fdf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.829790\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"1pCv_NrIQlWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-45000.zip')"],"metadata":{"id":"FGiwDyHQQlWb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662506317228,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"69b8551b-bc5a-4819-ec6d-e8452f58fec3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-45000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-bal-50000"],"metadata":{"id":"kBm5XWGUQq1M"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"3dv9aH5dQq1M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('//content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-bala-AR12/TGAN-syn-balanceAR-all-in-one-50000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"e5BfMwrBQq1N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"7B7tmM-7Qq1N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"xzU2Gaw-Qq1N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"63-EzsQ5Qq1N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"becScPDwQq1N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"RdpG3hegQq1N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"HXGwtqU5Qq1N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"njSG16etQq1N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"id":"T120BydoQq1N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662509501297,"user_tz":-540,"elapsed":2877477,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"b7f506c9-8121-4de2-acb8-dd4a95339ea4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 37388534.606 - ||grad||^2 = 63507487.72153 - ||diff_w|| = 16.72109\n"," * Iteration #2 - Loss = 9436824.866 - ||grad||^2 = 32066802.31306 - ||diff_w|| = 7.51181\n"," * Iteration #3 - Loss = 2905903.893 - ||grad||^2 = 17834751.57784 - ||diff_w|| = 4.08526\n"," * Iteration #4 - Loss = 933161.497 - ||grad||^2 = 9778297.39047 - ||diff_w|| = 2.09211\n"," * Iteration #5 - Loss = 375208.001 - ||grad||^2 = 5025443.93784 - ||diff_w|| = 0.90811\n"," * Iteration #6 - Loss = 256635.751 - ||grad||^2 = 2392886.87875 - ||diff_w|| = 0.42782\n"," * Iteration #7 - Loss = 244224.086 - ||grad||^2 = 873692.07766 - ||diff_w|| = 0.20845\n"," * Iteration #8 - Loss = 245730.086 - ||grad||^2 = 244701.63054 - ||diff_w|| = 0.08681\n"," * Iteration #9 - Loss = 245822.611 - ||grad||^2 = 71240.47377 - ||diff_w|| = 0.03233\n"," * Iteration #10 - Loss = 245725.472 - ||grad||^2 = 23893.00154 - ||diff_w|| = 0.01367\n"," * Iteration #11 - Loss = 245700.945 - ||grad||^2 = 8560.82785 - ||diff_w|| = 0.00614\n"," * Iteration #12 - Loss = 245691.453 - ||grad||^2 = 3778.71452 - ||diff_w|| = 0.00293\n"," * Iteration #13 - Loss = 245688.030 - ||grad||^2 = 2009.67788 - ||diff_w|| = 0.00148\n"," * Iteration #14 - Loss = 245686.787 - ||grad||^2 = 1086.57760 - ||diff_w|| = 0.00078\n"," * Iteration #15 - Loss = 245686.321 - ||grad||^2 = 583.58631 - ||diff_w|| = 0.00042\n"," * Iteration #16 - Loss = 245686.119 - ||grad||^2 = 311.52001 - ||diff_w|| = 0.00022\n"," * Iteration #17 - Loss = 245686.007 - ||grad||^2 = 164.65867 - ||diff_w|| = 0.00012\n"," * Iteration #18 - Loss = 245685.971 - ||grad||^2 = 86.28341 - ||diff_w|| = 0.00007\n"," * Iteration #19 - Loss = 245685.939 - ||grad||^2 = 45.14090 - ||diff_w|| = 0.00004\n"," * Iteration #20 - Loss = 245685.936 - ||grad||^2 = 23.67188 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 245685.932 - ||grad||^2 = 12.46922 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 245685.927 - ||grad||^2 = 6.52313 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 245685.929 - ||grad||^2 = 3.45669 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 245685.927 - ||grad||^2 = 1.77462 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 245685.926 - ||grad||^2 = 0.93926 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 245685.925 - ||grad||^2 = 0.47560 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 245685.925 - ||grad||^2 = 0.25519 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 245685.926 - ||grad||^2 = 0.15597 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 245685.925 - ||grad||^2 = 0.09106 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 245685.926 - ||grad||^2 = 0.04739 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 245685.926 - ||grad||^2 = 0.03329 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 245685.925 - ||grad||^2 = 0.04223 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 245685.926 - ||grad||^2 = 0.04749 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 245685.925 - ||grad||^2 = 0.04329 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 245685.926 - ||grad||^2 = 0.04052 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 245685.925 - ||grad||^2 = 0.03497 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 245685.925 - ||grad||^2 = 0.03337 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 245685.926 - ||grad||^2 = 0.02253 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 245685.925 - ||grad||^2 = 0.02378 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 245685.926 - ||grad||^2 = 0.03088 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 245685.926 - ||grad||^2 = 0.04980 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 245685.926 - ||grad||^2 = 0.03596 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 245685.925 - ||grad||^2 = 0.04713 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 245685.926 - ||grad||^2 = 0.03639 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 245685.926 - ||grad||^2 = 0.02550 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 245685.925 - ||grad||^2 = 0.02447 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 245685.926 - ||grad||^2 = 0.02264 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 245685.925 - ||grad||^2 = 0.03145 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 245685.926 - ||grad||^2 = 0.04474 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 245685.925 - ||grad||^2 = 0.04371 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 245685.926 - ||grad||^2 = 0.03991 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 245685.925 - ||grad||^2 = 0.03517 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 245685.925 - ||grad||^2 = 0.03292 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 245685.926 - ||grad||^2 = 0.02254 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 245685.925 - ||grad||^2 = 0.02385 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 245685.926 - ||grad||^2 = 0.03086 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 245685.926 - ||grad||^2 = 0.04980 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 245685.926 - ||grad||^2 = 0.03597 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 245685.925 - ||grad||^2 = 0.04714 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 245685.926 - ||grad||^2 = 0.03639 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 245685.926 - ||grad||^2 = 0.02550 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 245685.925 - ||grad||^2 = 0.02447 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 245685.926 - ||grad||^2 = 0.02264 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 245685.925 - ||grad||^2 = 0.03145 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 245685.926 - ||grad||^2 = 0.04474 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 245685.925 - ||grad||^2 = 0.04371 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 245685.926 - ||grad||^2 = 0.03991 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 245685.925 - ||grad||^2 = 0.03517 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 245685.925 - ||grad||^2 = 0.03292 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 245685.926 - ||grad||^2 = 0.02254 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 245685.925 - ||grad||^2 = 0.02385 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 245685.926 - ||grad||^2 = 0.03086 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 245685.926 - ||grad||^2 = 0.04980 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 245685.926 - ||grad||^2 = 0.03597 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 245685.925 - ||grad||^2 = 0.04714 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 245685.926 - ||grad||^2 = 0.03639 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 245685.926 - ||grad||^2 = 0.02550 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 245685.925 - ||grad||^2 = 0.02447 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 245685.926 - ||grad||^2 = 0.02264 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 245685.925 - ||grad||^2 = 0.03145 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 245685.926 - ||grad||^2 = 0.04474 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 245685.925 - ||grad||^2 = 0.04371 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 245685.926 - ||grad||^2 = 0.03991 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 245685.925 - ||grad||^2 = 0.03517 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 245685.925 - ||grad||^2 = 0.03292 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 245685.926 - ||grad||^2 = 0.02254 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 245685.925 - ||grad||^2 = 0.02385 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 245685.926 - ||grad||^2 = 0.03086 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 245685.926 - ||grad||^2 = 0.04980 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 245685.926 - ||grad||^2 = 0.03597 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 245685.925 - ||grad||^2 = 0.04714 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 245685.926 - ||grad||^2 = 0.03639 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 245685.926 - ||grad||^2 = 0.02550 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 245685.925 - ||grad||^2 = 0.02447 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 245685.926 - ||grad||^2 = 0.02264 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 245685.925 - ||grad||^2 = 0.03145 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 245685.926 - ||grad||^2 = 0.04474 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 245685.925 - ||grad||^2 = 0.04371 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 245685.926 - ||grad||^2 = 0.03991 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 245685.925 - ||grad||^2 = 0.03517 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"id":"3DZWmwnuQq1O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662509501661,"user_tz":-540,"elapsed":367,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"9e5c0bf9-d284-430c-9648-75eca76e920f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.829408\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"L4pTvtwHQq1O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-50000.zip')"],"metadata":{"id":"ahiGRtokQq1O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662509501662,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"4770beb3-6959-4116-ba03-8d98423fdb00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-bal-50000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-aug-5000"],"metadata":{"id":"Z6lh2Iz5T-lr"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"NE4uuIncT-ls"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-nonAR/TGAN-syn-imbar-nonAR-5000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"4pzELJCtT-lt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"0yJd-YstT-lt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"ZWrqVqsvT-lu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"JnFoyzczT-lu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"BAEM6JPZT-lu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"_tKURxQkT-lu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"wXworxYST-lv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"MSnTfIw-T-lv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662514390763,"user_tz":-540,"elapsed":26715,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"151f4ebf-3443-4562-f43c-fb2b5291ff67","id":"ZHcuorRZT-lv"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 108051.324 - ||grad||^2 = 138747.44533 - ||diff_w|| = 17.87421\n"," * Iteration #2 - Loss = 27448.960 - ||grad||^2 = 70218.09403 - ||diff_w|| = 8.03230\n"," * Iteration #3 - Loss = 8545.709 - ||grad||^2 = 39093.17899 - ||diff_w|| = 4.37546\n"," * Iteration #4 - Loss = 2821.681 - ||grad||^2 = 21159.53474 - ||diff_w|| = 2.24301\n"," * Iteration #5 - Loss = 1277.038 - ||grad||^2 = 9691.49468 - ||diff_w|| = 0.92314\n"," * Iteration #6 - Loss = 1014.076 - ||grad||^2 = 4027.32617 - ||diff_w|| = 0.37679\n"," * Iteration #7 - Loss = 987.692 - ||grad||^2 = 1810.27263 - ||diff_w|| = 0.18107\n"," * Iteration #8 - Loss = 986.160 - ||grad||^2 = 869.84435 - ||diff_w|| = 0.08875\n"," * Iteration #9 - Loss = 985.892 - ||grad||^2 = 416.78910 - ||diff_w|| = 0.04559\n"," * Iteration #10 - Loss = 985.746 - ||grad||^2 = 202.39371 - ||diff_w|| = 0.02428\n"," * Iteration #11 - Loss = 985.674 - ||grad||^2 = 101.36395 - ||diff_w|| = 0.01317\n"," * Iteration #12 - Loss = 985.659 - ||grad||^2 = 51.95787 - ||diff_w|| = 0.00714\n"," * Iteration #13 - Loss = 985.654 - ||grad||^2 = 27.17039 - ||diff_w|| = 0.00389\n"," * Iteration #14 - Loss = 985.655 - ||grad||^2 = 14.13853 - ||diff_w|| = 0.00215\n"," * Iteration #15 - Loss = 985.654 - ||grad||^2 = 7.41282 - ||diff_w|| = 0.00117\n"," * Iteration #16 - Loss = 985.653 - ||grad||^2 = 3.99190 - ||diff_w|| = 0.00064\n"," * Iteration #17 - Loss = 985.654 - ||grad||^2 = 2.15401 - ||diff_w|| = 0.00035\n"," * Iteration #18 - Loss = 985.654 - ||grad||^2 = 1.16649 - ||diff_w|| = 0.00019\n"," * Iteration #19 - Loss = 985.655 - ||grad||^2 = 0.63371 - ||diff_w|| = 0.00010\n"," * Iteration #20 - Loss = 985.653 - ||grad||^2 = 0.32358 - ||diff_w|| = 0.00006\n"," * Iteration #21 - Loss = 985.654 - ||grad||^2 = 0.19240 - ||diff_w|| = 0.00003\n"," * Iteration #22 - Loss = 985.653 - ||grad||^2 = 0.09783 - ||diff_w|| = 0.00002\n"," * Iteration #23 - Loss = 985.655 - ||grad||^2 = 0.07322 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 985.653 - ||grad||^2 = 0.04917 - ||diff_w|| = 0.00001\n"," * Iteration #25 - Loss = 985.655 - ||grad||^2 = 0.04835 - ||diff_w|| = 0.00001\n"," * Iteration #26 - Loss = 985.652 - ||grad||^2 = 0.05354 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 985.655 - ||grad||^2 = 0.06169 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 985.653 - ||grad||^2 = 0.04936 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 985.655 - ||grad||^2 = 0.04053 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 985.653 - ||grad||^2 = 0.04360 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 985.655 - ||grad||^2 = 0.05867 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 985.653 - ||grad||^2 = 0.04976 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 985.655 - ||grad||^2 = 0.04000 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 985.653 - ||grad||^2 = 0.04386 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 985.655 - ||grad||^2 = 0.05844 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 985.653 - ||grad||^2 = 0.04981 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 985.655 - ||grad||^2 = 0.03995 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 985.655 - ||grad||^2 = 0.03994 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 985.653 - ||grad||^2 = 0.04389 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 985.655 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 985.653 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662514390763,"user_tz":-540,"elapsed":22,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"95a6e15d-d42e-4b5e-e8e1-dc648e51157f","id":"0mCHCqyAT-lv"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.831346\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"tT0fO6o_T-lv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-5000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662514390764,"user_tz":-540,"elapsed":20,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"28ec3b35-59f9-4ccd-8d9b-2801c0248fae","id":"p3pLUohmT-lv"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-5000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-aug-10000"],"metadata":{"id":"UWfGinuLklbu"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"12o8IrcTklbv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-nonAR/TGAN-syn-imbar-nonAR-10000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"2Tl9Zw61klbv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"247LhWCgklbv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"xW_Bo7nVklbv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"Cxuymwcvklbw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"rXqfD-lTklbw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"R2JwKiveklbw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"OQ7a-fE0klbw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"tIPn9NIaklbw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662514534419,"user_tz":-540,"elapsed":91689,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"d5d4fd29-db7c-41b9-94e1-00348947bf67","id":"tw5BNClAklbx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 258437.854 - ||grad||^2 = 343936.11387 - ||diff_w|| = 18.48867\n"," * Iteration #2 - Loss = 67095.662 - ||grad||^2 = 178871.19314 - ||diff_w|| = 8.26919\n"," * Iteration #3 - Loss = 21951.716 - ||grad||^2 = 104994.03077 - ||diff_w|| = 4.40972\n"," * Iteration #4 - Loss = 8265.107 - ||grad||^2 = 59756.44459 - ||diff_w|| = 2.01575\n"," * Iteration #5 - Loss = 4641.990 - ||grad||^2 = 19662.52170 - ||diff_w|| = 0.66438\n"," * Iteration #6 - Loss = 4141.265 - ||grad||^2 = 7749.60618 - ||diff_w|| = 0.27543\n"," * Iteration #7 - Loss = 4132.216 - ||grad||^2 = 2716.50659 - ||diff_w|| = 0.12504\n"," * Iteration #8 - Loss = 4135.666 - ||grad||^2 = 1023.00347 - ||diff_w|| = 0.05933\n"," * Iteration #9 - Loss = 4136.408 - ||grad||^2 = 402.72138 - ||diff_w|| = 0.02903\n"," * Iteration #10 - Loss = 4136.621 - ||grad||^2 = 168.22754 - ||diff_w|| = 0.01488\n"," * Iteration #11 - Loss = 4136.686 - ||grad||^2 = 77.16438 - ||diff_w|| = 0.00784\n"," * Iteration #12 - Loss = 4136.713 - ||grad||^2 = 38.55333 - ||diff_w|| = 0.00419\n"," * Iteration #13 - Loss = 4136.721 - ||grad||^2 = 19.73494 - ||diff_w|| = 0.00226\n"," * Iteration #14 - Loss = 4136.725 - ||grad||^2 = 10.68764 - ||diff_w|| = 0.00123\n"," * Iteration #15 - Loss = 4136.724 - ||grad||^2 = 5.77092 - ||diff_w|| = 0.00067\n"," * Iteration #16 - Loss = 4136.726 - ||grad||^2 = 3.07951 - ||diff_w|| = 0.00036\n"," * Iteration #17 - Loss = 4136.726 - ||grad||^2 = 1.64982 - ||diff_w|| = 0.00020\n"," * Iteration #18 - Loss = 4136.727 - ||grad||^2 = 0.91788 - ||diff_w|| = 0.00011\n"," * Iteration #19 - Loss = 4136.727 - ||grad||^2 = 0.50004 - ||diff_w|| = 0.00006\n"," * Iteration #20 - Loss = 4136.726 - ||grad||^2 = 0.27341 - ||diff_w|| = 0.00003\n"," * Iteration #21 - Loss = 4136.727 - ||grad||^2 = 0.15428 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 4136.726 - ||grad||^2 = 0.09473 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 4136.726 - ||grad||^2 = 0.04038 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 4136.727 - ||grad||^2 = 0.05278 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 4136.726 - ||grad||^2 = 0.02975 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 4136.727 - ||grad||^2 = 0.03726 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 4136.726 - ||grad||^2 = 0.02980 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 4136.727 - ||grad||^2 = 0.03933 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 4136.726 - ||grad||^2 = 0.02825 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 4136.727 - ||grad||^2 = 0.03481 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 4136.726 - ||grad||^2 = 0.02997 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 4136.727 - ||grad||^2 = 0.02837 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 4136.726 - ||grad||^2 = 0.04547 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 4136.727 - ||grad||^2 = 0.02730 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 4136.726 - ||grad||^2 = 0.02774 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 4136.727 - ||grad||^2 = 0.03145 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 4136.726 - ||grad||^2 = 0.02869 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 4136.727 - ||grad||^2 = 0.02458 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 4136.726 - ||grad||^2 = 0.03016 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 4136.727 - ||grad||^2 = 0.02499 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 4136.726 - ||grad||^2 = 0.02798 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 4136.727 - ||grad||^2 = 0.03095 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 4136.726 - ||grad||^2 = 0.02884 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 4136.727 - ||grad||^2 = 0.02443 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 4136.726 - ||grad||^2 = 0.04285 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 4136.727 - ||grad||^2 = 0.03675 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 4136.726 - ||grad||^2 = 0.02867 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 4136.727 - ||grad||^2 = 0.02247 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 4136.726 - ||grad||^2 = 0.03280 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 4136.727 - ||grad||^2 = 0.02581 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 4136.726 - ||grad||^2 = 0.02219 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 4136.727 - ||grad||^2 = 0.02318 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 4136.726 - ||grad||^2 = 0.03973 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 4136.727 - ||grad||^2 = 0.03021 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 4136.726 - ||grad||^2 = 0.02041 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 4136.727 - ||grad||^2 = 0.02434 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 4136.726 - ||grad||^2 = 0.03083 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 4136.727 - ||grad||^2 = 0.02683 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 4136.726 - ||grad||^2 = 0.02171 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 4136.727 - ||grad||^2 = 0.02354 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 4136.726 - ||grad||^2 = 0.03953 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 4136.727 - ||grad||^2 = 0.03032 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 4136.726 - ||grad||^2 = 0.02038 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 4136.727 - ||grad||^2 = 0.02438 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 4136.726 - ||grad||^2 = 0.03082 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 4136.727 - ||grad||^2 = 0.02684 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 4136.726 - ||grad||^2 = 0.02170 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 4136.727 - ||grad||^2 = 0.02355 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 4136.726 - ||grad||^2 = 0.03953 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 4136.727 - ||grad||^2 = 0.03032 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 4136.726 - ||grad||^2 = 0.02038 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 4136.727 - ||grad||^2 = 0.02438 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 4136.726 - ||grad||^2 = 0.03082 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 4136.727 - ||grad||^2 = 0.02684 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 4136.726 - ||grad||^2 = 0.02170 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 4136.727 - ||grad||^2 = 0.02355 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 4136.726 - ||grad||^2 = 0.03953 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 4136.727 - ||grad||^2 = 0.03032 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 4136.726 - ||grad||^2 = 0.02038 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 4136.727 - ||grad||^2 = 0.02438 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 4136.726 - ||grad||^2 = 0.03082 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 4136.727 - ||grad||^2 = 0.02684 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 4136.726 - ||grad||^2 = 0.02170 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 4136.727 - ||grad||^2 = 0.02355 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 4136.726 - ||grad||^2 = 0.03953 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 4136.727 - ||grad||^2 = 0.03032 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 4136.726 - ||grad||^2 = 0.02038 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 4136.727 - ||grad||^2 = 0.02438 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 4136.726 - ||grad||^2 = 0.03082 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 4136.727 - ||grad||^2 = 0.02684 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 4136.726 - ||grad||^2 = 0.02170 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 4136.727 - ||grad||^2 = 0.02355 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 4136.726 - ||grad||^2 = 0.03953 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 4136.727 - ||grad||^2 = 0.03032 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 4136.726 - ||grad||^2 = 0.02038 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 4136.727 - ||grad||^2 = 0.02438 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 4136.726 - ||grad||^2 = 0.03082 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 4136.727 - ||grad||^2 = 0.02684 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 4136.726 - ||grad||^2 = 0.02170 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 4136.727 - ||grad||^2 = 0.02355 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662514534419,"user_tz":-540,"elapsed":24,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"2949b989-93bd-4aac-e2d1-84ba70a5d333","id":"03FSW0rLklbx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.827587\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"p0N_Wfsyklbx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-10000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662514534802,"user_tz":-540,"elapsed":402,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"7c8b8076-90d0-491d-d47f-56b473899d5b","id":"tilYqo8Dklbx"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-10000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-aug-15000"],"metadata":{"id":"QPg-VcFJks_T"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"5BB7EEEyks_T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-nonAR/TGAN-syn-imbar-nonAR-15000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"xMWdY0r9ks_T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"VaZtXTOwks_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"Vs93Elxtks_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"MH0FMGKAks_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"dyk-JeT6ks_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"vYeMnZprks_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"xgPxA54kks_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"GrqMLpwiks_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662514922807,"user_tz":-540,"elapsed":193758,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"90023d77-9127-4f3a-fccb-295bdcb13958","id":"qocX-nFUks_V"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 1015720.745 - ||grad||^2 = 1741711.96236 - ||diff_w|| = 17.00016\n"," * Iteration #2 - Loss = 258559.911 - ||grad||^2 = 881368.78134 - ||diff_w|| = 7.62858\n"," * Iteration #3 - Loss = 81087.492 - ||grad||^2 = 491242.88535 - ||diff_w|| = 4.13191\n"," * Iteration #4 - Loss = 27297.142 - ||grad||^2 = 266706.44836 - ||diff_w|| = 2.06114\n"," * Iteration #5 - Loss = 12278.481 - ||grad||^2 = 130859.17533 - ||diff_w|| = 0.77699\n"," * Iteration #6 - Loss = 9331.209 - ||grad||^2 = 61079.11173 - ||diff_w|| = 0.31418\n"," * Iteration #7 - Loss = 9030.490 - ||grad||^2 = 24050.69577 - ||diff_w|| = 0.13314\n"," * Iteration #8 - Loss = 9061.119 - ||grad||^2 = 7943.67932 - ||diff_w|| = 0.05043\n"," * Iteration #9 - Loss = 9073.467 - ||grad||^2 = 2694.18647 - ||diff_w|| = 0.01980\n"," * Iteration #10 - Loss = 9075.698 - ||grad||^2 = 1028.75785 - ||diff_w|| = 0.00847\n"," * Iteration #11 - Loss = 9076.006 - ||grad||^2 = 432.68061 - ||diff_w|| = 0.00386\n"," * Iteration #12 - Loss = 9076.130 - ||grad||^2 = 202.03157 - ||diff_w|| = 0.00189\n"," * Iteration #13 - Loss = 9076.163 - ||grad||^2 = 102.32254 - ||diff_w|| = 0.00097\n"," * Iteration #14 - Loss = 9076.164 - ||grad||^2 = 51.86656 - ||diff_w|| = 0.00051\n"," * Iteration #15 - Loss = 9076.154 - ||grad||^2 = 26.64733 - ||diff_w|| = 0.00027\n"," * Iteration #16 - Loss = 9076.157 - ||grad||^2 = 13.78860 - ||diff_w|| = 0.00015\n"," * Iteration #17 - Loss = 9076.163 - ||grad||^2 = 7.28505 - ||diff_w|| = 0.00008\n"," * Iteration #18 - Loss = 9076.163 - ||grad||^2 = 3.94557 - ||diff_w|| = 0.00004\n"," * Iteration #19 - Loss = 9076.163 - ||grad||^2 = 2.11125 - ||diff_w|| = 0.00002\n"," * Iteration #20 - Loss = 9076.161 - ||grad||^2 = 1.14921 - ||diff_w|| = 0.00001\n"," * Iteration #21 - Loss = 9076.162 - ||grad||^2 = 0.62974 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 9076.161 - ||grad||^2 = 0.32835 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 9076.162 - ||grad||^2 = 0.18421 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 9076.161 - ||grad||^2 = 0.09416 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 9076.162 - ||grad||^2 = 0.07031 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 9076.162 - ||grad||^2 = 0.03893 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 9076.162 - ||grad||^2 = 0.04075 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 9076.161 - ||grad||^2 = 0.04549 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 9076.163 - ||grad||^2 = 0.06539 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 9076.161 - ||grad||^2 = 0.05244 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 9076.162 - ||grad||^2 = 0.03635 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 9076.161 - ||grad||^2 = 0.04000 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 9076.162 - ||grad||^2 = 0.02652 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 9076.162 - ||grad||^2 = 0.03469 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 9076.161 - ||grad||^2 = 0.03845 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 9076.162 - ||grad||^2 = 0.04109 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 9076.161 - ||grad||^2 = 0.04758 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 9076.163 - ||grad||^2 = 0.05998 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 9076.161 - ||grad||^2 = 0.05470 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 9076.162 - ||grad||^2 = 0.04625 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 9076.161 - ||grad||^2 = 0.05050 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 9076.162 - ||grad||^2 = 0.05558 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 9076.161 - ||grad||^2 = 0.05583 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 9076.163 - ||grad||^2 = 0.06089 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 9076.161 - ||grad||^2 = 0.05573 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 9076.163 - ||grad||^2 = 0.05594 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 9076.161 - ||grad||^2 = 0.05283 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 9076.162 - ||grad||^2 = 0.02625 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 9076.162 - ||grad||^2 = 0.02796 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 9076.162 - ||grad||^2 = 0.03062 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 9076.162 - ||grad||^2 = 0.02186 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 9076.162 - ||grad||^2 = 0.03628 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 9076.161 - ||grad||^2 = 0.04726 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 9076.163 - ||grad||^2 = 0.04716 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 9076.161 - ||grad||^2 = 0.04888 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 9076.162 - ||grad||^2 = 0.03647 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 9076.162 - ||grad||^2 = 0.03405 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 9076.162 - ||grad||^2 = 0.04161 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 9076.161 - ||grad||^2 = 0.05036 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 9076.163 - ||grad||^2 = 0.05907 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 9076.161 - ||grad||^2 = 0.05111 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 9076.162 - ||grad||^2 = 0.03120 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 9076.161 - ||grad||^2 = 0.03598 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 9076.163 - ||grad||^2 = 0.05859 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 9076.161 - ||grad||^2 = 0.05463 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 9076.162 - ||grad||^2 = 0.03696 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 9076.162 - ||grad||^2 = 0.02787 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 9076.162 - ||grad||^2 = 0.02637 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 9076.162 - ||grad||^2 = 0.04462 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 9076.161 - ||grad||^2 = 0.04131 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 9076.162 - ||grad||^2 = 0.03933 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 9076.161 - ||grad||^2 = 0.04386 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 9076.162 - ||grad||^2 = 0.04025 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 9076.162 - ||grad||^2 = 0.03167 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 9076.162 - ||grad||^2 = 0.02687 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 9076.162 - ||grad||^2 = 0.03148 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 9076.162 - ||grad||^2 = 0.02162 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 9076.162 - ||grad||^2 = 0.03587 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 9076.161 - ||grad||^2 = 0.04985 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 9076.163 - ||grad||^2 = 0.05907 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 9076.161 - ||grad||^2 = 0.05508 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 9076.162 - ||grad||^2 = 0.04613 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 9076.161 - ||grad||^2 = 0.05061 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 9076.162 - ||grad||^2 = 0.05550 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 9076.161 - ||grad||^2 = 0.05585 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 9076.163 - ||grad||^2 = 0.06087 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 9076.161 - ||grad||^2 = 0.05574 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 9076.163 - ||grad||^2 = 0.05593 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 9076.161 - ||grad||^2 = 0.05284 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 9076.162 - ||grad||^2 = 0.02625 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 9076.162 - ||grad||^2 = 0.02796 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 9076.162 - ||grad||^2 = 0.03061 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 9076.162 - ||grad||^2 = 0.02186 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 9076.162 - ||grad||^2 = 0.03628 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 9076.161 - ||grad||^2 = 0.04726 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 9076.163 - ||grad||^2 = 0.04716 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 9076.161 - ||grad||^2 = 0.04888 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 9076.162 - ||grad||^2 = 0.03647 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 9076.162 - ||grad||^2 = 0.03405 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 9076.162 - ||grad||^2 = 0.04161 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662514922807,"user_tz":-540,"elapsed":18,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"44754a37-b9d6-4635-d992-1faf6723ce02","id":"kqP_Qt-sks_V"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.828600\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"HxqEXQjQks_V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-15000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662514922807,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"4465a1dd-bffe-4f13-e22d-8dc5e328fe21","id":"gzx8P3Roks_V"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-15000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-aug-20000"],"metadata":{"id":"YgU3RkC1k2U_"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"8RntqElyk2VA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-nonAR/TGAN-syn-imbar-nonAR-20000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"mim00e_Tk2VA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"YzqqbRP9k2VA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"Mbmg-lvak2VB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"BARWVmQAk2VB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"ZrswCew7k2VB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"NBj1GD1dk2VB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"6UYtUSbBk2VB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"cbA5I0Vrk2VB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662515321340,"user_tz":-540,"elapsed":328673,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"669e86c8-3943-43a4-8013-a694a73a1ad5","id":"U1ojnpgTk2VB"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 1672691.680 - ||grad||^2 = 2626335.64482 - ||diff_w|| = 14.07636\n"," * Iteration #2 - Loss = 424439.007 - ||grad||^2 = 1330783.75637 - ||diff_w|| = 6.30803\n"," * Iteration #3 - Loss = 132247.972 - ||grad||^2 = 741651.48288 - ||diff_w|| = 3.40006\n"," * Iteration #4 - Loss = 44314.124 - ||grad||^2 = 398363.29280 - ||diff_w|| = 1.68447\n"," * Iteration #5 - Loss = 20864.771 - ||grad||^2 = 193664.99718 - ||diff_w|| = 0.71976\n"," * Iteration #6 - Loss = 16438.440 - ||grad||^2 = 88538.27327 - ||diff_w|| = 0.32532\n"," * Iteration #7 - Loss = 16063.049 - ||grad||^2 = 35922.77545 - ||diff_w|| = 0.13983\n"," * Iteration #8 - Loss = 16120.709 - ||grad||^2 = 12658.87497 - ||diff_w|| = 0.05803\n"," * Iteration #9 - Loss = 16138.362 - ||grad||^2 = 4580.12904 - ||diff_w|| = 0.02640\n"," * Iteration #10 - Loss = 16141.674 - ||grad||^2 = 1757.04556 - ||diff_w|| = 0.01278\n"," * Iteration #11 - Loss = 16142.257 - ||grad||^2 = 715.86215 - ||diff_w|| = 0.00640\n"," * Iteration #12 - Loss = 16142.514 - ||grad||^2 = 315.63745 - ||diff_w|| = 0.00329\n"," * Iteration #13 - Loss = 16142.548 - ||grad||^2 = 149.96107 - ||diff_w|| = 0.00174\n"," * Iteration #14 - Loss = 16142.558 - ||grad||^2 = 75.37489 - ||diff_w|| = 0.00094\n"," * Iteration #15 - Loss = 16142.564 - ||grad||^2 = 38.71014 - ||diff_w|| = 0.00051\n"," * Iteration #16 - Loss = 16142.556 - ||grad||^2 = 20.58524 - ||diff_w|| = 0.00027\n"," * Iteration #17 - Loss = 16142.561 - ||grad||^2 = 11.02908 - ||diff_w|| = 0.00015\n"," * Iteration #18 - Loss = 16142.560 - ||grad||^2 = 5.87399 - ||diff_w|| = 0.00008\n"," * Iteration #19 - Loss = 16142.560 - ||grad||^2 = 3.15872 - ||diff_w|| = 0.00005\n"," * Iteration #20 - Loss = 16142.561 - ||grad||^2 = 1.68712 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 16142.560 - ||grad||^2 = 0.92959 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 16142.561 - ||grad||^2 = 0.50922 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 16142.561 - ||grad||^2 = 0.28712 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 16142.561 - ||grad||^2 = 0.15357 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 16142.560 - ||grad||^2 = 0.08828 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 16142.561 - ||grad||^2 = 0.04855 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 16142.560 - ||grad||^2 = 0.03911 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 16142.561 - ||grad||^2 = 0.02902 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 16142.561 - ||grad||^2 = 0.02805 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 16142.561 - ||grad||^2 = 0.01750 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 16142.561 - ||grad||^2 = 0.02196 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 16142.561 - ||grad||^2 = 0.02415 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 16142.561 - ||grad||^2 = 0.01947 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 16142.561 - ||grad||^2 = 0.02111 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 16142.561 - ||grad||^2 = 0.02177 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 16142.560 - ||grad||^2 = 0.02036 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 16142.561 - ||grad||^2 = 0.02443 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 16142.560 - ||grad||^2 = 0.02161 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 16142.561 - ||grad||^2 = 0.02149 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 16142.561 - ||grad||^2 = 0.02154 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 16142.561 - ||grad||^2 = 0.02031 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 16142.560 - ||grad||^2 = 0.01999 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 16142.561 - ||grad||^2 = 0.02656 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 16142.560 - ||grad||^2 = 0.02146 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 16142.561 - ||grad||^2 = 0.01981 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 16142.561 - ||grad||^2 = 0.02050 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 16142.561 - ||grad||^2 = 0.02249 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 16142.560 - ||grad||^2 = 0.02006 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 16142.561 - ||grad||^2 = 0.02447 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 16142.561 - ||grad||^2 = 0.02257 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 16142.561 - ||grad||^2 = 0.02048 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 16142.561 - ||grad||^2 = 0.02068 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 16142.561 - ||grad||^2 = 0.02193 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 16142.560 - ||grad||^2 = 0.02023 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 16142.561 - ||grad||^2 = 0.02450 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 16142.560 - ||grad||^2 = 0.02156 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 16142.561 - ||grad||^2 = 0.02150 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 16142.561 - ||grad||^2 = 0.02154 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 16142.561 - ||grad||^2 = 0.02032 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 16142.560 - ||grad||^2 = 0.01999 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 16142.561 - ||grad||^2 = 0.02656 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 16142.560 - ||grad||^2 = 0.02146 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 16142.561 - ||grad||^2 = 0.01981 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 16142.561 - ||grad||^2 = 0.02050 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 16142.561 - ||grad||^2 = 0.02249 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 16142.560 - ||grad||^2 = 0.02006 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 16142.561 - ||grad||^2 = 0.02447 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 16142.561 - ||grad||^2 = 0.02257 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 16142.561 - ||grad||^2 = 0.02048 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 16142.561 - ||grad||^2 = 0.02068 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 16142.561 - ||grad||^2 = 0.02193 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 16142.560 - ||grad||^2 = 0.02023 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 16142.561 - ||grad||^2 = 0.02450 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 16142.560 - ||grad||^2 = 0.02156 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 16142.561 - ||grad||^2 = 0.02150 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 16142.561 - ||grad||^2 = 0.02154 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 16142.561 - ||grad||^2 = 0.02032 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 16142.560 - ||grad||^2 = 0.01999 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 16142.561 - ||grad||^2 = 0.02656 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 16142.560 - ||grad||^2 = 0.02146 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 16142.561 - ||grad||^2 = 0.01981 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 16142.561 - ||grad||^2 = 0.02050 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 16142.561 - ||grad||^2 = 0.02249 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 16142.560 - ||grad||^2 = 0.02006 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 16142.561 - ||grad||^2 = 0.02447 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 16142.561 - ||grad||^2 = 0.02257 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 16142.561 - ||grad||^2 = 0.02048 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 16142.561 - ||grad||^2 = 0.02068 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 16142.561 - ||grad||^2 = 0.02193 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 16142.560 - ||grad||^2 = 0.02023 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 16142.561 - ||grad||^2 = 0.02450 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 16142.560 - ||grad||^2 = 0.02156 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 16142.561 - ||grad||^2 = 0.02150 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 16142.561 - ||grad||^2 = 0.02154 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 16142.561 - ||grad||^2 = 0.02032 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 16142.560 - ||grad||^2 = 0.01999 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 16142.561 - ||grad||^2 = 0.02656 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 16142.560 - ||grad||^2 = 0.02146 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 16142.561 - ||grad||^2 = 0.01981 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 16142.561 - ||grad||^2 = 0.02050 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662515321341,"user_tz":-540,"elapsed":21,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"890fb61d-0f08-4cd1-e394-a5fce023701d","id":"tvJnXsBJk2VC"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.829053\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"LLiK6BGvk2VC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-20000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662515321341,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"9144e295-c79a-41a6-a3a4-36391fbf6795","id":"kV98qksck2VC"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-20000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-aug-25000"],"metadata":{"id":"eiBupHOUmYZY"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"_4XDCAI6mYZY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-nonAR/TGAN-syn-imbar-nonAR-25000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"HImHi1lPmYZZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"QUSob7unmYZZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"q95WQ-1bmYZZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"jYNil34smYZZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"LDAVp4ycmYZZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"obhRalSbmYZZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"bvxwWNY5mYZZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"s43iTLEPmYZZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662515946742,"user_tz":-540,"elapsed":520278,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"56ee489d-f948-4b29-e373-16251cfcb77a","id":"o2lNzL2FmYZZ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 5126602.510 - ||grad||^2 = 6875661.80401 - ||diff_w|| = 19.36605\n"," * Iteration #2 - Loss = 1295422.764 - ||grad||^2 = 3484714.43881 - ||diff_w|| = 8.69887\n"," * Iteration #3 - Loss = 397714.326 - ||grad||^2 = 1950927.72513 - ||diff_w|| = 4.74391\n"," * Iteration #4 - Loss = 124323.492 - ||grad||^2 = 1084421.79927 - ||diff_w|| = 2.48604\n"," * Iteration #5 - Loss = 45033.209 - ||grad||^2 = 566113.62576 - ||diff_w|| = 1.11842\n"," * Iteration #6 - Loss = 27223.249 - ||grad||^2 = 266649.13867 - ||diff_w|| = 0.47299\n"," * Iteration #7 - Loss = 24820.293 - ||grad||^2 = 106433.17853 - ||diff_w|| = 0.22254\n"," * Iteration #8 - Loss = 24857.896 - ||grad||^2 = 38548.86699 - ||diff_w|| = 0.09628\n"," * Iteration #9 - Loss = 24917.333 - ||grad||^2 = 16023.62590 - ||diff_w|| = 0.03955\n"," * Iteration #10 - Loss = 24921.042 - ||grad||^2 = 7316.47099 - ||diff_w|| = 0.01826\n"," * Iteration #11 - Loss = 24919.854 - ||grad||^2 = 3561.48196 - ||diff_w|| = 0.00904\n"," * Iteration #12 - Loss = 24919.223 - ||grad||^2 = 1769.14964 - ||diff_w|| = 0.00473\n"," * Iteration #13 - Loss = 24919.010 - ||grad||^2 = 897.38952 - ||diff_w|| = 0.00252\n"," * Iteration #14 - Loss = 24918.935 - ||grad||^2 = 461.90496 - ||diff_w|| = 0.00138\n"," * Iteration #15 - Loss = 24918.934 - ||grad||^2 = 240.69357 - ||diff_w|| = 0.00076\n"," * Iteration #16 - Loss = 24918.896 - ||grad||^2 = 126.80042 - ||diff_w|| = 0.00042\n"," * Iteration #17 - Loss = 24918.899 - ||grad||^2 = 67.56742 - ||diff_w|| = 0.00023\n"," * Iteration #18 - Loss = 24918.904 - ||grad||^2 = 36.00453 - ||diff_w|| = 0.00013\n"," * Iteration #19 - Loss = 24918.903 - ||grad||^2 = 19.25600 - ||diff_w|| = 0.00007\n"," * Iteration #20 - Loss = 24918.903 - ||grad||^2 = 10.34180 - ||diff_w|| = 0.00004\n"," * Iteration #21 - Loss = 24918.902 - ||grad||^2 = 5.55989 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 24918.903 - ||grad||^2 = 3.04774 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 24918.901 - ||grad||^2 = 1.62240 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 24918.904 - ||grad||^2 = 0.91498 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 24918.901 - ||grad||^2 = 0.46034 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 24918.903 - ||grad||^2 = 0.27750 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 24918.901 - ||grad||^2 = 0.13614 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 24918.904 - ||grad||^2 = 0.11672 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 24918.901 - ||grad||^2 = 0.09535 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 24918.904 - ||grad||^2 = 0.09616 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 24918.900 - ||grad||^2 = 0.10528 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 24918.905 - ||grad||^2 = 0.12387 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 24918.901 - ||grad||^2 = 0.10531 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 24918.904 - ||grad||^2 = 0.09556 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 24918.901 - ||grad||^2 = 0.09282 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 24918.904 - ||grad||^2 = 0.10239 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 24918.901 - ||grad||^2 = 0.09653 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 24918.904 - ||grad||^2 = 0.09565 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 24918.900 - ||grad||^2 = 0.10899 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 24918.905 - ||grad||^2 = 0.11890 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 24918.901 - ||grad||^2 = 0.08566 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 24918.903 - ||grad||^2 = 0.06707 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 24918.902 - ||grad||^2 = 0.06163 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 24918.903 - ||grad||^2 = 0.05702 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 24918.903 - ||grad||^2 = 0.07134 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 24918.903 - ||grad||^2 = 0.06879 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 24918.902 - ||grad||^2 = 0.08038 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 24918.903 - ||grad||^2 = 0.08988 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 24918.902 - ||grad||^2 = 0.07362 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 24918.903 - ||grad||^2 = 0.06328 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 24918.902 - ||grad||^2 = 0.07685 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 24918.903 - ||grad||^2 = 0.07508 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 24918.902 - ||grad||^2 = 0.06647 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 24918.904 - ||grad||^2 = 0.08795 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 24918.901 - ||grad||^2 = 0.09073 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 24918.904 - ||grad||^2 = 0.11114 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 24918.901 - ||grad||^2 = 0.10698 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 24918.904 - ||grad||^2 = 0.10389 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 24918.900 - ||grad||^2 = 0.11648 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 24918.904 - ||grad||^2 = 0.11260 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 24918.901 - ||grad||^2 = 0.09874 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 24918.904 - ||grad||^2 = 0.08676 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 24918.901 - ||grad||^2 = 0.07874 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 24918.903 - ||grad||^2 = 0.07390 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 24918.902 - ||grad||^2 = 0.07243 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 24918.904 - ||grad||^2 = 0.07168 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 24918.901 - ||grad||^2 = 0.08368 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 24918.904 - ||grad||^2 = 0.08958 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 24918.901 - ||grad||^2 = 0.08414 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 24918.904 - ||grad||^2 = 0.09662 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 24918.901 - ||grad||^2 = 0.10524 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 24918.904 - ||grad||^2 = 0.10896 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 24918.901 - ||grad||^2 = 0.10368 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 24918.904 - ||grad||^2 = 0.09983 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 24918.901 - ||grad||^2 = 0.08792 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 24918.904 - ||grad||^2 = 0.08603 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 24918.901 - ||grad||^2 = 0.09983 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 24918.904 - ||grad||^2 = 0.09506 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 24918.901 - ||grad||^2 = 0.07711 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 24918.904 - ||grad||^2 = 0.07721 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 24918.901 - ||grad||^2 = 0.08447 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 24918.904 - ||grad||^2 = 0.08642 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 24918.901 - ||grad||^2 = 0.08424 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 24918.904 - ||grad||^2 = 0.08893 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 24918.901 - ||grad||^2 = 0.08553 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 24918.904 - ||grad||^2 = 0.09715 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 24918.901 - ||grad||^2 = 0.10503 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 24918.905 - ||grad||^2 = 0.12104 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 24918.900 - ||grad||^2 = 0.12217 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 24918.904 - ||grad||^2 = 0.10912 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 24918.901 - ||grad||^2 = 0.08598 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 24918.903 - ||grad||^2 = 0.06503 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 24918.902 - ||grad||^2 = 0.05887 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 24918.903 - ||grad||^2 = 0.05475 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 24918.901 - ||grad||^2 = 0.08029 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 24918.904 - ||grad||^2 = 0.10832 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 24918.901 - ||grad||^2 = 0.11227 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 24918.904 - ||grad||^2 = 0.09049 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 24918.901 - ||grad||^2 = 0.08223 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 24918.904 - ||grad||^2 = 0.09580 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662515946742,"user_tz":-540,"elapsed":21,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"1ef80795-b55b-41a4-c9fc-1c4289858745","id":"zLS1YCx6mYZZ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.828902\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"FGVWYTITmYZZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-25000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662515946742,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"b54f0741-9c61-45c4-9a44-2bc65412a06a","id":"QkhVpw7tmYZZ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-25000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-aug-30000"],"metadata":{"id":"lUuOesr7mhrU"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"-sHGayv0mhrV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-nonAR/TGAN-syn-imbar-nonAR-30000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"c9ODuTc3mhrV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"TuntCv4jmhrV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"d_iDSNgCmhrV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"_gPl2-TnmhrV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"8XUslPZKmhrV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"UN6HjO24mhrW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"C-Ju4jGjmhrW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"9b5OfcUemhrW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662600203179,"user_tz":-540,"elapsed":788988,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"5b905c81-1ec3-4ae6-c578-003c4dfd5f69","id":"fCfYAft9mhrW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 3878208.837 - ||grad||^2 = 5519710.00138 - ||diff_w|| = 17.51438\n"," * Iteration #2 - Loss = 992759.802 - ||grad||^2 = 2818569.60113 - ||diff_w|| = 7.86127\n"," * Iteration #3 - Loss = 313681.873 - ||grad||^2 = 1606249.86804 - ||diff_w|| = 4.26734\n"," * Iteration #4 - Loss = 105770.749 - ||grad||^2 = 907484.48217 - ||diff_w|| = 2.15466\n"," * Iteration #5 - Loss = 45823.196 - ||grad||^2 = 413087.25005 - ||diff_w|| = 0.82952\n"," * Iteration #6 - Loss = 35191.767 - ||grad||^2 = 150330.86130 - ||diff_w|| = 0.32610\n"," * Iteration #7 - Loss = 35259.060 - ||grad||^2 = 45940.80580 - ||diff_w|| = 0.14203\n"," * Iteration #8 - Loss = 35313.416 - ||grad||^2 = 15318.98041 - ||diff_w|| = 0.05917\n"," * Iteration #9 - Loss = 35318.030 - ||grad||^2 = 5733.00254 - ||diff_w|| = 0.02598\n"," * Iteration #10 - Loss = 35318.522 - ||grad||^2 = 2260.95742 - ||diff_w|| = 0.01233\n"," * Iteration #11 - Loss = 35318.532 - ||grad||^2 = 917.28641 - ||diff_w|| = 0.00610\n"," * Iteration #12 - Loss = 35318.548 - ||grad||^2 = 384.61175 - ||diff_w|| = 0.00310\n"," * Iteration #13 - Loss = 35318.553 - ||grad||^2 = 171.90748 - ||diff_w|| = 0.00162\n"," * Iteration #14 - Loss = 35318.533 - ||grad||^2 = 78.58939 - ||diff_w|| = 0.00085\n"," * Iteration #15 - Loss = 35318.547 - ||grad||^2 = 36.76395 - ||diff_w|| = 0.00046\n"," * Iteration #16 - Loss = 35318.552 - ||grad||^2 = 17.71263 - ||diff_w|| = 0.00025\n"," * Iteration #17 - Loss = 35318.563 - ||grad||^2 = 8.55055 - ||diff_w|| = 0.00013\n"," * Iteration #18 - Loss = 35318.555 - ||grad||^2 = 4.38157 - ||diff_w|| = 0.00007\n"," * Iteration #19 - Loss = 35318.557 - ||grad||^2 = 2.15170 - ||diff_w|| = 0.00004\n"," * Iteration #20 - Loss = 35318.557 - ||grad||^2 = 1.05496 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 35318.555 - ||grad||^2 = 0.59428 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 35318.556 - ||grad||^2 = 0.31010 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 35318.556 - ||grad||^2 = 0.16139 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 35318.556 - ||grad||^2 = 0.08365 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 35318.555 - ||grad||^2 = 0.06189 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 35318.556 - ||grad||^2 = 0.03432 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 35318.556 - ||grad||^2 = 0.01683 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 35318.556 - ||grad||^2 = 0.01849 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 35318.555 - ||grad||^2 = 0.02811 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 35318.556 - ||grad||^2 = 0.02642 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 35318.555 - ||grad||^2 = 0.02693 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 35318.556 - ||grad||^2 = 0.02273 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 35318.555 - ||grad||^2 = 0.02503 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 35318.556 - ||grad||^2 = 0.02761 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 35318.556 - ||grad||^2 = 0.01549 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 35318.556 - ||grad||^2 = 0.01747 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 35318.555 - ||grad||^2 = 0.02801 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 35318.556 - ||grad||^2 = 0.02614 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 35318.555 - ||grad||^2 = 0.02700 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 35318.556 - ||grad||^2 = 0.02276 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 35318.555 - ||grad||^2 = 0.02506 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 35318.556 - ||grad||^2 = 0.02758 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 35318.556 - ||grad||^2 = 0.01553 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 35318.556 - ||grad||^2 = 0.01747 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 35318.555 - ||grad||^2 = 0.02801 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 35318.556 - ||grad||^2 = 0.02613 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 35318.555 - ||grad||^2 = 0.02700 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 35318.556 - ||grad||^2 = 0.02276 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 35318.555 - ||grad||^2 = 0.02506 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 35318.556 - ||grad||^2 = 0.02758 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 35318.556 - ||grad||^2 = 0.01553 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 35318.556 - ||grad||^2 = 0.01747 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 35318.555 - ||grad||^2 = 0.02801 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 35318.556 - ||grad||^2 = 0.02613 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 35318.555 - ||grad||^2 = 0.02700 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 35318.556 - ||grad||^2 = 0.02276 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 35318.555 - ||grad||^2 = 0.02506 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 35318.556 - ||grad||^2 = 0.02758 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 35318.556 - ||grad||^2 = 0.01553 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 35318.556 - ||grad||^2 = 0.01747 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 35318.555 - ||grad||^2 = 0.02801 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 35318.556 - ||grad||^2 = 0.02613 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 35318.555 - ||grad||^2 = 0.02700 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 35318.556 - ||grad||^2 = 0.02276 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 35318.555 - ||grad||^2 = 0.02506 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 35318.556 - ||grad||^2 = 0.02758 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 35318.556 - ||grad||^2 = 0.01553 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 35318.556 - ||grad||^2 = 0.01747 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 35318.555 - ||grad||^2 = 0.02801 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 35318.556 - ||grad||^2 = 0.02613 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 35318.555 - ||grad||^2 = 0.02700 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 35318.556 - ||grad||^2 = 0.02276 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 35318.555 - ||grad||^2 = 0.02506 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 35318.556 - ||grad||^2 = 0.02758 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 35318.556 - ||grad||^2 = 0.01553 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 35318.556 - ||grad||^2 = 0.01747 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 35318.555 - ||grad||^2 = 0.02801 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 35318.556 - ||grad||^2 = 0.02613 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 35318.555 - ||grad||^2 = 0.02700 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 35318.556 - ||grad||^2 = 0.02276 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 35318.555 - ||grad||^2 = 0.02506 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 35318.556 - ||grad||^2 = 0.02758 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 35318.556 - ||grad||^2 = 0.01553 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 35318.556 - ||grad||^2 = 0.01747 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 35318.555 - ||grad||^2 = 0.02801 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 35318.556 - ||grad||^2 = 0.02613 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 35318.555 - ||grad||^2 = 0.02700 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 35318.556 - ||grad||^2 = 0.02276 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 35318.555 - ||grad||^2 = 0.02506 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 35318.556 - ||grad||^2 = 0.02758 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 35318.556 - ||grad||^2 = 0.01553 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 35318.556 - ||grad||^2 = 0.01747 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 35318.555 - ||grad||^2 = 0.02801 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 35318.556 - ||grad||^2 = 0.02613 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 35318.555 - ||grad||^2 = 0.02700 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 35318.556 - ||grad||^2 = 0.02276 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 35318.555 - ||grad||^2 = 0.02506 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 35318.556 - ||grad||^2 = 0.02758 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 35318.556 - ||grad||^2 = 0.01553 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 35318.556 - ||grad||^2 = 0.01747 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662600203180,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"527d0751-a24c-464e-be42-1154f74bfeee","id":"7D56Sx6jmhrW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.829702\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"xMg-KCJgmhrW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-30000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662600203180,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"eba0e3f9-3560-4a6c-984e-1f529fe80bea","id":"YVb-MmehmhrW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-30000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-aug-35000"],"metadata":{"id":"vMwfd9-XpCFB"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"qgBxWu0npCFC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-nonAR/TGAN-syn-imbar-nonAR-35000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"_m265STBpCFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"kDyNCiOdpCFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"eLQe0zEJpCFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"HRo-TX6JpCFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"jTfmibFgpCFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"JVLv0YxgpCFD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"PSsbdFwfpCFE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"whx5z6ofpCFE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662601804264,"user_tz":-540,"elapsed":585944,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"4631d4c1-3d5c-4970-cace-2a28ae57bcd8","id":"gbesPojYpCFE"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 7599275.567 - ||grad||^2 = 11871713.02894 - ||diff_w|| = 14.88904\n"," * Iteration #2 - Loss = 1922508.074 - ||grad||^2 = 6007609.38805 - ||diff_w|| = 6.68104\n"," * Iteration #3 - Loss = 592763.983 - ||grad||^2 = 3351742.91713 - ||diff_w|| = 3.62653\n"," * Iteration #4 - Loss = 189165.259 - ||grad||^2 = 1845298.03442 - ||diff_w|| = 1.86048\n"," * Iteration #5 - Loss = 75337.262 - ||grad||^2 = 958113.09306 - ||diff_w|| = 0.81697\n"," * Iteration #6 - Loss = 51380.390 - ||grad||^2 = 448800.19958 - ||diff_w|| = 0.36868\n"," * Iteration #7 - Loss = 48602.881 - ||grad||^2 = 170317.34228 - ||diff_w|| = 0.16703\n"," * Iteration #8 - Loss = 48909.786 - ||grad||^2 = 61098.69898 - ||diff_w|| = 0.06427\n"," * Iteration #9 - Loss = 48989.676 - ||grad||^2 = 25265.11260 - ||diff_w|| = 0.02632\n"," * Iteration #10 - Loss = 48992.175 - ||grad||^2 = 10643.13011 - ||diff_w|| = 0.01211\n"," * Iteration #11 - Loss = 48991.415 - ||grad||^2 = 4774.98284 - ||diff_w|| = 0.00601\n"," * Iteration #12 - Loss = 48990.767 - ||grad||^2 = 2239.89268 - ||diff_w|| = 0.00315\n"," * Iteration #13 - Loss = 48990.534 - ||grad||^2 = 1097.03275 - ||diff_w|| = 0.00169\n"," * Iteration #14 - Loss = 48990.519 - ||grad||^2 = 554.76391 - ||diff_w|| = 0.00092\n"," * Iteration #15 - Loss = 48990.460 - ||grad||^2 = 286.88758 - ||diff_w|| = 0.00050\n"," * Iteration #16 - Loss = 48990.467 - ||grad||^2 = 150.76840 - ||diff_w|| = 0.00027\n"," * Iteration #17 - Loss = 48990.474 - ||grad||^2 = 80.28809 - ||diff_w|| = 0.00015\n"," * Iteration #18 - Loss = 48990.467 - ||grad||^2 = 42.77469 - ||diff_w|| = 0.00008\n"," * Iteration #19 - Loss = 48990.471 - ||grad||^2 = 23.03376 - ||diff_w|| = 0.00004\n"," * Iteration #20 - Loss = 48990.471 - ||grad||^2 = 12.45542 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 48990.470 - ||grad||^2 = 6.79258 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 48990.470 - ||grad||^2 = 3.70466 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 48990.469 - ||grad||^2 = 2.02405 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 48990.470 - ||grad||^2 = 1.10310 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 48990.470 - ||grad||^2 = 0.59502 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 48990.470 - ||grad||^2 = 0.33632 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 48990.469 - ||grad||^2 = 0.16672 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 48990.470 - ||grad||^2 = 0.09368 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 48990.470 - ||grad||^2 = 0.06583 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 48990.470 - ||grad||^2 = 0.03551 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 48990.469 - ||grad||^2 = 0.03227 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 48990.470 - ||grad||^2 = 0.02914 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 48990.470 - ||grad||^2 = 0.03453 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 48990.470 - ||grad||^2 = 0.03569 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 48990.469 - ||grad||^2 = 0.03109 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 48990.470 - ||grad||^2 = 0.02405 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 48990.470 - ||grad||^2 = 0.01369 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 48990.470 - ||grad||^2 = 0.03320 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 48990.470 - ||grad||^2 = 0.02968 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 48990.470 - ||grad||^2 = 0.02367 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 48990.469 - ||grad||^2 = 0.04200 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 48990.470 - ||grad||^2 = 0.02710 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 48990.470 - ||grad||^2 = 0.02406 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 48990.470 - ||grad||^2 = 0.01940 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 48990.470 - ||grad||^2 = 0.01335 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 48990.470 - ||grad||^2 = 0.01929 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 48990.471 - ||grad||^2 = 0.02678 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 48990.470 - ||grad||^2 = 0.01719 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 48990.470 - ||grad||^2 = 0.02792 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 48990.470 - ||grad||^2 = 0.02768 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 48990.470 - ||grad||^2 = 0.03372 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 48990.470 - ||grad||^2 = 0.02753 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 48990.469 - ||grad||^2 = 0.01825 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 48990.470 - ||grad||^2 = 0.02237 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 48990.469 - ||grad||^2 = 0.02673 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 48990.471 - ||grad||^2 = 0.02734 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 48990.470 - ||grad||^2 = 0.01490 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 48990.470 - ||grad||^2 = 0.02492 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 48990.470 - ||grad||^2 = 0.02589 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 48990.470 - ||grad||^2 = 0.03921 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 48990.470 - ||grad||^2 = 0.02873 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 48990.470 - ||grad||^2 = 0.02380 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 48990.470 - ||grad||^2 = 0.01566 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 48990.469 - ||grad||^2 = 0.02420 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 48990.471 - ||grad||^2 = 0.03819 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 48990.470 - ||grad||^2 = 0.01685 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 48990.469 - ||grad||^2 = 0.03020 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 48990.470 - ||grad||^2 = 0.01766 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 48990.470 - ||grad||^2 = 0.02706 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 48990.470 - ||grad||^2 = 0.01443 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 48990.469 - ||grad||^2 = 0.02886 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 48990.470 - ||grad||^2 = 0.02874 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 48990.470 - ||grad||^2 = 0.03287 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 48990.470 - ||grad||^2 = 0.03570 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 48990.469 - ||grad||^2 = 0.03090 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 48990.470 - ||grad||^2 = 0.02407 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 48990.470 - ||grad||^2 = 0.01350 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 48990.470 - ||grad||^2 = 0.03325 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 48990.470 - ||grad||^2 = 0.02968 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 48990.470 - ||grad||^2 = 0.02366 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 48990.469 - ||grad||^2 = 0.04200 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 48990.470 - ||grad||^2 = 0.02710 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 48990.470 - ||grad||^2 = 0.02406 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 48990.470 - ||grad||^2 = 0.01940 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 48990.470 - ||grad||^2 = 0.01335 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 48990.470 - ||grad||^2 = 0.01929 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 48990.471 - ||grad||^2 = 0.02678 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 48990.470 - ||grad||^2 = 0.01719 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 48990.470 - ||grad||^2 = 0.02792 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 48990.470 - ||grad||^2 = 0.02768 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 48990.470 - ||grad||^2 = 0.03372 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 48990.470 - ||grad||^2 = 0.02753 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 48990.469 - ||grad||^2 = 0.01825 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 48990.470 - ||grad||^2 = 0.02237 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 48990.469 - ||grad||^2 = 0.02673 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 48990.471 - ||grad||^2 = 0.02734 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 48990.470 - ||grad||^2 = 0.01490 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 48990.470 - ||grad||^2 = 0.02492 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 48990.470 - ||grad||^2 = 0.02589 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 48990.470 - ||grad||^2 = 0.03921 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662601804264,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"3e55e438-6439-4e6c-fa0a-cd5965d19479","id":"LOWWUr1ppCFE"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.831275\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"EgWPlZZ_pCFF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-35000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662601804265,"user_tz":-540,"elapsed":3,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"97a87bce-c7cd-4c47-816d-c5634a4f7794","id":"fP3bw9EbpCFF"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-35000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-aug-40000"],"metadata":{"id":"q8B9qsPWpEo3"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"rFe2PrwspEo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-nonAR/TGAN-syn-imbar-nonAR-40000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"SfqgrGuppEo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"0ykwt_1vpEo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"YbADmb0XpEo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"dpNVXTcOpEo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"g2ZJzKVkpEo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"0ZRl3yiLpEo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"kjkbTktKpEo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"uOmFGylQpEo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662603530154,"user_tz":-540,"elapsed":1472634,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"0e62885f-5015-4ab4-a971-89018a2a48a5","id":"o34aPlfFpEo4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 5369581.148 - ||grad||^2 = 9453948.89009 - ||diff_w|| = 17.62188\n"," * Iteration #2 - Loss = 1372424.893 - ||grad||^2 = 4778937.86501 - ||diff_w|| = 7.89496\n"," * Iteration #3 - Loss = 435408.798 - ||grad||^2 = 2648818.21589 - ||diff_w|| = 4.23658\n"," * Iteration #4 - Loss = 153379.889 - ||grad||^2 = 1402306.19971 - ||diff_w|| = 2.00184\n"," * Iteration #5 - Loss = 78976.090 - ||grad||^2 = 666331.17235 - ||diff_w|| = 0.69830\n"," * Iteration #6 - Loss = 67036.390 - ||grad||^2 = 299339.19177 - ||diff_w|| = 0.28310\n"," * Iteration #7 - Loss = 66012.057 - ||grad||^2 = 116021.09687 - ||diff_w|| = 0.12546\n"," * Iteration #8 - Loss = 66050.343 - ||grad||^2 = 43563.87966 - ||diff_w|| = 0.05430\n"," * Iteration #9 - Loss = 66068.685 - ||grad||^2 = 18982.19760 - ||diff_w|| = 0.02477\n"," * Iteration #10 - Loss = 66071.172 - ||grad||^2 = 8966.82405 - ||diff_w|| = 0.01210\n"," * Iteration #11 - Loss = 66070.965 - ||grad||^2 = 4449.25235 - ||diff_w|| = 0.00623\n"," * Iteration #12 - Loss = 66070.886 - ||grad||^2 = 2273.46565 - ||diff_w|| = 0.00333\n"," * Iteration #13 - Loss = 66070.883 - ||grad||^2 = 1190.13147 - ||diff_w|| = 0.00181\n"," * Iteration #14 - Loss = 66070.854 - ||grad||^2 = 631.48944 - ||diff_w|| = 0.00099\n"," * Iteration #15 - Loss = 66070.843 - ||grad||^2 = 339.06541 - ||diff_w|| = 0.00055\n"," * Iteration #16 - Loss = 66070.833 - ||grad||^2 = 182.06787 - ||diff_w|| = 0.00030\n"," * Iteration #17 - Loss = 66070.837 - ||grad||^2 = 98.33209 - ||diff_w|| = 0.00016\n"," * Iteration #18 - Loss = 66070.834 - ||grad||^2 = 53.06434 - ||diff_w|| = 0.00009\n"," * Iteration #19 - Loss = 66070.837 - ||grad||^2 = 28.72605 - ||diff_w|| = 0.00005\n"," * Iteration #20 - Loss = 66070.837 - ||grad||^2 = 15.58309 - ||diff_w|| = 0.00003\n"," * Iteration #21 - Loss = 66070.838 - ||grad||^2 = 8.48179 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 66070.837 - ||grad||^2 = 4.59096 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 66070.839 - ||grad||^2 = 2.51879 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 66070.838 - ||grad||^2 = 1.32427 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 66070.838 - ||grad||^2 = 0.73177 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 66070.838 - ||grad||^2 = 0.40868 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 66070.838 - ||grad||^2 = 0.21783 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 66070.838 - ||grad||^2 = 0.12860 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 66070.838 - ||grad||^2 = 0.06541 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 66070.837 - ||grad||^2 = 0.03809 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 66070.839 - ||grad||^2 = 0.05168 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 66070.837 - ||grad||^2 = 0.04549 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 66070.839 - ||grad||^2 = 0.04988 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 66070.837 - ||grad||^2 = 0.04572 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 66070.839 - ||grad||^2 = 0.04514 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 66070.837 - ||grad||^2 = 0.04546 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 66070.839 - ||grad||^2 = 0.04868 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 66070.837 - ||grad||^2 = 0.04583 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 66070.839 - ||grad||^2 = 0.04508 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 66070.837 - ||grad||^2 = 0.04549 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 66070.839 - ||grad||^2 = 0.04861 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 66070.839 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 66070.839 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 66070.839 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 66070.839 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 66070.839 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 66070.839 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 66070.839 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 66070.839 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 66070.839 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 66070.839 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 66070.839 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 66070.839 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 66070.839 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 66070.839 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 66070.837 - ||grad||^2 = 0.04585 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 66070.839 - ||grad||^2 = 0.04507 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 66070.837 - ||grad||^2 = 0.04550 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662603530155,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"53efde8d-2abd-428d-e29e-eabb18c5e845","id":"3doqZq8-pEo4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.829755\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"cZtz3IbppEo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-40000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662603530155,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"734d31d7-9216-4a40-e36f-ed56ed8967da","id":"vv4faL4qpEo4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-40000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-aug-45000"],"metadata":{"id":"xqUY7ln6pPLc"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"4IQloyVupPLd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-nonAR/TGAN-syn-imbar-nonAR-45000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"YF8mV5dspPLe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"2Yi__RbQpPLe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"JOY5APlopPLe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"r8OBiRpepPLe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"VvB-QChPpPLe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"3OSm3KfhpPLf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"epRDQYlypPLf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"4x8o7_bvpPLf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662628152927,"user_tz":-540,"elapsed":1652317,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"b0193e66-127d-4e59-a331-ee963f0ea825","id":"yyCMWx72pPLf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 5653390.523 - ||grad||^2 = 9616056.56523 - ||diff_w|| = 14.77140\n"," * Iteration #2 - Loss = 1461728.763 - ||grad||^2 = 4926067.99497 - ||diff_w|| = 6.60955\n"," * Iteration #3 - Loss = 473684.687 - ||grad||^2 = 2835497.43138 - ||diff_w|| = 3.53211\n"," * Iteration #4 - Loss = 173429.079 - ||grad||^2 = 1576100.01208 - ||diff_w|| = 1.63191\n"," * Iteration #5 - Loss = 93373.863 - ||grad||^2 = 568960.10290 - ||diff_w|| = 0.52262\n"," * Iteration #6 - Loss = 82128.746 - ||grad||^2 = 199203.76592 - ||diff_w|| = 0.18862\n"," * Iteration #7 - Loss = 81646.424 - ||grad||^2 = 69243.15675 - ||diff_w|| = 0.08380\n"," * Iteration #8 - Loss = 81659.211 - ||grad||^2 = 25574.56424 - ||diff_w|| = 0.03909\n"," * Iteration #9 - Loss = 81661.930 - ||grad||^2 = 11229.67338 - ||diff_w|| = 0.01879\n"," * Iteration #10 - Loss = 81662.404 - ||grad||^2 = 5390.38876 - ||diff_w|| = 0.00960\n"," * Iteration #11 - Loss = 81662.579 - ||grad||^2 = 2760.65807 - ||diff_w|| = 0.00502\n"," * Iteration #12 - Loss = 81662.819 - ||grad||^2 = 1505.67473 - ||diff_w|| = 0.00266\n"," * Iteration #13 - Loss = 81662.884 - ||grad||^2 = 822.62221 - ||diff_w|| = 0.00143\n"," * Iteration #14 - Loss = 81662.928 - ||grad||^2 = 447.57454 - ||diff_w|| = 0.00077\n"," * Iteration #15 - Loss = 81662.955 - ||grad||^2 = 242.89743 - ||diff_w|| = 0.00042\n"," * Iteration #16 - Loss = 81662.951 - ||grad||^2 = 131.85744 - ||diff_w|| = 0.00023\n"," * Iteration #17 - Loss = 81662.957 - ||grad||^2 = 71.39515 - ||diff_w|| = 0.00012\n"," * Iteration #18 - Loss = 81662.964 - ||grad||^2 = 38.62923 - ||diff_w|| = 0.00007\n"," * Iteration #19 - Loss = 81662.962 - ||grad||^2 = 20.81631 - ||diff_w|| = 0.00004\n"," * Iteration #20 - Loss = 81662.962 - ||grad||^2 = 11.28729 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 81662.963 - ||grad||^2 = 6.19067 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 81662.963 - ||grad||^2 = 3.32315 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 81662.962 - ||grad||^2 = 1.77738 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 81662.963 - ||grad||^2 = 0.97885 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 81662.963 - ||grad||^2 = 0.54319 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 81662.962 - ||grad||^2 = 0.30075 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 81662.963 - ||grad||^2 = 0.17793 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 81662.962 - ||grad||^2 = 0.10149 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 81662.964 - ||grad||^2 = 0.06462 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 81662.962 - ||grad||^2 = 0.04632 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 81662.963 - ||grad||^2 = 0.04438 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 81662.962 - ||grad||^2 = 0.02945 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 81662.964 - ||grad||^2 = 0.04935 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 81662.962 - ||grad||^2 = 0.04905 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 81662.963 - ||grad||^2 = 0.04031 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 81662.962 - ||grad||^2 = 0.04843 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 81662.963 - ||grad||^2 = 0.03078 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 81662.963 - ||grad||^2 = 0.01845 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 81662.963 - ||grad||^2 = 0.03506 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 81662.963 - ||grad||^2 = 0.03814 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 81662.963 - ||grad||^2 = 0.03673 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 81662.962 - ||grad||^2 = 0.05030 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 81662.963 - ||grad||^2 = 0.02537 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 81662.963 - ||grad||^2 = 0.01919 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 81662.963 - ||grad||^2 = 0.02161 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 81662.963 - ||grad||^2 = 0.01898 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 81662.963 - ||grad||^2 = 0.03006 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 81662.963 - ||grad||^2 = 0.02775 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 81662.963 - ||grad||^2 = 0.03064 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 81662.963 - ||grad||^2 = 0.02743 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 81662.963 - ||grad||^2 = 0.01614 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 81662.963 - ||grad||^2 = 0.02237 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 81662.963 - ||grad||^2 = 0.01909 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 81662.963 - ||grad||^2 = 0.01720 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 81662.963 - ||grad||^2 = 0.01889 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 81662.963 - ||grad||^2 = 0.02107 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 81662.963 - ||grad||^2 = 0.02735 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 81662.962 - ||grad||^2 = 0.04666 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 81662.964 - ||grad||^2 = 0.04046 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 81662.963 - ||grad||^2 = 0.02181 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 81662.963 - ||grad||^2 = 0.02130 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 81662.962 - ||grad||^2 = 0.03911 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 81662.964 - ||grad||^2 = 0.03874 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 81662.962 - ||grad||^2 = 0.02717 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 81662.963 - ||grad||^2 = 0.03722 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 81662.962 - ||grad||^2 = 0.05119 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 81662.963 - ||grad||^2 = 0.03132 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 81662.963 - ||grad||^2 = 0.02120 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 81662.963 - ||grad||^2 = 0.03760 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 81662.963 - ||grad||^2 = 0.02538 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 81662.963 - ||grad||^2 = 0.02315 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 81662.963 - ||grad||^2 = 0.02203 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 81662.963 - ||grad||^2 = 0.01658 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 81662.963 - ||grad||^2 = 0.01940 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 81662.963 - ||grad||^2 = 0.03869 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 81662.962 - ||grad||^2 = 0.05061 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 81662.963 - ||grad||^2 = 0.03128 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 81662.963 - ||grad||^2 = 0.01933 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 81662.963 - ||grad||^2 = 0.04084 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 81662.962 - ||grad||^2 = 0.04100 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 81662.963 - ||grad||^2 = 0.01858 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 81662.963 - ||grad||^2 = 0.02641 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 81662.963 - ||grad||^2 = 0.02125 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 81662.963 - ||grad||^2 = 0.01879 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 81662.963 - ||grad||^2 = 0.03485 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 81662.963 - ||grad||^2 = 0.02593 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 81662.963 - ||grad||^2 = 0.01659 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 81662.963 - ||grad||^2 = 0.01846 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 81662.963 - ||grad||^2 = 0.03784 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 81662.962 - ||grad||^2 = 0.04982 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 81662.963 - ||grad||^2 = 0.03056 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 81662.963 - ||grad||^2 = 0.01876 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 81662.963 - ||grad||^2 = 0.03504 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 81662.963 - ||grad||^2 = 0.03840 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 81662.963 - ||grad||^2 = 0.03664 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 81662.962 - ||grad||^2 = 0.05034 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 81662.963 - ||grad||^2 = 0.02534 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 81662.963 - ||grad||^2 = 0.01918 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 81662.963 - ||grad||^2 = 0.02161 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 81662.963 - ||grad||^2 = 0.01898 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662628152927,"user_tz":-540,"elapsed":11,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"028dfac5-14d5-4bfe-95c3-412a7c73511c","id":"Fpfkr_CCpPLf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.831461\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"X6-ZfqsQpPLf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-45000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662628152927,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"95417e1b-7c12-4c5d-827a-fe346b8d958f","id":"UCZ3p8vfpPLf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-45000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-aug-50000"],"metadata":{"id":"o9EiEJpUQkj7"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"vqMCcXblQkj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/TGAN-imbal-nonAR/TGAN-syn-imbar-nonAR-50000.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"GiyRMFP-Qkj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"AafNcvonQkj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"A3iUJfJVQkj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"IgK3gwH3Qkj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"qTHXy5mrQkj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"9AJdOSlbQkj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"zdnVHOZuQkj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"jz1_Wrb_Qkj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NiIIPM8FQkj8","executionInfo":{"status":"ok","timestamp":1662630313380,"user_tz":-540,"elapsed":2050869,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"4c552b4c-4269-4c22-a430-1e5b5647bf6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 8277014.253 - ||grad||^2 = 13726613.41928 - ||diff_w|| = 16.65035\n"," * Iteration #2 - Loss = 2102260.238 - ||grad||^2 = 6950792.68063 - ||diff_w|| = 7.45346\n"," * Iteration #3 - Loss = 658163.289 - ||grad||^2 = 3851769.41402 - ||diff_w|| = 3.98135\n"," * Iteration #4 - Loss = 228661.930 - ||grad||^2 = 2043950.42605 - ||diff_w|| = 1.88199\n"," * Iteration #5 - Loss = 121174.255 - ||grad||^2 = 1028568.53788 - ||diff_w|| = 0.80917\n"," * Iteration #6 - Loss = 102143.815 - ||grad||^2 = 463588.70096 - ||diff_w|| = 0.38495\n"," * Iteration #7 - Loss = 100565.546 - ||grad||^2 = 174604.48494 - ||diff_w|| = 0.16950\n"," * Iteration #8 - Loss = 100768.598 - ||grad||^2 = 65683.35225 - ||diff_w|| = 0.06776\n"," * Iteration #9 - Loss = 100854.461 - ||grad||^2 = 25211.71147 - ||diff_w|| = 0.02758\n"," * Iteration #10 - Loss = 100876.678 - ||grad||^2 = 10229.99415 - ||diff_w|| = 0.01196\n"," * Iteration #11 - Loss = 100883.418 - ||grad||^2 = 4570.17278 - ||diff_w|| = 0.00565\n"," * Iteration #12 - Loss = 100885.549 - ||grad||^2 = 2151.14272 - ||diff_w|| = 0.00285\n"," * Iteration #13 - Loss = 100886.442 - ||grad||^2 = 1044.51741 - ||diff_w|| = 0.00148\n"," * Iteration #14 - Loss = 100886.634 - ||grad||^2 = 526.81492 - ||diff_w|| = 0.00078\n"," * Iteration #15 - Loss = 100886.769 - ||grad||^2 = 271.99727 - ||diff_w|| = 0.00041\n"," * Iteration #16 - Loss = 100886.807 - ||grad||^2 = 142.20748 - ||diff_w|| = 0.00022\n"," * Iteration #17 - Loss = 100886.835 - ||grad||^2 = 74.93226 - ||diff_w|| = 0.00012\n"," * Iteration #18 - Loss = 100886.829 - ||grad||^2 = 39.72391 - ||diff_w|| = 0.00007\n"," * Iteration #19 - Loss = 100886.835 - ||grad||^2 = 21.06220 - ||diff_w|| = 0.00004\n"," * Iteration #20 - Loss = 100886.834 - ||grad||^2 = 11.06536 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 100886.835 - ||grad||^2 = 5.91162 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 100886.834 - ||grad||^2 = 3.13389 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 100886.836 - ||grad||^2 = 1.69356 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 100886.835 - ||grad||^2 = 0.87090 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 100886.837 - ||grad||^2 = 0.45510 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 100886.835 - ||grad||^2 = 0.25553 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 100886.837 - ||grad||^2 = 0.14826 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 100886.834 - ||grad||^2 = 0.09393 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 100886.838 - ||grad||^2 = 0.12135 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 100886.834 - ||grad||^2 = 0.08759 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 100886.837 - ||grad||^2 = 0.06792 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 100886.835 - ||grad||^2 = 0.05706 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 100886.837 - ||grad||^2 = 0.06360 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 100886.834 - ||grad||^2 = 0.07382 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 100886.838 - ||grad||^2 = 0.07352 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 100886.834 - ||grad||^2 = 0.07283 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 100886.838 - ||grad||^2 = 0.08892 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 100886.834 - ||grad||^2 = 0.08784 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 100886.838 - ||grad||^2 = 0.09033 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 100886.834 - ||grad||^2 = 0.09078 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 100886.838 - ||grad||^2 = 0.07810 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 100886.834 - ||grad||^2 = 0.07711 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 100886.838 - ||grad||^2 = 0.08191 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 100886.834 - ||grad||^2 = 0.08550 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 100886.838 - ||grad||^2 = 0.07632 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 100886.834 - ||grad||^2 = 0.07176 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 100886.837 - ||grad||^2 = 0.05949 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 100886.834 - ||grad||^2 = 0.06010 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 100886.838 - ||grad||^2 = 0.08253 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 100886.834 - ||grad||^2 = 0.08666 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 100886.838 - ||grad||^2 = 0.08751 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 100886.834 - ||grad||^2 = 0.08602 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 100886.838 - ||grad||^2 = 0.07872 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 100886.834 - ||grad||^2 = 0.09166 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 100886.838 - ||grad||^2 = 0.09891 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 100886.834 - ||grad||^2 = 0.08769 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 100886.838 - ||grad||^2 = 0.07463 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 100886.834 - ||grad||^2 = 0.06150 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 100886.838 - ||grad||^2 = 0.06882 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 100886.834 - ||grad||^2 = 0.08571 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 100886.838 - ||grad||^2 = 0.09829 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 100886.834 - ||grad||^2 = 0.08936 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 100886.837 - ||grad||^2 = 0.06529 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 100886.835 - ||grad||^2 = 0.05579 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 100886.837 - ||grad||^2 = 0.06232 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 100886.834 - ||grad||^2 = 0.07424 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 100886.838 - ||grad||^2 = 0.07313 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 100886.834 - ||grad||^2 = 0.07295 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 100886.838 - ||grad||^2 = 0.08886 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 100886.834 - ||grad||^2 = 0.08788 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 100886.838 - ||grad||^2 = 0.09030 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 100886.834 - ||grad||^2 = 0.09079 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 100886.838 - ||grad||^2 = 0.07809 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 100886.834 - ||grad||^2 = 0.07711 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 100886.838 - ||grad||^2 = 0.08190 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 100886.834 - ||grad||^2 = 0.08550 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 100886.838 - ||grad||^2 = 0.07632 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 100886.834 - ||grad||^2 = 0.07176 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 100886.837 - ||grad||^2 = 0.05949 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 100886.834 - ||grad||^2 = 0.06010 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 100886.838 - ||grad||^2 = 0.08253 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 100886.834 - ||grad||^2 = 0.08666 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 100886.838 - ||grad||^2 = 0.08751 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 100886.834 - ||grad||^2 = 0.08602 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 100886.838 - ||grad||^2 = 0.07872 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 100886.834 - ||grad||^2 = 0.09166 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 100886.838 - ||grad||^2 = 0.09891 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 100886.834 - ||grad||^2 = 0.08769 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 100886.838 - ||grad||^2 = 0.07463 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 100886.834 - ||grad||^2 = 0.06150 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 100886.838 - ||grad||^2 = 0.06882 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 100886.834 - ||grad||^2 = 0.08571 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 100886.838 - ||grad||^2 = 0.09829 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 100886.834 - ||grad||^2 = 0.08936 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 100886.837 - ||grad||^2 = 0.06529 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 100886.835 - ||grad||^2 = 0.05579 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 100886.837 - ||grad||^2 = 0.06232 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 100886.834 - ||grad||^2 = 0.07424 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 100886.838 - ||grad||^2 = 0.07313 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 100886.834 - ||grad||^2 = 0.07295 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2RitcIGCQkj8","executionInfo":{"status":"ok","timestamp":1662630313380,"user_tz":-540,"elapsed":19,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"925fddb6-f053-40ac-bfb2-36681071d18f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.829862\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"KHuU3Yr9Qkj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-50000.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y12s99guQkj8","executionInfo":{"status":"ok","timestamp":1662630313777,"user_tz":-540,"elapsed":401,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"8a0bc3b9-0e92-4907-c279-ac73262277d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-aug-50000.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-org+balAR-6616"],"metadata":{"id":"zvcfGSv5OEFy"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"enwlDMpmOEFy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/original+TGAN-balAR/origin+tganbalAR-6616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"qe-5rIxFOEFz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"Yc3al7gTOEFz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"B2PvBUifOEFz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"ZOjyO82vOEFz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"nIxn2XTMOEFz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"ImFZ7Xc8OEFz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"1lGJboXvOEF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"RqDjZezXOEF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662709820547,"user_tz":-540,"elapsed":44381,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"91f90ae8-4d19-402b-fe15-37fbb7ac1805","id":"Rm1F_JJkOEF0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 240913.415 - ||grad||^2 = 324735.96632 - ||diff_w|| = 16.12766\n"," * Iteration #2 - Loss = 61842.311 - ||grad||^2 = 165660.53742 - ||diff_w|| = 7.20866\n"," * Iteration #3 - Loss = 19788.100 - ||grad||^2 = 93331.82783 - ||diff_w|| = 3.82949\n"," * Iteration #4 - Loss = 7203.968 - ||grad||^2 = 49383.52452 - ||diff_w|| = 1.72154\n"," * Iteration #5 - Loss = 4073.801 - ||grad||^2 = 21768.48682 - ||diff_w|| = 0.59772\n"," * Iteration #6 - Loss = 3691.525 - ||grad||^2 = 8360.84445 - ||diff_w|| = 0.24208\n"," * Iteration #7 - Loss = 3686.440 - ||grad||^2 = 3036.53618 - ||diff_w|| = 0.09609\n"," * Iteration #8 - Loss = 3684.498 - ||grad||^2 = 1162.42334 - ||diff_w|| = 0.03869\n"," * Iteration #9 - Loss = 3684.232 - ||grad||^2 = 454.61920 - ||diff_w|| = 0.01609\n"," * Iteration #10 - Loss = 3684.363 - ||grad||^2 = 186.50696 - ||diff_w|| = 0.00703\n"," * Iteration #11 - Loss = 3684.381 - ||grad||^2 = 77.70458 - ||diff_w|| = 0.00318\n"," * Iteration #12 - Loss = 3684.373 - ||grad||^2 = 32.99984 - ||diff_w|| = 0.00151\n"," * Iteration #13 - Loss = 3684.393 - ||grad||^2 = 14.54469 - ||diff_w|| = 0.00074\n"," * Iteration #14 - Loss = 3684.384 - ||grad||^2 = 6.61443 - ||diff_w|| = 0.00037\n"," * Iteration #15 - Loss = 3684.391 - ||grad||^2 = 2.88470 - ||diff_w|| = 0.00019\n"," * Iteration #16 - Loss = 3684.385 - ||grad||^2 = 1.45852 - ||diff_w|| = 0.00010\n"," * Iteration #17 - Loss = 3684.387 - ||grad||^2 = 0.68950 - ||diff_w|| = 0.00006\n"," * Iteration #18 - Loss = 3684.389 - ||grad||^2 = 0.32628 - ||diff_w|| = 0.00003\n"," * Iteration #19 - Loss = 3684.388 - ||grad||^2 = 0.14961 - ||diff_w|| = 0.00002\n"," * Iteration #20 - Loss = 3684.390 - ||grad||^2 = 0.07798 - ||diff_w|| = 0.00001\n"," * Iteration #21 - Loss = 3684.388 - ||grad||^2 = 0.08526 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 3684.390 - ||grad||^2 = 0.05296 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 3684.389 - ||grad||^2 = 0.03449 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 3684.389 - ||grad||^2 = 0.02697 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 3684.389 - ||grad||^2 = 0.02696 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 3684.390 - ||grad||^2 = 0.03353 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 3684.388 - ||grad||^2 = 0.03041 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 3684.390 - ||grad||^2 = 0.05480 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 3684.387 - ||grad||^2 = 0.08919 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 3684.390 - ||grad||^2 = 0.10739 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 3684.387 - ||grad||^2 = 0.10384 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 3684.391 - ||grad||^2 = 0.09738 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 3684.387 - ||grad||^2 = 0.07457 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 3684.390 - ||grad||^2 = 0.05110 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 3684.388 - ||grad||^2 = 0.03831 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 3684.389 - ||grad||^2 = 0.03463 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 3684.388 - ||grad||^2 = 0.03707 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 3684.390 - ||grad||^2 = 0.04519 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 3684.388 - ||grad||^2 = 0.06611 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 3684.389 - ||grad||^2 = 0.05606 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 3684.388 - ||grad||^2 = 0.03215 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 3684.389 - ||grad||^2 = 0.03544 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 3684.388 - ||grad||^2 = 0.04134 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 3684.390 - ||grad||^2 = 0.06427 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 3684.387 - ||grad||^2 = 0.07043 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 3684.390 - ||grad||^2 = 0.08601 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 3684.387 - ||grad||^2 = 0.10278 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 3684.391 - ||grad||^2 = 0.11305 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 3684.387 - ||grad||^2 = 0.08147 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 3684.389 - ||grad||^2 = 0.04276 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 3684.389 - ||grad||^2 = 0.02206 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 3684.390 - ||grad||^2 = 0.03723 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 3684.388 - ||grad||^2 = 0.07074 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 3684.390 - ||grad||^2 = 0.09733 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 3684.388 - ||grad||^2 = 0.09387 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 3684.390 - ||grad||^2 = 0.06735 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 3684.388 - ||grad||^2 = 0.05768 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 3684.390 - ||grad||^2 = 0.06776 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 3684.387 - ||grad||^2 = 0.07017 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 3684.390 - ||grad||^2 = 0.06736 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 3684.387 - ||grad||^2 = 0.06835 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 3684.390 - ||grad||^2 = 0.07982 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 3684.387 - ||grad||^2 = 0.08956 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 3684.391 - ||grad||^2 = 0.10318 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 3684.387 - ||grad||^2 = 0.07888 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 3684.389 - ||grad||^2 = 0.04158 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 3684.389 - ||grad||^2 = 0.02245 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 3684.389 - ||grad||^2 = 0.03522 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 3684.388 - ||grad||^2 = 0.06911 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 3684.390 - ||grad||^2 = 0.09998 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 3684.388 - ||grad||^2 = 0.09446 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 3684.390 - ||grad||^2 = 0.06686 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 3684.387 - ||grad||^2 = 0.06845 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 3684.390 - ||grad||^2 = 0.07242 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 3684.388 - ||grad||^2 = 0.05704 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 3684.390 - ||grad||^2 = 0.04325 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 3684.388 - ||grad||^2 = 0.04096 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 3684.390 - ||grad||^2 = 0.06865 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 3684.387 - ||grad||^2 = 0.09491 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 3684.390 - ||grad||^2 = 0.07906 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 3684.387 - ||grad||^2 = 0.07147 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 3684.391 - ||grad||^2 = 0.07733 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 3684.387 - ||grad||^2 = 0.07140 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 3684.390 - ||grad||^2 = 0.05701 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 3684.387 - ||grad||^2 = 0.06342 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 3684.391 - ||grad||^2 = 0.09468 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 3684.387 - ||grad||^2 = 0.10301 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 3684.391 - ||grad||^2 = 0.10792 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 3684.387 - ||grad||^2 = 0.07929 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 3684.390 - ||grad||^2 = 0.04272 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 3684.388 - ||grad||^2 = 0.03567 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 3684.390 - ||grad||^2 = 0.05587 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 3684.387 - ||grad||^2 = 0.07116 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 3684.390 - ||grad||^2 = 0.08568 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 3684.387 - ||grad||^2 = 0.10307 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 3684.391 - ||grad||^2 = 0.10544 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 3684.387 - ||grad||^2 = 0.07824 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 3684.390 - ||grad||^2 = 0.04267 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 3684.388 - ||grad||^2 = 0.03136 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 3684.390 - ||grad||^2 = 0.04218 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662709820548,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"92611798-ca28-4147-fc09-e52d4c559809","id":"Y0qMXExaOEF0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.834963\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"stief2CdOEF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-6616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662709820548,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"e89fddbb-b6bf-4c55-cc58-9aeec27535fd","id":"6QNm60z4OEF0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-6616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-org+balAR-11616"],"metadata":{"id":"pydZ5eWCObhS"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"U1haRNZvObhS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/original+TGAN-balAR/origin+tganbalAR-11616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"lpIdfJiOObhT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"fllfdgcrObhT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"HlZJM06BObhT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"0BcNrhNLObhT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"C6Kd8Nm6ObhT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"JtOsLgUGObhT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"oNwHR8WEObhU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"zMaMXHW7ObhU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VxtGMhnvObhU","executionInfo":{"status":"ok","timestamp":1662710173158,"user_tz":-540,"elapsed":121852,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"0f7e6547-bdc2-4c1d-e19b-72c1e9cf0fbe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 2793116.558 - ||grad||^2 = 4461179.73052 - ||diff_w|| = 14.96894\n"," * Iteration #2 - Loss = 709704.281 - ||grad||^2 = 2271999.11641 - ||diff_w|| = 6.71699\n"," * Iteration #3 - Loss = 219518.408 - ||grad||^2 = 1280860.13079 - ||diff_w|| = 3.65574\n"," * Iteration #4 - Loss = 68867.040 - ||grad||^2 = 718303.57395 - ||diff_w|| = 1.92967\n"," * Iteration #5 - Loss = 23982.187 - ||grad||^2 = 374375.09011 - ||diff_w|| = 0.93097\n"," * Iteration #6 - Loss = 13147.867 - ||grad||^2 = 186247.03533 - ||diff_w|| = 0.44273\n"," * Iteration #7 - Loss = 11552.535 - ||grad||^2 = 70504.85502 - ||diff_w|| = 0.21196\n"," * Iteration #8 - Loss = 11661.293 - ||grad||^2 = 21104.85493 - ||diff_w|| = 0.08362\n"," * Iteration #9 - Loss = 11646.070 - ||grad||^2 = 7137.69138 - ||diff_w|| = 0.03092\n"," * Iteration #10 - Loss = 11643.111 - ||grad||^2 = 2474.59546 - ||diff_w|| = 0.01260\n"," * Iteration #11 - Loss = 11643.642 - ||grad||^2 = 906.59412 - ||diff_w|| = 0.00562\n"," * Iteration #12 - Loss = 11643.829 - ||grad||^2 = 351.52452 - ||diff_w|| = 0.00265\n"," * Iteration #13 - Loss = 11643.944 - ||grad||^2 = 146.78248 - ||diff_w|| = 0.00134\n"," * Iteration #14 - Loss = 11643.973 - ||grad||^2 = 63.00367 - ||diff_w|| = 0.00070\n"," * Iteration #15 - Loss = 11643.963 - ||grad||^2 = 27.79260 - ||diff_w|| = 0.00037\n"," * Iteration #16 - Loss = 11643.967 - ||grad||^2 = 12.57137 - ||diff_w|| = 0.00020\n"," * Iteration #17 - Loss = 11643.974 - ||grad||^2 = 5.89330 - ||diff_w|| = 0.00011\n"," * Iteration #18 - Loss = 11643.972 - ||grad||^2 = 2.84707 - ||diff_w|| = 0.00006\n"," * Iteration #19 - Loss = 11643.972 - ||grad||^2 = 1.32100 - ||diff_w|| = 0.00003\n"," * Iteration #20 - Loss = 11643.973 - ||grad||^2 = 0.63947 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 11643.972 - ||grad||^2 = 0.35217 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 11643.973 - ||grad||^2 = 0.17273 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 11643.972 - ||grad||^2 = 0.12608 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 11643.974 - ||grad||^2 = 0.06337 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 11643.972 - ||grad||^2 = 0.08185 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 11643.974 - ||grad||^2 = 0.07622 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 11643.972 - ||grad||^2 = 0.06563 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 11643.974 - ||grad||^2 = 0.04390 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 11643.971 - ||grad||^2 = 0.06765 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 11643.975 - ||grad||^2 = 0.10468 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 11643.970 - ||grad||^2 = 0.13144 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 11643.975 - ||grad||^2 = 0.10537 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 11643.971 - ||grad||^2 = 0.06616 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 11643.974 - ||grad||^2 = 0.06115 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 11643.972 - ||grad||^2 = 0.06544 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 11643.974 - ||grad||^2 = 0.05586 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 11643.971 - ||grad||^2 = 0.07401 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 11643.975 - ||grad||^2 = 0.09898 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 11643.970 - ||grad||^2 = 0.11263 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 11643.975 - ||grad||^2 = 0.09350 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 11643.971 - ||grad||^2 = 0.07962 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 11643.975 - ||grad||^2 = 0.08944 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 11643.971 - ||grad||^2 = 0.07583 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 11643.974 - ||grad||^2 = 0.05892 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 11643.972 - ||grad||^2 = 0.05730 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 11643.975 - ||grad||^2 = 0.06745 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 11643.970 - ||grad||^2 = 0.10827 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 11643.975 - ||grad||^2 = 0.11109 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 11643.971 - ||grad||^2 = 0.09791 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 11643.975 - ||grad||^2 = 0.08632 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 11643.971 - ||grad||^2 = 0.07937 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 11643.975 - ||grad||^2 = 0.09725 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 11643.971 - ||grad||^2 = 0.09989 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 11643.975 - ||grad||^2 = 0.08466 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 11643.971 - ||grad||^2 = 0.09468 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 11643.975 - ||grad||^2 = 0.11201 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 11643.971 - ||grad||^2 = 0.10059 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 11643.975 - ||grad||^2 = 0.09048 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 11643.970 - ||grad||^2 = 0.10187 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 11643.975 - ||grad||^2 = 0.10629 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 11643.971 - ||grad||^2 = 0.09263 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 11643.975 - ||grad||^2 = 0.08433 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 11643.971 - ||grad||^2 = 0.09643 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 11643.975 - ||grad||^2 = 0.10801 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 11643.970 - ||grad||^2 = 0.10258 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 11643.975 - ||grad||^2 = 0.10557 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 11643.970 - ||grad||^2 = 0.10960 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 11643.975 - ||grad||^2 = 0.08817 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 11643.971 - ||grad||^2 = 0.06968 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 11643.975 - ||grad||^2 = 0.08824 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 11643.972 - ||grad||^2 = 0.07082 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 11643.974 - ||grad||^2 = 0.04732 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 11643.972 - ||grad||^2 = 0.06125 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 11643.974 - ||grad||^2 = 0.09420 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 11643.971 - ||grad||^2 = 0.08629 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 11643.975 - ||grad||^2 = 0.08247 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 11643.970 - ||grad||^2 = 0.11200 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 11643.975 - ||grad||^2 = 0.10904 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 11643.971 - ||grad||^2 = 0.09903 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 11643.975 - ||grad||^2 = 0.08566 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 11643.971 - ||grad||^2 = 0.08685 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 11643.975 - ||grad||^2 = 0.11571 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 11643.970 - ||grad||^2 = 0.12560 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 11643.975 - ||grad||^2 = 0.11018 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 11643.971 - ||grad||^2 = 0.08315 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 11643.974 - ||grad||^2 = 0.07096 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 11643.972 - ||grad||^2 = 0.06939 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 11643.974 - ||grad||^2 = 0.07300 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 11643.971 - ||grad||^2 = 0.08809 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 11643.975 - ||grad||^2 = 0.09491 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 11643.972 - ||grad||^2 = 0.07453 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 11643.973 - ||grad||^2 = 0.05666 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 11643.972 - ||grad||^2 = 0.05045 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 11643.974 - ||grad||^2 = 0.05963 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 11643.971 - ||grad||^2 = 0.07811 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 11643.975 - ||grad||^2 = 0.08449 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 11643.970 - ||grad||^2 = 0.11586 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 11643.975 - ||grad||^2 = 0.11854 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 11643.971 - ||grad||^2 = 0.09364 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 11643.975 - ||grad||^2 = 0.07773 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6qDIQzpkObhU","executionInfo":{"status":"ok","timestamp":1662710173159,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"e5219584-a281-4c2b-e60b-c881e8661c72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.832394\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"5gxIv2KSObhU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-11616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zDYSZmEcObhU","executionInfo":{"status":"ok","timestamp":1662710173159,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"e2232dc8-7808-4edd-d2ef-c49aa19df772"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-11616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-org+balAR-16616"],"metadata":{"id":"5kDTXB6-Om2Q"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"QgGpe6YjOm2R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/original+TGAN-balAR/origin+tganbalAR-16616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"XyynbVQxOm2R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"Ef_m2UmfOm2R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"nNbSiUYaOm2R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"hByh7QG5Om2S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"loVSFfMmOm2S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"aZqrw0QiOm2S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"j3Qt5kgSOm2S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"E-ThNEWwOm2S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qSgNQXCdOm2S","executionInfo":{"status":"ok","timestamp":1662710438787,"user_tz":-540,"elapsed":231224,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"fdda4581-77a8-4c20-8062-03741b1805d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 1648021.517 - ||grad||^2 = 2520291.73682 - ||diff_w|| = 19.46804\n"," * Iteration #2 - Loss = 432266.052 - ||grad||^2 = 1330091.39529 - ||diff_w|| = 8.72042\n"," * Iteration #3 - Loss = 143510.813 - ||grad||^2 = 794399.05786 - ||diff_w|| = 4.68442\n"," * Iteration #4 - Loss = 54452.489 - ||grad||^2 = 464443.56080 - ||diff_w|| = 2.20368\n"," * Iteration #5 - Loss = 29347.522 - ||grad||^2 = 192484.45483 - ||diff_w|| = 0.68335\n"," * Iteration #6 - Loss = 24668.983 - ||grad||^2 = 61207.57697 - ||diff_w|| = 0.20612\n"," * Iteration #7 - Loss = 24301.073 - ||grad||^2 = 25349.16364 - ||diff_w|| = 0.08876\n"," * Iteration #8 - Loss = 24289.228 - ||grad||^2 = 10331.80786 - ||diff_w|| = 0.03976\n"," * Iteration #9 - Loss = 24287.075 - ||grad||^2 = 4284.04201 - ||diff_w|| = 0.01868\n"," * Iteration #10 - Loss = 24286.096 - ||grad||^2 = 1861.84311 - ||diff_w|| = 0.00915\n"," * Iteration #11 - Loss = 24285.561 - ||grad||^2 = 852.71401 - ||diff_w|| = 0.00465\n"," * Iteration #12 - Loss = 24285.332 - ||grad||^2 = 402.42937 - ||diff_w|| = 0.00244\n"," * Iteration #13 - Loss = 24285.239 - ||grad||^2 = 195.28300 - ||diff_w|| = 0.00131\n"," * Iteration #14 - Loss = 24285.179 - ||grad||^2 = 95.98657 - ||diff_w|| = 0.00070\n"," * Iteration #15 - Loss = 24285.149 - ||grad||^2 = 47.86756 - ||diff_w|| = 0.00038\n"," * Iteration #16 - Loss = 24285.137 - ||grad||^2 = 24.21232 - ||diff_w|| = 0.00021\n"," * Iteration #17 - Loss = 24285.135 - ||grad||^2 = 11.91853 - ||diff_w|| = 0.00011\n"," * Iteration #18 - Loss = 24285.134 - ||grad||^2 = 6.06518 - ||diff_w|| = 0.00006\n"," * Iteration #19 - Loss = 24285.130 - ||grad||^2 = 3.02316 - ||diff_w|| = 0.00003\n"," * Iteration #20 - Loss = 24285.128 - ||grad||^2 = 1.54964 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 24285.129 - ||grad||^2 = 0.79815 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 24285.129 - ||grad||^2 = 0.41980 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 24285.128 - ||grad||^2 = 0.20074 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 24285.129 - ||grad||^2 = 0.13631 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 24285.128 - ||grad||^2 = 0.07164 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 24285.129 - ||grad||^2 = 0.09020 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 24285.127 - ||grad||^2 = 0.08204 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 24285.130 - ||grad||^2 = 0.08797 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 24285.127 - ||grad||^2 = 0.08699 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 24285.130 - ||grad||^2 = 0.08640 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 24285.127 - ||grad||^2 = 0.07640 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 24285.130 - ||grad||^2 = 0.07567 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 24285.127 - ||grad||^2 = 0.10120 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 24285.129 - ||grad||^2 = 0.09016 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 24285.127 - ||grad||^2 = 0.08251 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 24285.130 - ||grad||^2 = 0.10240 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 24285.127 - ||grad||^2 = 0.09089 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 24285.130 - ||grad||^2 = 0.07842 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 24285.127 - ||grad||^2 = 0.10152 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 24285.130 - ||grad||^2 = 0.10149 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 24285.127 - ||grad||^2 = 0.08920 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 24285.130 - ||grad||^2 = 0.07378 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 24285.127 - ||grad||^2 = 0.06950 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 24285.130 - ||grad||^2 = 0.07541 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 24285.127 - ||grad||^2 = 0.10183 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 24285.129 - ||grad||^2 = 0.08979 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 24285.127 - ||grad||^2 = 0.08245 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 24285.130 - ||grad||^2 = 0.10246 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 24285.127 - ||grad||^2 = 0.09083 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 24285.130 - ||grad||^2 = 0.07842 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 24285.127 - ||grad||^2 = 0.10154 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 24285.130 - ||grad||^2 = 0.10149 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 24285.127 - ||grad||^2 = 0.08920 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 24285.130 - ||grad||^2 = 0.07378 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 24285.127 - ||grad||^2 = 0.06950 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 24285.130 - ||grad||^2 = 0.07541 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 24285.127 - ||grad||^2 = 0.10183 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 24285.129 - ||grad||^2 = 0.08979 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 24285.127 - ||grad||^2 = 0.08245 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 24285.130 - ||grad||^2 = 0.10246 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 24285.127 - ||grad||^2 = 0.09083 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 24285.130 - ||grad||^2 = 0.07842 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 24285.127 - ||grad||^2 = 0.10154 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 24285.130 - ||grad||^2 = 0.10149 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 24285.127 - ||grad||^2 = 0.08920 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 24285.130 - ||grad||^2 = 0.07378 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 24285.127 - ||grad||^2 = 0.06950 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 24285.130 - ||grad||^2 = 0.07541 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 24285.127 - ||grad||^2 = 0.10183 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 24285.129 - ||grad||^2 = 0.08979 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 24285.127 - ||grad||^2 = 0.08245 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 24285.130 - ||grad||^2 = 0.10246 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 24285.127 - ||grad||^2 = 0.09083 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 24285.130 - ||grad||^2 = 0.07842 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 24285.127 - ||grad||^2 = 0.10154 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 24285.130 - ||grad||^2 = 0.10149 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 24285.127 - ||grad||^2 = 0.08920 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 24285.130 - ||grad||^2 = 0.07378 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 24285.127 - ||grad||^2 = 0.06950 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 24285.130 - ||grad||^2 = 0.07541 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 24285.127 - ||grad||^2 = 0.10183 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 24285.129 - ||grad||^2 = 0.08979 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 24285.127 - ||grad||^2 = 0.08245 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 24285.130 - ||grad||^2 = 0.10246 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 24285.127 - ||grad||^2 = 0.09083 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 24285.130 - ||grad||^2 = 0.07842 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 24285.127 - ||grad||^2 = 0.10154 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 24285.130 - ||grad||^2 = 0.10149 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 24285.127 - ||grad||^2 = 0.08920 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 24285.130 - ||grad||^2 = 0.07378 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 24285.127 - ||grad||^2 = 0.06950 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 24285.130 - ||grad||^2 = 0.07541 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 24285.127 - ||grad||^2 = 0.10183 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 24285.129 - ||grad||^2 = 0.08979 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 24285.127 - ||grad||^2 = 0.08245 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 24285.130 - ||grad||^2 = 0.10246 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 24285.127 - ||grad||^2 = 0.09083 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 24285.130 - ||grad||^2 = 0.07842 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 24285.127 - ||grad||^2 = 0.10154 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 24285.130 - ||grad||^2 = 0.10149 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YudUaYN-Om2S","executionInfo":{"status":"ok","timestamp":1662710438788,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"65a9f7b4-2b76-4ab6-be84-a3a06d9dd34d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.833274\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"VzGgYYVLOm2S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-16616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gz7oHLI7Om2S","executionInfo":{"status":"ok","timestamp":1662710438788,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"3a4e5229-2b7c-4eab-9dd8-af7363f350b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-16616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-org+balAR-21616"],"metadata":{"id":"MS6NFDC8OuH6"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"92xnb7FCOuH8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/original+TGAN-balAR/origin+tganbalAR-21616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"6TnAnET5OuH8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"JHD-7IzeOuH8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"AJy7iMRLOuH9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"SWScNgfuOuH9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"BGitOp4IOuH9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"wyj8M0D9OuH9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"Je0xZxw5OuH9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"5zJRL7fcOuH9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yuxvItV2OuH9","executionInfo":{"status":"ok","timestamp":1662711003523,"user_tz":-540,"elapsed":387435,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"f2b7d3a7-da18-4ad2-9c57-8e6e9e7f4a0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 9169573.246 - ||grad||^2 = 13034647.67127 - ||diff_w|| = 19.97380\n"," * Iteration #2 - Loss = 2315265.797 - ||grad||^2 = 6599596.53930 - ||diff_w|| = 8.97061\n"," * Iteration #3 - Loss = 709910.142 - ||grad||^2 = 3691645.42735 - ||diff_w|| = 4.89068\n"," * Iteration #4 - Loss = 221111.482 - ||grad||^2 = 2052123.53745 - ||diff_w|| = 2.56227\n"," * Iteration #5 - Loss = 78898.780 - ||grad||^2 = 1084619.60667 - ||diff_w|| = 1.18598\n"," * Iteration #6 - Loss = 45125.661 - ||grad||^2 = 539091.78311 - ||diff_w|| = 0.57701\n"," * Iteration #7 - Loss = 41060.052 - ||grad||^2 = 200326.12882 - ||diff_w|| = 0.30773\n"," * Iteration #8 - Loss = 41342.942 - ||grad||^2 = 63219.35458 - ||diff_w|| = 0.14225\n"," * Iteration #9 - Loss = 41339.533 - ||grad||^2 = 20265.05506 - ||diff_w|| = 0.06114\n"," * Iteration #10 - Loss = 41345.787 - ||grad||^2 = 6449.27568 - ||diff_w|| = 0.02660\n"," * Iteration #11 - Loss = 41344.564 - ||grad||^2 = 2202.92408 - ||diff_w|| = 0.01236\n"," * Iteration #12 - Loss = 41344.140 - ||grad||^2 = 878.63801 - ||diff_w|| = 0.00607\n"," * Iteration #13 - Loss = 41343.992 - ||grad||^2 = 387.04320 - ||diff_w|| = 0.00310\n"," * Iteration #14 - Loss = 41343.907 - ||grad||^2 = 185.21270 - ||diff_w|| = 0.00162\n"," * Iteration #15 - Loss = 41343.863 - ||grad||^2 = 90.67769 - ||diff_w|| = 0.00087\n"," * Iteration #16 - Loss = 41343.846 - ||grad||^2 = 45.03195 - ||diff_w|| = 0.00047\n"," * Iteration #17 - Loss = 41343.840 - ||grad||^2 = 22.47347 - ||diff_w|| = 0.00025\n"," * Iteration #18 - Loss = 41343.829 - ||grad||^2 = 11.15858 - ||diff_w|| = 0.00014\n"," * Iteration #19 - Loss = 41343.826 - ||grad||^2 = 5.81384 - ||diff_w|| = 0.00008\n"," * Iteration #20 - Loss = 41343.825 - ||grad||^2 = 2.88400 - ||diff_w|| = 0.00004\n"," * Iteration #21 - Loss = 41343.822 - ||grad||^2 = 1.44601 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 41343.822 - ||grad||^2 = 0.74011 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 41343.821 - ||grad||^2 = 0.38051 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 41343.823 - ||grad||^2 = 0.21504 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 41343.822 - ||grad||^2 = 0.12006 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 41343.822 - ||grad||^2 = 0.05885 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 41343.822 - ||grad||^2 = 0.04573 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 41343.822 - ||grad||^2 = 0.04636 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 41343.822 - ||grad||^2 = 0.03357 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 41343.822 - ||grad||^2 = 0.01959 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 41343.822 - ||grad||^2 = 0.02099 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 41343.823 - ||grad||^2 = 0.04697 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 41343.821 - ||grad||^2 = 0.06077 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 41343.823 - ||grad||^2 = 0.04201 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 41343.821 - ||grad||^2 = 0.03300 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 41343.823 - ||grad||^2 = 0.05303 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 41343.822 - ||grad||^2 = 0.03110 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 41343.822 - ||grad||^2 = 0.02609 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 41343.822 - ||grad||^2 = 0.03227 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 41343.822 - ||grad||^2 = 0.03652 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 41343.822 - ||grad||^2 = 0.06003 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 41343.822 - ||grad||^2 = 0.04631 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 41343.822 - ||grad||^2 = 0.02313 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 41343.822 - ||grad||^2 = 0.03124 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 41343.822 - ||grad||^2 = 0.03308 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 41343.822 - ||grad||^2 = 0.03218 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 41343.822 - ||grad||^2 = 0.02611 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 41343.823 - ||grad||^2 = 0.03216 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 41343.822 - ||grad||^2 = 0.02932 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 41343.823 - ||grad||^2 = 0.04137 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 41343.821 - ||grad||^2 = 0.05745 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 41343.823 - ||grad||^2 = 0.05070 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 41343.822 - ||grad||^2 = 0.03135 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 41343.822 - ||grad||^2 = 0.03248 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 41343.822 - ||grad||^2 = 0.03551 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 41343.822 - ||grad||^2 = 0.02636 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 41343.822 - ||grad||^2 = 0.02611 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 41343.822 - ||grad||^2 = 0.02481 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 41343.823 - ||grad||^2 = 0.03251 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 41343.821 - ||grad||^2 = 0.05515 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 41343.823 - ||grad||^2 = 0.06246 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 41343.822 - ||grad||^2 = 0.03536 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 41343.822 - ||grad||^2 = 0.03287 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 41343.822 - ||grad||^2 = 0.02953 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 41343.822 - ||grad||^2 = 0.02501 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 41343.823 - ||grad||^2 = 0.02994 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 41343.822 - ||grad||^2 = 0.02950 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 41343.823 - ||grad||^2 = 0.04128 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 41343.821 - ||grad||^2 = 0.05752 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 41343.823 - ||grad||^2 = 0.05045 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 41343.822 - ||grad||^2 = 0.03133 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 41343.822 - ||grad||^2 = 0.03246 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 41343.822 - ||grad||^2 = 0.03553 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 41343.822 - ||grad||^2 = 0.02633 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 41343.822 - ||grad||^2 = 0.02611 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 41343.822 - ||grad||^2 = 0.02482 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 41343.823 - ||grad||^2 = 0.03251 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 41343.821 - ||grad||^2 = 0.05515 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 41343.823 - ||grad||^2 = 0.06246 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 41343.822 - ||grad||^2 = 0.03536 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 41343.822 - ||grad||^2 = 0.03287 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 41343.822 - ||grad||^2 = 0.02953 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 41343.822 - ||grad||^2 = 0.02501 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 41343.823 - ||grad||^2 = 0.02994 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 41343.822 - ||grad||^2 = 0.02950 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 41343.823 - ||grad||^2 = 0.04128 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 41343.821 - ||grad||^2 = 0.05752 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 41343.823 - ||grad||^2 = 0.05045 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 41343.822 - ||grad||^2 = 0.03133 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 41343.822 - ||grad||^2 = 0.03246 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 41343.822 - ||grad||^2 = 0.03553 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 41343.822 - ||grad||^2 = 0.02633 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 41343.822 - ||grad||^2 = 0.02611 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 41343.822 - ||grad||^2 = 0.02482 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 41343.823 - ||grad||^2 = 0.03251 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 41343.821 - ||grad||^2 = 0.05515 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 41343.823 - ||grad||^2 = 0.06246 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 41343.822 - ||grad||^2 = 0.03536 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 41343.822 - ||grad||^2 = 0.03287 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 41343.822 - ||grad||^2 = 0.02953 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KFzAacUzOuH-","executionInfo":{"status":"ok","timestamp":1662711003523,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"169d6d03-ec7b-4cad-ecf6-adbb46d0abcf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.831799\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"T8tMnRKrOuH-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-21616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3AvseJWfOuH-","executionInfo":{"status":"ok","timestamp":1662711003524,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"a1d0b5b6-7da5-43be-ea95-d0e3174a0c29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-21616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-org+balAR-26616"],"metadata":{"id":"O0R2sorNO3IM"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"HJH1XcMPO3IN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/original+TGAN-balAR/origin+tganbalAR-26616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"Iuecm9SzO3IN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"6TeGGxfpO3IN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"7a_RSjlKO3IN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"-8SVKa4AO3IO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"dHR_51PaO3IO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"KU4MfA5rO3IO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"LUuWgUN-O3IO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"5zvnI68MO3IO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCWa73YtO3IO","executionInfo":{"status":"ok","timestamp":1662712024404,"user_tz":-540,"elapsed":591415,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"0fa3c43a-9ce9-43e9-d056-5b63b6952a2b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 2806989.674 - ||grad||^2 = 3874115.26573 - ||diff_w|| = 16.68777\n"," * Iteration #2 - Loss = 737799.016 - ||grad||^2 = 2043593.03166 - ||diff_w|| = 7.44599\n"," * Iteration #3 - Loss = 248512.918 - ||grad||^2 = 1204766.83486 - ||diff_w|| = 3.92354\n"," * Iteration #4 - Loss = 103634.546 - ||grad||^2 = 646437.02418 - ||diff_w|| = 1.79045\n"," * Iteration #5 - Loss = 68720.852 - ||grad||^2 = 194812.92683 - ||diff_w|| = 0.69112\n"," * Iteration #6 - Loss = 66045.181 - ||grad||^2 = 106819.76029 - ||diff_w|| = 0.28206\n"," * Iteration #7 - Loss = 65156.476 - ||grad||^2 = 41862.71124 - ||diff_w|| = 0.13370\n"," * Iteration #8 - Loss = 65055.250 - ||grad||^2 = 16748.07956 - ||diff_w|| = 0.06659\n"," * Iteration #9 - Loss = 65035.038 - ||grad||^2 = 6593.38341 - ||diff_w|| = 0.03365\n"," * Iteration #10 - Loss = 65043.074 - ||grad||^2 = 2250.34096 - ||diff_w|| = 0.01675\n"," * Iteration #11 - Loss = 65047.356 - ||grad||^2 = 880.45501 - ||diff_w|| = 0.00851\n"," * Iteration #12 - Loss = 65048.246 - ||grad||^2 = 409.99071 - ||diff_w|| = 0.00449\n"," * Iteration #13 - Loss = 65048.286 - ||grad||^2 = 206.03366 - ||diff_w|| = 0.00243\n"," * Iteration #14 - Loss = 65048.275 - ||grad||^2 = 105.32719 - ||diff_w|| = 0.00133\n"," * Iteration #15 - Loss = 65048.264 - ||grad||^2 = 54.70587 - ||diff_w|| = 0.00073\n"," * Iteration #16 - Loss = 65048.263 - ||grad||^2 = 28.39670 - ||diff_w|| = 0.00040\n"," * Iteration #17 - Loss = 65048.257 - ||grad||^2 = 14.76469 - ||diff_w|| = 0.00022\n"," * Iteration #18 - Loss = 65048.254 - ||grad||^2 = 7.68819 - ||diff_w|| = 0.00012\n"," * Iteration #19 - Loss = 65048.252 - ||grad||^2 = 3.97278 - ||diff_w|| = 0.00007\n"," * Iteration #20 - Loss = 65048.249 - ||grad||^2 = 2.00070 - ||diff_w|| = 0.00004\n"," * Iteration #21 - Loss = 65048.250 - ||grad||^2 = 1.02686 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 65048.248 - ||grad||^2 = 0.46169 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 65048.249 - ||grad||^2 = 0.26140 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 65048.249 - ||grad||^2 = 0.15194 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 65048.248 - ||grad||^2 = 0.08127 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 65048.249 - ||grad||^2 = 0.07538 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 65048.249 - ||grad||^2 = 0.06556 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 65048.248 - ||grad||^2 = 0.05643 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 65048.249 - ||grad||^2 = 0.03421 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 65048.248 - ||grad||^2 = 0.06862 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 65048.249 - ||grad||^2 = 0.05736 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 65048.248 - ||grad||^2 = 0.05180 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 65048.250 - ||grad||^2 = 0.08150 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 65048.248 - ||grad||^2 = 0.07100 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 65048.249 - ||grad||^2 = 0.05169 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 65048.248 - ||grad||^2 = 0.06178 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 65048.249 - ||grad||^2 = 0.05959 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 65048.248 - ||grad||^2 = 0.05708 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 65048.250 - ||grad||^2 = 0.06353 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 65048.248 - ||grad||^2 = 0.05253 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 65048.249 - ||grad||^2 = 0.04875 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 65048.249 - ||grad||^2 = 0.06687 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 65048.249 - ||grad||^2 = 0.05822 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 65048.248 - ||grad||^2 = 0.05077 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 65048.250 - ||grad||^2 = 0.07088 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 65048.248 - ||grad||^2 = 0.05934 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 65048.249 - ||grad||^2 = 0.04510 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 65048.248 - ||grad||^2 = 0.07153 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 65048.249 - ||grad||^2 = 0.06194 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 65048.248 - ||grad||^2 = 0.03866 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 65048.250 - ||grad||^2 = 0.06036 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 65048.248 - ||grad||^2 = 0.04945 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 65048.249 - ||grad||^2 = 0.04242 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 65048.248 - ||grad||^2 = 0.07019 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 65048.249 - ||grad||^2 = 0.06168 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 65048.248 - ||grad||^2 = 0.03757 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 65048.249 - ||grad||^2 = 0.06132 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 65048.248 - ||grad||^2 = 0.04945 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 65048.249 - ||grad||^2 = 0.04146 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 65048.248 - ||grad||^2 = 0.07065 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 65048.249 - ||grad||^2 = 0.06310 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 65048.248 - ||grad||^2 = 0.03891 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 65048.250 - ||grad||^2 = 0.05992 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 65048.248 - ||grad||^2 = 0.05123 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 65048.249 - ||grad||^2 = 0.04599 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 65048.248 - ||grad||^2 = 0.08192 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 65048.249 - ||grad||^2 = 0.05950 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 65048.248 - ||grad||^2 = 0.03211 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 65048.249 - ||grad||^2 = 0.05989 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 65048.248 - ||grad||^2 = 0.05569 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 65048.249 - ||grad||^2 = 0.04237 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 65048.248 - ||grad||^2 = 0.07204 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 65048.249 - ||grad||^2 = 0.06237 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 65048.248 - ||grad||^2 = 0.03736 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 65048.249 - ||grad||^2 = 0.06155 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 65048.248 - ||grad||^2 = 0.04936 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 65048.249 - ||grad||^2 = 0.04161 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 65048.248 - ||grad||^2 = 0.07058 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 65048.249 - ||grad||^2 = 0.06309 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 65048.248 - ||grad||^2 = 0.03890 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 65048.250 - ||grad||^2 = 0.05993 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 65048.248 - ||grad||^2 = 0.05122 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 65048.249 - ||grad||^2 = 0.04600 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 65048.248 - ||grad||^2 = 0.08191 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 65048.249 - ||grad||^2 = 0.05950 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 65048.248 - ||grad||^2 = 0.03211 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 65048.249 - ||grad||^2 = 0.05989 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 65048.248 - ||grad||^2 = 0.05569 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 65048.249 - ||grad||^2 = 0.04237 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 65048.248 - ||grad||^2 = 0.07204 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 65048.249 - ||grad||^2 = 0.06237 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 65048.248 - ||grad||^2 = 0.03736 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 65048.249 - ||grad||^2 = 0.06155 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 65048.248 - ||grad||^2 = 0.04936 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 65048.249 - ||grad||^2 = 0.04161 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 65048.248 - ||grad||^2 = 0.07058 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 65048.249 - ||grad||^2 = 0.06309 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 65048.248 - ||grad||^2 = 0.03890 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 65048.250 - ||grad||^2 = 0.05993 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 65048.248 - ||grad||^2 = 0.05122 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UgsxOB89O3IP","executionInfo":{"status":"ok","timestamp":1662712024404,"user_tz":-540,"elapsed":23,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"8ab80255-63a9-49bf-e784-5a05ebcca125"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.830786\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"PG3WBXbeO3IP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-26616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTQ_A6rTO3IP","executionInfo":{"status":"ok","timestamp":1662712024404,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"69930da5-6dc3-42e8-adae-8484bbb83494"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-26616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-org+balAR-31616"],"metadata":{"id":"hLuKO6xKPJdt"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"AsIiCHD-PJdu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/original+TGAN-balAR/origin+tganbalAR-31616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"zBX_rWGbPJdv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"9MEopGCNPJdv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"mrNsP-UlPJdv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"Z3md6e17PJdv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"JqrXPi5zPJdv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"O9pmFhTvPJdv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"NCa-46uzPJdw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"dXlzXfydPJdw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bqyCLxRIPJdw","executionInfo":{"status":"ok","timestamp":1662713034381,"user_tz":-540,"elapsed":807615,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"a424da8e-9858-40ed-ce51-444f61ff1cca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 19789841.925 - ||grad||^2 = 34421272.16309 - ||diff_w|| = 16.99451\n"," * Iteration #2 - Loss = 4997071.637 - ||grad||^2 = 17437284.69884 - ||diff_w|| = 7.62843\n"," * Iteration #3 - Loss = 1533113.339 - ||grad||^2 = 9758411.57806 - ||diff_w|| = 4.14943\n"," * Iteration #4 - Loss = 478787.084 - ||grad||^2 = 5425817.11825 - ||diff_w|| = 2.15801\n"," * Iteration #5 - Loss = 171669.233 - ||grad||^2 = 2875599.64962 - ||diff_w|| = 1.00215\n"," * Iteration #6 - Loss = 97671.306 - ||grad||^2 = 1428967.33866 - ||diff_w|| = 0.50531\n"," * Iteration #7 - Loss = 88442.171 - ||grad||^2 = 505982.06905 - ||diff_w|| = 0.26699\n"," * Iteration #8 - Loss = 88241.669 - ||grad||^2 = 150329.12548 - ||diff_w|| = 0.11967\n"," * Iteration #9 - Loss = 88001.085 - ||grad||^2 = 52624.89560 - ||diff_w|| = 0.05041\n"," * Iteration #10 - Loss = 87975.592 - ||grad||^2 = 18264.66795 - ||diff_w|| = 0.02162\n"," * Iteration #11 - Loss = 87981.112 - ||grad||^2 = 5559.59295 - ||diff_w|| = 0.00890\n"," * Iteration #12 - Loss = 87985.494 - ||grad||^2 = 1747.08253 - ||diff_w|| = 0.00391\n"," * Iteration #13 - Loss = 87985.377 - ||grad||^2 = 629.28547 - ||diff_w|| = 0.00193\n"," * Iteration #14 - Loss = 87985.252 - ||grad||^2 = 247.84380 - ||diff_w|| = 0.00097\n"," * Iteration #15 - Loss = 87985.155 - ||grad||^2 = 106.74085 - ||diff_w|| = 0.00050\n"," * Iteration #16 - Loss = 87985.155 - ||grad||^2 = 49.37323 - ||diff_w|| = 0.00027\n"," * Iteration #17 - Loss = 87985.176 - ||grad||^2 = 23.45458 - ||diff_w|| = 0.00014\n"," * Iteration #18 - Loss = 87985.162 - ||grad||^2 = 11.86806 - ||diff_w|| = 0.00008\n"," * Iteration #19 - Loss = 87985.164 - ||grad||^2 = 6.01906 - ||diff_w|| = 0.00004\n"," * Iteration #20 - Loss = 87985.168 - ||grad||^2 = 2.92548 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 87985.170 - ||grad||^2 = 1.43715 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 87985.169 - ||grad||^2 = 0.73778 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 87985.169 - ||grad||^2 = 0.43582 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 87985.170 - ||grad||^2 = 0.20576 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 87985.168 - ||grad||^2 = 0.12744 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 87985.169 - ||grad||^2 = 0.08823 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 87985.169 - ||grad||^2 = 0.06496 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 87985.169 - ||grad||^2 = 0.06290 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 87985.169 - ||grad||^2 = 0.06066 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 87985.169 - ||grad||^2 = 0.05785 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 87985.169 - ||grad||^2 = 0.05597 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 87985.169 - ||grad||^2 = 0.05947 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 87985.169 - ||grad||^2 = 0.05769 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 87985.169 - ||grad||^2 = 0.05502 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 87985.170 - ||grad||^2 = 0.07296 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 87985.168 - ||grad||^2 = 0.06523 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 87985.169 - ||grad||^2 = 0.03685 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 87985.169 - ||grad||^2 = 0.05894 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 87985.169 - ||grad||^2 = 0.06052 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 87985.169 - ||grad||^2 = 0.04866 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 87985.170 - ||grad||^2 = 0.07635 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 87985.169 - ||grad||^2 = 0.06429 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 87985.169 - ||grad||^2 = 0.04609 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 87985.169 - ||grad||^2 = 0.06060 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 87985.170 - ||grad||^2 = 0.05898 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 87985.168 - ||grad||^2 = 0.04909 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 87985.170 - ||grad||^2 = 0.06539 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 87985.168 - ||grad||^2 = 0.06305 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 87985.169 - ||grad||^2 = 0.05245 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 87985.168 - ||grad||^2 = 0.06546 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 87985.170 - ||grad||^2 = 0.05959 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 87985.168 - ||grad||^2 = 0.04886 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 87985.170 - ||grad||^2 = 0.06554 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 87985.169 - ||grad||^2 = 0.06141 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 87985.169 - ||grad||^2 = 0.05599 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 87985.169 - ||grad||^2 = 0.06210 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 87985.169 - ||grad||^2 = 0.05254 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 87985.169 - ||grad||^2 = 0.04956 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 87985.170 - ||grad||^2 = 0.07756 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 87985.169 - ||grad||^2 = 0.06198 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 87985.169 - ||grad||^2 = 0.04735 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 87985.169 - ||grad||^2 = 0.06011 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 87985.169 - ||grad||^2 = 0.06147 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 87985.169 - ||grad||^2 = 0.05368 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 87985.169 - ||grad||^2 = 0.07231 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 87985.169 - ||grad||^2 = 0.06390 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 87985.168 - ||grad||^2 = 0.05557 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 87985.170 - ||grad||^2 = 0.06067 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 87985.169 - ||grad||^2 = 0.04945 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 87985.169 - ||grad||^2 = 0.05887 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 87985.170 - ||grad||^2 = 0.08521 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 87985.169 - ||grad||^2 = 0.07334 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 87985.169 - ||grad||^2 = 0.05892 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 87985.169 - ||grad||^2 = 0.05914 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 87985.169 - ||grad||^2 = 0.05885 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 87985.169 - ||grad||^2 = 0.06656 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 87985.169 - ||grad||^2 = 0.07252 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 87985.169 - ||grad||^2 = 0.06758 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 87985.169 - ||grad||^2 = 0.05919 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 87985.169 - ||grad||^2 = 0.05784 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 87985.169 - ||grad||^2 = 0.05276 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 87985.169 - ||grad||^2 = 0.05155 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 87985.169 - ||grad||^2 = 0.05572 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 87985.169 - ||grad||^2 = 0.05578 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 87985.168 - ||grad||^2 = 0.06125 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 87985.169 - ||grad||^2 = 0.05434 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 87985.168 - ||grad||^2 = 0.04706 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 87985.169 - ||grad||^2 = 0.06221 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 87985.169 - ||grad||^2 = 0.06996 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 87985.169 - ||grad||^2 = 0.06958 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 87985.169 - ||grad||^2 = 0.07068 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 87985.169 - ||grad||^2 = 0.06772 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 87985.169 - ||grad||^2 = 0.05940 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 87985.169 - ||grad||^2 = 0.05703 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 87985.169 - ||grad||^2 = 0.05334 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 87985.169 - ||grad||^2 = 0.04697 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 87985.169 - ||grad||^2 = 0.05196 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 87985.169 - ||grad||^2 = 0.05670 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 87985.168 - ||grad||^2 = 0.04869 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 87985.170 - ||grad||^2 = 0.05594 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gbGFV8kFPJdw","executionInfo":{"status":"ok","timestamp":1662713034381,"user_tz":-540,"elapsed":22,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"7cc02bbd-697e-43ab-a2e7-8f1115516247"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.831612\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"-gxteCaPPJdw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-31616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U6k8oh1ZPJdw","executionInfo":{"status":"ok","timestamp":1662713034382,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"e5c37c82-0f20-45c5-9352-53c4f77095f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-31616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-org+balAR-36616"],"metadata":{"id":"ibt42OoBPRLZ"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"Pg2iCoqiPRLa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/original+TGAN-balAR/origin+tganbalAR-36616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"y0I45Gz1PRLb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"I5x7EQoqPRLb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"fNoc8PjxPRLb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"P3KRfM-QPRLb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"UUE2CymDPRLb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"43MLIf09PRLb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"4t_j7NlqPRLc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"k7ygTXmzPRLc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aH9Iff2EPRLc","executionInfo":{"status":"ok","timestamp":1662715098216,"user_tz":-540,"elapsed":1087846,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"56b641f2-a825-4a68-bdd1-c1ebb74434ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 14506286.711 - ||grad||^2 = 24804731.97273 - ||diff_w|| = 15.77542\n"," * Iteration #2 - Loss = 3700452.605 - ||grad||^2 = 12611723.21722 - ||diff_w|| = 7.07872\n"," * Iteration #3 - Loss = 1159824.507 - ||grad||^2 = 7090180.54215 - ||diff_w|| = 3.84364\n"," * Iteration #4 - Loss = 385141.252 - ||grad||^2 = 3930534.25187 - ||diff_w|| = 1.97274\n"," * Iteration #5 - Loss = 163952.860 - ||grad||^2 = 1906931.06079 - ||diff_w|| = 0.82030\n"," * Iteration #6 - Loss = 124266.154 - ||grad||^2 = 795386.28097 - ||diff_w|| = 0.34784\n"," * Iteration #7 - Loss = 121360.458 - ||grad||^2 = 284409.36486 - ||diff_w|| = 0.16517\n"," * Iteration #8 - Loss = 121132.494 - ||grad||^2 = 95115.06451 - ||diff_w|| = 0.07421\n"," * Iteration #9 - Loss = 121131.119 - ||grad||^2 = 33138.63266 - ||diff_w|| = 0.03498\n"," * Iteration #10 - Loss = 121123.022 - ||grad||^2 = 12180.34713 - ||diff_w|| = 0.01724\n"," * Iteration #11 - Loss = 121118.763 - ||grad||^2 = 4841.98639 - ||diff_w|| = 0.00877\n"," * Iteration #12 - Loss = 121116.892 - ||grad||^2 = 2369.00368 - ||diff_w|| = 0.00457\n"," * Iteration #13 - Loss = 121116.110 - ||grad||^2 = 1179.58777 - ||diff_w|| = 0.00242\n"," * Iteration #14 - Loss = 121115.707 - ||grad||^2 = 602.67773 - ||diff_w|| = 0.00129\n"," * Iteration #15 - Loss = 121115.541 - ||grad||^2 = 310.89576 - ||diff_w|| = 0.00070\n"," * Iteration #16 - Loss = 121115.403 - ||grad||^2 = 159.09813 - ||diff_w|| = 0.00038\n"," * Iteration #17 - Loss = 121115.379 - ||grad||^2 = 81.49341 - ||diff_w|| = 0.00020\n"," * Iteration #18 - Loss = 121115.362 - ||grad||^2 = 41.82098 - ||diff_w|| = 0.00011\n"," * Iteration #19 - Loss = 121115.341 - ||grad||^2 = 21.51472 - ||diff_w|| = 0.00006\n"," * Iteration #20 - Loss = 121115.337 - ||grad||^2 = 11.01439 - ||diff_w|| = 0.00003\n"," * Iteration #21 - Loss = 121115.334 - ||grad||^2 = 5.47511 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 121115.332 - ||grad||^2 = 2.77828 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 121115.330 - ||grad||^2 = 1.38088 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 121115.331 - ||grad||^2 = 0.73941 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 121115.331 - ||grad||^2 = 0.42116 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 121115.331 - ||grad||^2 = 0.20154 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 121115.331 - ||grad||^2 = 0.13043 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 121115.331 - ||grad||^2 = 0.07587 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 121115.330 - ||grad||^2 = 0.05385 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 121115.331 - ||grad||^2 = 0.06317 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 121115.330 - ||grad||^2 = 0.04896 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 121115.331 - ||grad||^2 = 0.03913 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 121115.330 - ||grad||^2 = 0.05008 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 121115.331 - ||grad||^2 = 0.05229 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 121115.330 - ||grad||^2 = 0.05639 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 121115.332 - ||grad||^2 = 0.05499 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 121115.330 - ||grad||^2 = 0.06428 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 121115.332 - ||grad||^2 = 0.06622 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 121115.329 - ||grad||^2 = 0.07692 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 121115.332 - ||grad||^2 = 0.08125 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 121115.329 - ||grad||^2 = 0.06249 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 121115.332 - ||grad||^2 = 0.06859 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 121115.329 - ||grad||^2 = 0.07923 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 121115.332 - ||grad||^2 = 0.08670 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 121115.329 - ||grad||^2 = 0.06963 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 121115.332 - ||grad||^2 = 0.06661 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 121115.329 - ||grad||^2 = 0.08038 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 121115.332 - ||grad||^2 = 0.06984 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 121115.330 - ||grad||^2 = 0.06461 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 121115.332 - ||grad||^2 = 0.05810 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 121115.329 - ||grad||^2 = 0.05888 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 121115.332 - ||grad||^2 = 0.07639 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 121115.329 - ||grad||^2 = 0.07988 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 121115.332 - ||grad||^2 = 0.07358 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 121115.330 - ||grad||^2 = 0.05643 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 121115.332 - ||grad||^2 = 0.07332 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 121115.330 - ||grad||^2 = 0.06994 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 121115.331 - ||grad||^2 = 0.05258 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 121115.330 - ||grad||^2 = 0.06548 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 121115.331 - ||grad||^2 = 0.05131 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 121115.330 - ||grad||^2 = 0.04462 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 121115.331 - ||grad||^2 = 0.05550 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 121115.330 - ||grad||^2 = 0.06116 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 121115.332 - ||grad||^2 = 0.08378 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 121115.329 - ||grad||^2 = 0.09335 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 121115.332 - ||grad||^2 = 0.07749 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 121115.329 - ||grad||^2 = 0.07194 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 121115.332 - ||grad||^2 = 0.05939 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 121115.330 - ||grad||^2 = 0.04730 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 121115.331 - ||grad||^2 = 0.04708 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 121115.330 - ||grad||^2 = 0.04695 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 121115.331 - ||grad||^2 = 0.04668 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 121115.329 - ||grad||^2 = 0.06677 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 121115.332 - ||grad||^2 = 0.08816 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 121115.329 - ||grad||^2 = 0.06877 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 121115.332 - ||grad||^2 = 0.06720 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 121115.329 - ||grad||^2 = 0.08014 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 121115.332 - ||grad||^2 = 0.07547 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 121115.330 - ||grad||^2 = 0.05456 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 121115.331 - ||grad||^2 = 0.04383 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 121115.330 - ||grad||^2 = 0.04896 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 121115.331 - ||grad||^2 = 0.04559 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 121115.329 - ||grad||^2 = 0.06732 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 121115.332 - ||grad||^2 = 0.08786 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 121115.329 - ||grad||^2 = 0.06929 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 121115.332 - ||grad||^2 = 0.06807 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 121115.329 - ||grad||^2 = 0.07991 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 121115.332 - ||grad||^2 = 0.07997 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 121115.329 - ||grad||^2 = 0.06363 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 121115.332 - ||grad||^2 = 0.05691 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 121115.329 - ||grad||^2 = 0.06939 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 121115.332 - ||grad||^2 = 0.06919 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 121115.330 - ||grad||^2 = 0.05007 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 121115.331 - ||grad||^2 = 0.04479 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 121115.329 - ||grad||^2 = 0.06726 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 121115.332 - ||grad||^2 = 0.08792 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 121115.329 - ||grad||^2 = 0.06932 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 121115.332 - ||grad||^2 = 0.06798 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 121115.329 - ||grad||^2 = 0.07994 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 121115.332 - ||grad||^2 = 0.07998 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EeCZ4DTvPRLc","executionInfo":{"status":"ok","timestamp":1662715098216,"user_tz":-540,"elapsed":17,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"ebe32177-b55b-4430-a270-6940e13d14d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.830315\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"IV_6peNfPRLc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-36616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LUYL08-cPRLc","executionInfo":{"status":"ok","timestamp":1662715098216,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"5819cb90-b119-4352-9f83-28e637a5240f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-36616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-org+balAR-41616"],"metadata":{"id":"unoekyaBPpQc"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"MG5T_GCCPpQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/original+TGAN-balAR/origin+tganbalAR-41616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"XeINw-7_PpQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"TRbvEOZnPpQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"Xpc5DyS-PpQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"qxPDATJJPpQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"d9d-zCQtPpQe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"dJCDvc9MPpQe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"3u_behSLPpQe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"1sEj7eYjPpQe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WvWKFOJwPpQe","executionInfo":{"status":"ok","timestamp":1662716926611,"user_tz":-540,"elapsed":1411513,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"ed9f0b55-a344-4868-e3f2-bdd1664a9430"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 16356825.265 - ||grad||^2 = 27451213.53346 - ||diff_w|| = 16.81271\n"," * Iteration #2 - Loss = 4171842.398 - ||grad||^2 = 14004819.80317 - ||diff_w|| = 7.53866\n"," * Iteration #3 - Loss = 1309101.502 - ||grad||^2 = 7895021.84308 - ||diff_w|| = 4.07835\n"," * Iteration #4 - Loss = 440013.089 - ||grad||^2 = 4311780.44203 - ||diff_w|| = 2.04676\n"," * Iteration #5 - Loss = 205914.157 - ||grad||^2 = 2056146.00482 - ||diff_w|| = 0.76507\n"," * Iteration #6 - Loss = 166069.383 - ||grad||^2 = 926166.75215 - ||diff_w|| = 0.35218\n"," * Iteration #7 - Loss = 162571.203 - ||grad||^2 = 333223.82461 - ||diff_w|| = 0.14486\n"," * Iteration #8 - Loss = 162740.366 - ||grad||^2 = 107368.76843 - ||diff_w|| = 0.05608\n"," * Iteration #9 - Loss = 162766.014 - ||grad||^2 = 35109.77829 - ||diff_w|| = 0.02276\n"," * Iteration #10 - Loss = 162770.490 - ||grad||^2 = 12145.92484 - ||diff_w|| = 0.00974\n"," * Iteration #11 - Loss = 162775.575 - ||grad||^2 = 4473.36647 - ||diff_w|| = 0.00452\n"," * Iteration #12 - Loss = 162776.017 - ||grad||^2 = 1749.18530 - ||diff_w|| = 0.00220\n"," * Iteration #13 - Loss = 162776.195 - ||grad||^2 = 744.86045 - ||diff_w|| = 0.00111\n"," * Iteration #14 - Loss = 162776.141 - ||grad||^2 = 360.41159 - ||diff_w|| = 0.00058\n"," * Iteration #15 - Loss = 162776.159 - ||grad||^2 = 181.30591 - ||diff_w|| = 0.00031\n"," * Iteration #16 - Loss = 162776.091 - ||grad||^2 = 91.61989 - ||diff_w|| = 0.00017\n"," * Iteration #17 - Loss = 162776.080 - ||grad||^2 = 46.31835 - ||diff_w|| = 0.00009\n"," * Iteration #18 - Loss = 162776.061 - ||grad||^2 = 23.52314 - ||diff_w|| = 0.00005\n"," * Iteration #19 - Loss = 162776.061 - ||grad||^2 = 12.16142 - ||diff_w|| = 0.00003\n"," * Iteration #20 - Loss = 162776.061 - ||grad||^2 = 6.23952 - ||diff_w|| = 0.00001\n"," * Iteration #21 - Loss = 162776.056 - ||grad||^2 = 3.13220 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 162776.057 - ||grad||^2 = 1.63384 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 162776.057 - ||grad||^2 = 0.81121 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 162776.056 - ||grad||^2 = 0.41178 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 162776.056 - ||grad||^2 = 0.20077 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 162776.055 - ||grad||^2 = 0.07677 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 162776.055 - ||grad||^2 = 0.04878 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 162776.055 - ||grad||^2 = 0.03727 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 162776.056 - ||grad||^2 = 0.03231 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 162776.056 - ||grad||^2 = 0.02501 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 162776.056 - ||grad||^2 = 0.04179 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 162776.055 - ||grad||^2 = 0.05217 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 162776.056 - ||grad||^2 = 0.03775 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 162776.055 - ||grad||^2 = 0.03455 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 162776.056 - ||grad||^2 = 0.03205 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 162776.055 - ||grad||^2 = 0.02987 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 162776.056 - ||grad||^2 = 0.02926 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 162776.056 - ||grad||^2 = 0.03409 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 162776.056 - ||grad||^2 = 0.04563 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 162776.055 - ||grad||^2 = 0.03719 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 162776.056 - ||grad||^2 = 0.03277 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 162776.056 - ||grad||^2 = 0.03592 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 162776.056 - ||grad||^2 = 0.03042 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 162776.055 - ||grad||^2 = 0.03069 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 162776.056 - ||grad||^2 = 0.02936 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 162776.055 - ||grad||^2 = 0.03422 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 162776.056 - ||grad||^2 = 0.04617 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 162776.055 - ||grad||^2 = 0.05020 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 162776.056 - ||grad||^2 = 0.03900 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 162776.055 - ||grad||^2 = 0.02380 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 162776.056 - ||grad||^2 = 0.02670 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 162776.055 - ||grad||^2 = 0.04345 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 162776.056 - ||grad||^2 = 0.03297 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 162776.056 - ||grad||^2 = 0.02352 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 162776.056 - ||grad||^2 = 0.02578 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 162776.055 - ||grad||^2 = 0.04302 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 162776.056 - ||grad||^2 = 0.04989 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 162776.056 - ||grad||^2 = 0.03003 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 162776.056 - ||grad||^2 = 0.02939 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 162776.055 - ||grad||^2 = 0.04668 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 162776.056 - ||grad||^2 = 0.03533 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 162776.055 - ||grad||^2 = 0.02281 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 162776.056 - ||grad||^2 = 0.02552 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 162776.055 - ||grad||^2 = 0.04315 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 162776.056 - ||grad||^2 = 0.04968 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 162776.056 - ||grad||^2 = 0.03027 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 162776.056 - ||grad||^2 = 0.02937 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 162776.055 - ||grad||^2 = 0.04531 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 162776.056 - ||grad||^2 = 0.03378 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 162776.056 - ||grad||^2 = 0.02388 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 162776.056 - ||grad||^2 = 0.02599 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 162776.055 - ||grad||^2 = 0.04459 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 162776.056 - ||grad||^2 = 0.05102 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 162776.055 - ||grad||^2 = 0.03883 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 162776.056 - ||grad||^2 = 0.03484 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 162776.055 - ||grad||^2 = 0.03149 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 162776.056 - ||grad||^2 = 0.03010 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 162776.056 - ||grad||^2 = 0.03451 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 162776.056 - ||grad||^2 = 0.02960 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 162776.055 - ||grad||^2 = 0.03023 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 162776.056 - ||grad||^2 = 0.04596 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 162776.055 - ||grad||^2 = 0.04045 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 162776.056 - ||grad||^2 = 0.03391 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 162776.055 - ||grad||^2 = 0.03212 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 162776.056 - ||grad||^2 = 0.02977 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 162776.056 - ||grad||^2 = 0.03471 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 162776.056 - ||grad||^2 = 0.02949 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 162776.055 - ||grad||^2 = 0.03028 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 162776.056 - ||grad||^2 = 0.04592 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 162776.055 - ||grad||^2 = 0.04046 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 162776.056 - ||grad||^2 = 0.03390 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 162776.055 - ||grad||^2 = 0.03212 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 162776.056 - ||grad||^2 = 0.02976 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 162776.056 - ||grad||^2 = 0.03471 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 162776.056 - ||grad||^2 = 0.02949 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 162776.055 - ||grad||^2 = 0.03028 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 162776.056 - ||grad||^2 = 0.04592 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 162776.055 - ||grad||^2 = 0.04046 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 162776.056 - ||grad||^2 = 0.03390 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 162776.055 - ||grad||^2 = 0.03212 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3PKwEfjFPpQe","executionInfo":{"status":"ok","timestamp":1662716926611,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"1a94a0b3-c3a4-4b98-f1bb-e5fb4d235701"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.830892\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"g1Y5qZqhPpQe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-41616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9EkefnVHPpQe","executionInfo":{"status":"ok","timestamp":1662716926611,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"253b91e0-9f63-4ad9-b831-ab4b7883d580"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-41616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-org+balAR-46616"],"metadata":{"id":"vrM7wrezPw7h"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"tUWqkOPqPw7i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/original+TGAN-balAR/origin+tganbalAR-46616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"wIUc9x4QPw7i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"ast2RRRKPw7i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"YJ-sRcrYPw7i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"vsdXg5rMPw7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"iWtoPzpUPw7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"Kb1VYjO4Pw7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"AvIVElv0Pw7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"zbx4sW7aPw7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e_yk7DmSPw7j","executionInfo":{"status":"ok","timestamp":1662718755737,"user_tz":-540,"elapsed":1794217,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"6ba465bf-63ea-4f23-a0c7-d3041cccac05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 34710766.835 - ||grad||^2 = 48843617.20646 - ||diff_w|| = 17.59845\n"," * Iteration #2 - Loss = 8790343.757 - ||grad||^2 = 24688483.60264 - ||diff_w|| = 7.90751\n"," * Iteration #3 - Loss = 2718163.441 - ||grad||^2 = 13761145.30731 - ||diff_w|| = 4.31623\n"," * Iteration #4 - Loss = 867518.812 - ||grad||^2 = 7569518.92302 - ||diff_w|| = 2.26759\n"," * Iteration #5 - Loss = 330270.006 - ||grad||^2 = 3763233.97894 - ||diff_w|| = 0.98907\n"," * Iteration #6 - Loss = 218247.486 - ||grad||^2 = 1731139.30715 - ||diff_w|| = 0.40929\n"," * Iteration #7 - Loss = 204271.874 - ||grad||^2 = 677772.63246 - ||diff_w|| = 0.17694\n"," * Iteration #8 - Loss = 203034.827 - ||grad||^2 = 242334.76457 - ||diff_w|| = 0.07034\n"," * Iteration #9 - Loss = 202711.911 - ||grad||^2 = 85811.79524 - ||diff_w|| = 0.02807\n"," * Iteration #10 - Loss = 202727.383 - ||grad||^2 = 28534.93146 - ||diff_w|| = 0.01012\n"," * Iteration #11 - Loss = 202748.122 - ||grad||^2 = 8719.03260 - ||diff_w|| = 0.00329\n"," * Iteration #12 - Loss = 202751.478 - ||grad||^2 = 2902.48531 - ||diff_w|| = 0.00123\n"," * Iteration #13 - Loss = 202751.415 - ||grad||^2 = 1075.44581 - ||diff_w|| = 0.00053\n"," * Iteration #14 - Loss = 202751.223 - ||grad||^2 = 421.68019 - ||diff_w|| = 0.00025\n"," * Iteration #15 - Loss = 202751.221 - ||grad||^2 = 177.34894 - ||diff_w|| = 0.00012\n"," * Iteration #16 - Loss = 202751.169 - ||grad||^2 = 81.84002 - ||diff_w|| = 0.00006\n"," * Iteration #17 - Loss = 202751.152 - ||grad||^2 = 40.65240 - ||diff_w|| = 0.00003\n"," * Iteration #18 - Loss = 202751.156 - ||grad||^2 = 20.50068 - ||diff_w|| = 0.00002\n"," * Iteration #19 - Loss = 202751.153 - ||grad||^2 = 10.75140 - ||diff_w|| = 0.00001\n"," * Iteration #20 - Loss = 202751.143 - ||grad||^2 = 5.47178 - ||diff_w|| = 0.00000\n"," * Iteration #21 - Loss = 202751.145 - ||grad||^2 = 2.95578 - ||diff_w|| = 0.00000\n"," * Iteration #22 - Loss = 202751.144 - ||grad||^2 = 1.55923 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 202751.144 - ||grad||^2 = 0.80195 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 202751.143 - ||grad||^2 = 0.39257 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 202751.144 - ||grad||^2 = 0.25698 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 202751.142 - ||grad||^2 = 0.12470 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 202751.145 - ||grad||^2 = 0.11061 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 202751.142 - ||grad||^2 = 0.05878 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 202751.143 - ||grad||^2 = 0.05954 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 202751.143 - ||grad||^2 = 0.05636 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 202751.143 - ||grad||^2 = 0.04811 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 202751.143 - ||grad||^2 = 0.06352 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 202751.143 - ||grad||^2 = 0.06170 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 202751.143 - ||grad||^2 = 0.07019 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 202751.144 - ||grad||^2 = 0.07665 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 202751.142 - ||grad||^2 = 0.06378 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 202751.144 - ||grad||^2 = 0.06561 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 202751.142 - ||grad||^2 = 0.05353 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 202751.143 - ||grad||^2 = 0.04940 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 202751.143 - ||grad||^2 = 0.06142 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 202751.143 - ||grad||^2 = 0.05323 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 202751.143 - ||grad||^2 = 0.04715 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 202751.144 - ||grad||^2 = 0.06117 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 202751.142 - ||grad||^2 = 0.08331 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 202751.144 - ||grad||^2 = 0.07991 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 202751.142 - ||grad||^2 = 0.07471 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 202751.144 - ||grad||^2 = 0.06838 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 202751.142 - ||grad||^2 = 0.05319 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 202751.143 - ||grad||^2 = 0.04602 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 202751.143 - ||grad||^2 = 0.06248 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 202751.143 - ||grad||^2 = 0.05239 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 202751.143 - ||grad||^2 = 0.04778 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 202751.144 - ||grad||^2 = 0.05759 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 202751.142 - ||grad||^2 = 0.08262 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 202751.144 - ||grad||^2 = 0.08072 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 202751.142 - ||grad||^2 = 0.07608 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 202751.144 - ||grad||^2 = 0.06091 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 202751.142 - ||grad||^2 = 0.05288 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 202751.143 - ||grad||^2 = 0.04501 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 202751.143 - ||grad||^2 = 0.06072 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 202751.143 - ||grad||^2 = 0.05195 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 202751.143 - ||grad||^2 = 0.05007 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 202751.143 - ||grad||^2 = 0.04796 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 202751.143 - ||grad||^2 = 0.05498 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 202751.144 - ||grad||^2 = 0.07800 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 202751.142 - ||grad||^2 = 0.07936 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 202751.144 - ||grad||^2 = 0.07692 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 202751.142 - ||grad||^2 = 0.05534 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 202751.143 - ||grad||^2 = 0.04741 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 202751.143 - ||grad||^2 = 0.06214 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 202751.143 - ||grad||^2 = 0.05274 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 202751.143 - ||grad||^2 = 0.05427 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 202751.144 - ||grad||^2 = 0.06044 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 202751.142 - ||grad||^2 = 0.07228 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 202751.144 - ||grad||^2 = 0.08273 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 202751.142 - ||grad||^2 = 0.08060 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 202751.145 - ||grad||^2 = 0.07862 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 202751.142 - ||grad||^2 = 0.05563 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 202751.143 - ||grad||^2 = 0.04030 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 202751.143 - ||grad||^2 = 0.06187 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 202751.143 - ||grad||^2 = 0.05513 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 202751.143 - ||grad||^2 = 0.05414 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 202751.144 - ||grad||^2 = 0.06169 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 202751.142 - ||grad||^2 = 0.07991 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 202751.144 - ||grad||^2 = 0.08222 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 202751.142 - ||grad||^2 = 0.07572 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 202751.144 - ||grad||^2 = 0.06109 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 202751.142 - ||grad||^2 = 0.05293 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 202751.143 - ||grad||^2 = 0.04513 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 202751.143 - ||grad||^2 = 0.06066 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 202751.143 - ||grad||^2 = 0.05199 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 202751.143 - ||grad||^2 = 0.05007 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 202751.143 - ||grad||^2 = 0.04797 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 202751.143 - ||grad||^2 = 0.05497 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 202751.144 - ||grad||^2 = 0.07800 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 202751.142 - ||grad||^2 = 0.07936 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 202751.144 - ||grad||^2 = 0.07692 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 202751.142 - ||grad||^2 = 0.05534 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 202751.143 - ||grad||^2 = 0.04741 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 202751.143 - ||grad||^2 = 0.06214 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y4rgXkrgPw7j","executionInfo":{"status":"ok","timestamp":1662718755737,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"afbcab89-1340-4d77-ebc0-59cc33c9b421"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.830688\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"6w8PO5_TPw7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-46616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Djgl1JrJPw7k","executionInfo":{"status":"ok","timestamp":1662718755738,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"cabe7a4c-6492-4d48-8ade-5f2fffe30474"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-46616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# tgan-org+balAR-51616"],"metadata":{"id":"R9WFaEkVP4JG"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"NiU9Ks1pP4JG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/original+TGAN-balAR/origin+tganbalAR-51616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"9DgVaGkeP4JH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"YoW5sRstP4JH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"wdZ7Gb4KP4JH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"JJN7reCeP4JH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"_nKPx7RJP4JH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"gaU0ZXtCP4JH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"otb6UQQdP4JH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"nv_IGK7dP4JI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ruxLBUIjP4JI","executionInfo":{"status":"ok","timestamp":1662721229445,"user_tz":-540,"elapsed":2238498,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"4337ea94-be9e-4ae3-c37a-c17b6a78532b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 23513975.338 - ||grad||^2 = 39155053.49174 - ||diff_w|| = 20.15564\n"," * Iteration #2 - Loss = 5988631.991 - ||grad||^2 = 19889842.47950 - ||diff_w|| = 9.03482\n"," * Iteration #3 - Loss = 1874248.850 - ||grad||^2 = 11112454.44268 - ||diff_w|| = 4.87276\n"," * Iteration #4 - Loss = 633194.259 - ||grad||^2 = 5895222.99888 - ||diff_w|| = 2.39138\n"," * Iteration #5 - Loss = 316552.110 - ||grad||^2 = 2853557.91232 - ||diff_w|| = 1.03746\n"," * Iteration #6 - Loss = 263547.536 - ||grad||^2 = 1166043.62299 - ||diff_w|| = 0.48122\n"," * Iteration #7 - Loss = 259039.883 - ||grad||^2 = 431743.11857 - ||diff_w|| = 0.21948\n"," * Iteration #8 - Loss = 258329.588 - ||grad||^2 = 154317.10767 - ||diff_w|| = 0.09687\n"," * Iteration #9 - Loss = 258305.825 - ||grad||^2 = 52017.62772 - ||diff_w|| = 0.04327\n"," * Iteration #10 - Loss = 258338.793 - ||grad||^2 = 17508.95930 - ||diff_w|| = 0.02070\n"," * Iteration #11 - Loss = 258351.465 - ||grad||^2 = 6207.30067 - ||diff_w|| = 0.01023\n"," * Iteration #12 - Loss = 258354.934 - ||grad||^2 = 2294.48996 - ||diff_w|| = 0.00520\n"," * Iteration #13 - Loss = 258356.536 - ||grad||^2 = 865.20354 - ||diff_w|| = 0.00270\n"," * Iteration #14 - Loss = 258357.091 - ||grad||^2 = 333.20162 - ||diff_w|| = 0.00143\n"," * Iteration #15 - Loss = 258357.263 - ||grad||^2 = 130.31808 - ||diff_w|| = 0.00077\n"," * Iteration #16 - Loss = 258357.352 - ||grad||^2 = 52.20481 - ||diff_w|| = 0.00041\n"," * Iteration #17 - Loss = 258357.384 - ||grad||^2 = 21.60060 - ||diff_w|| = 0.00022\n"," * Iteration #18 - Loss = 258357.403 - ||grad||^2 = 9.31269 - ||diff_w|| = 0.00012\n"," * Iteration #19 - Loss = 258357.410 - ||grad||^2 = 3.91065 - ||diff_w|| = 0.00007\n"," * Iteration #20 - Loss = 258357.411 - ||grad||^2 = 1.77501 - ||diff_w|| = 0.00004\n"," * Iteration #21 - Loss = 258357.413 - ||grad||^2 = 0.86757 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 258357.413 - ||grad||^2 = 0.41572 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 258357.411 - ||grad||^2 = 0.24153 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 258357.413 - ||grad||^2 = 0.12831 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 258357.412 - ||grad||^2 = 0.09701 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 258357.414 - ||grad||^2 = 0.07609 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 258357.411 - ||grad||^2 = 0.07020 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 258357.414 - ||grad||^2 = 0.08309 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 258357.412 - ||grad||^2 = 0.07601 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 258357.414 - ||grad||^2 = 0.06152 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 258357.412 - ||grad||^2 = 0.05820 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 258357.414 - ||grad||^2 = 0.06153 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 258357.412 - ||grad||^2 = 0.06083 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 258357.414 - ||grad||^2 = 0.06516 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 258357.412 - ||grad||^2 = 0.07193 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 258357.414 - ||grad||^2 = 0.07841 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 258357.412 - ||grad||^2 = 0.07844 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 258357.414 - ||grad||^2 = 0.06125 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 258357.411 - ||grad||^2 = 0.06550 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 258357.414 - ||grad||^2 = 0.09069 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 258357.412 - ||grad||^2 = 0.06757 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 258357.413 - ||grad||^2 = 0.04396 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 258357.412 - ||grad||^2 = 0.06859 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 258357.414 - ||grad||^2 = 0.09317 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 258357.411 - ||grad||^2 = 0.08526 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 258357.414 - ||grad||^2 = 0.07415 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 258357.412 - ||grad||^2 = 0.06538 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 258357.414 - ||grad||^2 = 0.07067 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 258357.412 - ||grad||^2 = 0.06880 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 258357.414 - ||grad||^2 = 0.06983 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 258357.412 - ||grad||^2 = 0.06725 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 258357.414 - ||grad||^2 = 0.07043 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 258357.411 - ||grad||^2 = 0.07164 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 258357.414 - ||grad||^2 = 0.07886 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 258357.412 - ||grad||^2 = 0.07785 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 258357.413 - ||grad||^2 = 0.04925 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 258357.411 - ||grad||^2 = 0.06247 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 258357.414 - ||grad||^2 = 0.08792 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 258357.412 - ||grad||^2 = 0.07028 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 258357.413 - ||grad||^2 = 0.04678 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 258357.412 - ||grad||^2 = 0.06530 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 258357.414 - ||grad||^2 = 0.09498 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 258357.411 - ||grad||^2 = 0.07517 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 258357.414 - ||grad||^2 = 0.04623 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 258357.412 - ||grad||^2 = 0.04699 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 258357.414 - ||grad||^2 = 0.08786 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 258357.411 - ||grad||^2 = 0.10355 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 258357.414 - ||grad||^2 = 0.07762 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 258357.411 - ||grad||^2 = 0.06660 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 258357.414 - ||grad||^2 = 0.08730 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 258357.412 - ||grad||^2 = 0.06244 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 258357.413 - ||grad||^2 = 0.05955 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 258357.412 - ||grad||^2 = 0.07278 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 258357.414 - ||grad||^2 = 0.09087 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 258357.411 - ||grad||^2 = 0.08603 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 258357.414 - ||grad||^2 = 0.07396 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 258357.412 - ||grad||^2 = 0.06563 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 258357.414 - ||grad||^2 = 0.07046 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 258357.412 - ||grad||^2 = 0.06892 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 258357.414 - ||grad||^2 = 0.06976 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 258357.412 - ||grad||^2 = 0.06728 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 258357.414 - ||grad||^2 = 0.07042 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 258357.411 - ||grad||^2 = 0.07164 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 258357.414 - ||grad||^2 = 0.07885 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 258357.412 - ||grad||^2 = 0.07785 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 258357.413 - ||grad||^2 = 0.04925 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 258357.411 - ||grad||^2 = 0.06247 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 258357.414 - ||grad||^2 = 0.08792 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 258357.412 - ||grad||^2 = 0.07028 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 258357.413 - ||grad||^2 = 0.04678 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 258357.412 - ||grad||^2 = 0.06530 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 258357.414 - ||grad||^2 = 0.09498 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 258357.411 - ||grad||^2 = 0.07517 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 258357.414 - ||grad||^2 = 0.04623 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 258357.412 - ||grad||^2 = 0.04699 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 258357.414 - ||grad||^2 = 0.08786 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 258357.411 - ||grad||^2 = 0.10355 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 258357.414 - ||grad||^2 = 0.07762 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 258357.411 - ||grad||^2 = 0.06660 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 258357.414 - ||grad||^2 = 0.08730 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gzfQ8T-VP4JI","executionInfo":{"status":"ok","timestamp":1662721229446,"user_tz":-540,"elapsed":14,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"38122afe-6d40-440e-f28e-02ea97510568"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.830279\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"4BFfvej9P4JI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-51616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MC9bat8SP4JI","executionInfo":{"status":"ok","timestamp":1662721229446,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"bc343a0d-1cce-4e09-a226-cfce08ddaf5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+balAR-51616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# orig+tgan-aug-6616"],"metadata":{"id":"xMYKkNHNqmjx"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"2yFHuBprqmjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/Original+TGAN-aug/orig-TGANaug-6616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"d73vmbyGqmjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"jW6bIPPdqmjy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"tinPG_Buqmjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"1UXqBTqjqmjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"xOF_AYUvqmjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"oqm45kCJqmjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"ekoYtJzHqmjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"Ibdk3264qmjz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662901871866,"user_tz":-540,"elapsed":41479,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"b0fa2c46-e2ce-42ef-8096-519239560934","id":"GKsScp5bqmjz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 203490.267 - ||grad||^2 = 253112.10863 - ||diff_w|| = 16.08824\n"," * Iteration #2 - Loss = 52513.804 - ||grad||^2 = 129946.50532 - ||diff_w|| = 7.21471\n"," * Iteration #3 - Loss = 16870.611 - ||grad||^2 = 74951.85062 - ||diff_w|| = 3.90716\n"," * Iteration #4 - Loss = 5900.117 - ||grad||^2 = 43744.78429 - ||diff_w|| = 1.96547\n"," * Iteration #5 - Loss = 2693.929 - ||grad||^2 = 20283.05800 - ||diff_w|| = 0.74869\n"," * Iteration #6 - Loss = 2051.945 - ||grad||^2 = 8111.82582 - ||diff_w|| = 0.29658\n"," * Iteration #7 - Loss = 1995.352 - ||grad||^2 = 3335.71833 - ||diff_w|| = 0.13771\n"," * Iteration #8 - Loss = 1995.699 - ||grad||^2 = 1249.90275 - ||diff_w|| = 0.06297\n"," * Iteration #9 - Loss = 1996.886 - ||grad||^2 = 480.36079 - ||diff_w|| = 0.03022\n"," * Iteration #10 - Loss = 1997.304 - ||grad||^2 = 198.05305 - ||diff_w|| = 0.01485\n"," * Iteration #11 - Loss = 1997.408 - ||grad||^2 = 90.17372 - ||diff_w|| = 0.00763\n"," * Iteration #12 - Loss = 1997.440 - ||grad||^2 = 43.29480 - ||diff_w|| = 0.00407\n"," * Iteration #13 - Loss = 1997.449 - ||grad||^2 = 22.08751 - ||diff_w|| = 0.00220\n"," * Iteration #14 - Loss = 1997.451 - ||grad||^2 = 11.85771 - ||diff_w|| = 0.00119\n"," * Iteration #15 - Loss = 1997.452 - ||grad||^2 = 6.40312 - ||diff_w|| = 0.00065\n"," * Iteration #16 - Loss = 1997.452 - ||grad||^2 = 3.39795 - ||diff_w|| = 0.00035\n"," * Iteration #17 - Loss = 1997.452 - ||grad||^2 = 1.81506 - ||diff_w|| = 0.00019\n"," * Iteration #18 - Loss = 1997.453 - ||grad||^2 = 0.98088 - ||diff_w|| = 0.00011\n"," * Iteration #19 - Loss = 1997.453 - ||grad||^2 = 0.54721 - ||diff_w|| = 0.00006\n"," * Iteration #20 - Loss = 1997.452 - ||grad||^2 = 0.30528 - ||diff_w|| = 0.00003\n"," * Iteration #21 - Loss = 1997.453 - ||grad||^2 = 0.16359 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 1997.453 - ||grad||^2 = 0.08997 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 1997.452 - ||grad||^2 = 0.06890 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 1997.453 - ||grad||^2 = 0.02954 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 1997.452 - ||grad||^2 = 0.02806 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 1997.453 - ||grad||^2 = 0.01389 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 1997.453 - ||grad||^2 = 0.00764 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 1997.452 - ||grad||^2 = 0.03986 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 1997.453 - ||grad||^2 = 0.03317 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 1997.452 - ||grad||^2 = 0.02515 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 1997.453 - ||grad||^2 = 0.01605 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 1997.453 - ||grad||^2 = 0.00883 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 1997.452 - ||grad||^2 = 0.02962 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 1997.453 - ||grad||^2 = 0.02690 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 1997.452 - ||grad||^2 = 0.02102 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 1997.453 - ||grad||^2 = 0.01400 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 1997.453 - ||grad||^2 = 0.00770 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 1997.452 - ||grad||^2 = 0.03860 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 1997.453 - ||grad||^2 = 0.03335 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 1997.452 - ||grad||^2 = 0.02513 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 1997.453 - ||grad||^2 = 0.01625 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 1997.453 - ||grad||^2 = 0.00894 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 1997.452 - ||grad||^2 = 0.02957 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 1997.453 - ||grad||^2 = 0.02693 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 1997.452 - ||grad||^2 = 0.02101 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 1997.453 - ||grad||^2 = 0.01400 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 1997.453 - ||grad||^2 = 0.00770 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 1997.452 - ||grad||^2 = 0.03860 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 1997.453 - ||grad||^2 = 0.03335 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 1997.452 - ||grad||^2 = 0.02513 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 1997.453 - ||grad||^2 = 0.01625 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 1997.453 - ||grad||^2 = 0.00894 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 1997.452 - ||grad||^2 = 0.02957 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 1997.453 - ||grad||^2 = 0.02693 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 1997.452 - ||grad||^2 = 0.02101 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 1997.453 - ||grad||^2 = 0.01400 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 1997.453 - ||grad||^2 = 0.00770 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 1997.452 - ||grad||^2 = 0.03860 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 1997.453 - ||grad||^2 = 0.03335 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 1997.452 - ||grad||^2 = 0.02513 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 1997.453 - ||grad||^2 = 0.01625 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 1997.453 - ||grad||^2 = 0.00894 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 1997.452 - ||grad||^2 = 0.02957 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 1997.453 - ||grad||^2 = 0.02693 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 1997.452 - ||grad||^2 = 0.02101 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 1997.453 - ||grad||^2 = 0.01400 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 1997.453 - ||grad||^2 = 0.00770 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 1997.452 - ||grad||^2 = 0.03860 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 1997.453 - ||grad||^2 = 0.03335 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 1997.452 - ||grad||^2 = 0.02513 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 1997.453 - ||grad||^2 = 0.01625 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 1997.453 - ||grad||^2 = 0.00894 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 1997.452 - ||grad||^2 = 0.02957 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 1997.453 - ||grad||^2 = 0.02693 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 1997.452 - ||grad||^2 = 0.02101 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 1997.453 - ||grad||^2 = 0.01400 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 1997.453 - ||grad||^2 = 0.00770 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 1997.452 - ||grad||^2 = 0.03860 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 1997.453 - ||grad||^2 = 0.03335 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 1997.452 - ||grad||^2 = 0.02513 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 1997.453 - ||grad||^2 = 0.01625 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 1997.453 - ||grad||^2 = 0.00894 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 1997.452 - ||grad||^2 = 0.02957 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 1997.453 - ||grad||^2 = 0.02693 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 1997.452 - ||grad||^2 = 0.02101 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 1997.453 - ||grad||^2 = 0.01400 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 1997.453 - ||grad||^2 = 0.00770 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 1997.452 - ||grad||^2 = 0.03860 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 1997.453 - ||grad||^2 = 0.03335 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 1997.452 - ||grad||^2 = 0.02513 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 1997.453 - ||grad||^2 = 0.01625 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 1997.453 - ||grad||^2 = 0.00894 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 1997.452 - ||grad||^2 = 0.02957 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 1997.453 - ||grad||^2 = 0.02693 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 1997.452 - ||grad||^2 = 0.02101 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 1997.453 - ||grad||^2 = 0.01400 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 1997.453 - ||grad||^2 = 0.00770 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 1997.452 - ||grad||^2 = 0.03860 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 1997.453 - ||grad||^2 = 0.03335 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 1997.452 - ||grad||^2 = 0.02513 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662901871866,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"9fda9c51-9020-4abb-8b5a-3d9370fae4a3","id":"L1FnZaz4qmj0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.836704\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"u7cQVIDBqmj0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-6616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662901871867,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"2961bade-ff6b-4051-ede8-a77f5f118e66","id":"12HwpHr2qmj0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-6616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# orig+tgan-aug-11616"],"metadata":{"id":"iTGZa3ZZrEry"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"CcW7oBEZrErz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/Original+TGAN-aug/orig-TGANaug-11616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"3bfbNdfVrErz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"DSDFsYZ_rEr0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"XjVoROUerEr0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"zFa13thtrEr0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"2G6EfSolrEr0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"RmF27h1RrEr0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"4tOzPu4TrEr0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"HqNSpUClrEr0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3a36179a-36c3-41da-834d-01d4a508f827","id":"BFoy-DWBrEr1","executionInfo":{"status":"ok","timestamp":1662902064702,"user_tz":-540,"elapsed":117675,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 704144.425 - ||grad||^2 = 1450305.37871 - ||diff_w|| = 17.29851\n"," * Iteration #2 - Loss = 178534.536 - ||grad||^2 = 739786.59858 - ||diff_w|| = 7.75262\n"," * Iteration #3 - Loss = 55093.685 - ||grad||^2 = 416057.24638 - ||diff_w|| = 4.17929\n"," * Iteration #4 - Loss = 17900.788 - ||grad||^2 = 228085.50410 - ||diff_w|| = 2.08625\n"," * Iteration #5 - Loss = 8105.943 - ||grad||^2 = 115178.51023 - ||diff_w|| = 0.97240\n"," * Iteration #6 - Loss = 6201.352 - ||grad||^2 = 50414.42709 - ||diff_w|| = 0.49870\n"," * Iteration #7 - Loss = 6012.064 - ||grad||^2 = 16882.83031 - ||diff_w|| = 0.25461\n"," * Iteration #8 - Loss = 6034.850 - ||grad||^2 = 5612.92741 - ||diff_w|| = 0.12058\n"," * Iteration #9 - Loss = 6037.709 - ||grad||^2 = 2432.07038 - ||diff_w|| = 0.05741\n"," * Iteration #10 - Loss = 6036.447 - ||grad||^2 = 1193.74637 - ||diff_w|| = 0.02918\n"," * Iteration #11 - Loss = 6036.021 - ||grad||^2 = 606.16770 - ||diff_w|| = 0.01513\n"," * Iteration #12 - Loss = 6035.894 - ||grad||^2 = 317.47404 - ||diff_w|| = 0.00800\n"," * Iteration #13 - Loss = 6035.831 - ||grad||^2 = 167.86443 - ||diff_w|| = 0.00431\n"," * Iteration #14 - Loss = 6035.808 - ||grad||^2 = 89.13574 - ||diff_w|| = 0.00234\n"," * Iteration #15 - Loss = 6035.814 - ||grad||^2 = 47.76750 - ||diff_w|| = 0.00127\n"," * Iteration #16 - Loss = 6035.811 - ||grad||^2 = 25.46659 - ||diff_w|| = 0.00069\n"," * Iteration #17 - Loss = 6035.814 - ||grad||^2 = 13.77944 - ||diff_w|| = 0.00038\n"," * Iteration #18 - Loss = 6035.812 - ||grad||^2 = 7.48810 - ||diff_w|| = 0.00021\n"," * Iteration #19 - Loss = 6035.813 - ||grad||^2 = 4.08311 - ||diff_w|| = 0.00011\n"," * Iteration #20 - Loss = 6035.813 - ||grad||^2 = 2.21347 - ||diff_w|| = 0.00006\n"," * Iteration #21 - Loss = 6035.813 - ||grad||^2 = 1.22458 - ||diff_w|| = 0.00003\n"," * Iteration #22 - Loss = 6035.812 - ||grad||^2 = 0.65829 - ||diff_w|| = 0.00002\n"," * Iteration #23 - Loss = 6035.813 - ||grad||^2 = 0.37033 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 6035.812 - ||grad||^2 = 0.19004 - ||diff_w|| = 0.00001\n"," * Iteration #25 - Loss = 6035.813 - ||grad||^2 = 0.11815 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 6035.812 - ||grad||^2 = 0.05922 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 6035.812 - ||grad||^2 = 0.03647 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 6035.812 - ||grad||^2 = 0.02355 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 6035.812 - ||grad||^2 = 0.01733 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 6035.812 - ||grad||^2 = 0.01308 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 6035.812 - ||grad||^2 = 0.02205 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 6035.813 - ||grad||^2 = 0.01857 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 6035.812 - ||grad||^2 = 0.02228 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 6035.813 - ||grad||^2 = 0.01968 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 6035.812 - ||grad||^2 = 0.00859 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 6035.812 - ||grad||^2 = 0.02024 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 6035.813 - ||grad||^2 = 0.02316 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 6035.812 - ||grad||^2 = 0.01805 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 6035.812 - ||grad||^2 = 0.01398 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 6035.812 - ||grad||^2 = 0.01539 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 6035.812 - ||grad||^2 = 0.01275 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 6035.812 - ||grad||^2 = 0.01114 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 6035.812 - ||grad||^2 = 0.02204 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 6035.813 - ||grad||^2 = 0.01812 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 6035.812 - ||grad||^2 = 0.02235 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 6035.813 - ||grad||^2 = 0.01957 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 6035.812 - ||grad||^2 = 0.00852 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 6035.812 - ||grad||^2 = 0.02025 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 6035.813 - ||grad||^2 = 0.02316 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 6035.812 - ||grad||^2 = 0.01804 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 6035.812 - ||grad||^2 = 0.01398 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 6035.812 - ||grad||^2 = 0.01539 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 6035.812 - ||grad||^2 = 0.01275 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 6035.812 - ||grad||^2 = 0.01114 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 6035.812 - ||grad||^2 = 0.02204 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 6035.813 - ||grad||^2 = 0.01812 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 6035.812 - ||grad||^2 = 0.02235 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 6035.813 - ||grad||^2 = 0.01957 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 6035.812 - ||grad||^2 = 0.00852 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 6035.812 - ||grad||^2 = 0.02025 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 6035.813 - ||grad||^2 = 0.02316 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 6035.812 - ||grad||^2 = 0.01804 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 6035.812 - ||grad||^2 = 0.01398 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 6035.812 - ||grad||^2 = 0.01539 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 6035.812 - ||grad||^2 = 0.01275 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 6035.812 - ||grad||^2 = 0.01114 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 6035.812 - ||grad||^2 = 0.02204 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 6035.813 - ||grad||^2 = 0.01812 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 6035.812 - ||grad||^2 = 0.02235 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 6035.813 - ||grad||^2 = 0.01957 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 6035.812 - ||grad||^2 = 0.00852 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 6035.812 - ||grad||^2 = 0.02025 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 6035.813 - ||grad||^2 = 0.02316 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 6035.812 - ||grad||^2 = 0.01804 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 6035.812 - ||grad||^2 = 0.01398 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 6035.812 - ||grad||^2 = 0.01539 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 6035.812 - ||grad||^2 = 0.01275 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 6035.812 - ||grad||^2 = 0.01114 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 6035.812 - ||grad||^2 = 0.02204 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 6035.813 - ||grad||^2 = 0.01812 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 6035.812 - ||grad||^2 = 0.02235 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 6035.813 - ||grad||^2 = 0.01957 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 6035.812 - ||grad||^2 = 0.00852 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 6035.812 - ||grad||^2 = 0.02025 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 6035.813 - ||grad||^2 = 0.02316 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 6035.812 - ||grad||^2 = 0.01804 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 6035.812 - ||grad||^2 = 0.01398 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 6035.812 - ||grad||^2 = 0.01539 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 6035.812 - ||grad||^2 = 0.01275 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 6035.812 - ||grad||^2 = 0.01114 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 6035.812 - ||grad||^2 = 0.02204 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 6035.813 - ||grad||^2 = 0.01812 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 6035.812 - ||grad||^2 = 0.02235 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 6035.813 - ||grad||^2 = 0.01957 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 6035.812 - ||grad||^2 = 0.00852 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 6035.812 - ||grad||^2 = 0.02025 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 6035.813 - ||grad||^2 = 0.02316 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 6035.812 - ||grad||^2 = 0.01804 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 6035.812 - ||grad||^2 = 0.01398 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 6035.812 - ||grad||^2 = 0.01539 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VOa9fPeYrEr1","executionInfo":{"status":"ok","timestamp":1662902064702,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"ddb21b6b-8a1e-4bd1-85d5-c907e88dffad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.833025\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"QnSTNVG-rEr1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-11616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LmibsXyPrEr1","executionInfo":{"status":"ok","timestamp":1662902064703,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"b55693ec-c9f5-48ab-dcc6-b390aa9e3751"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-11616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# orig+tgan-aug-16166"],"metadata":{"id":"L1K4ffzzsoHm"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"W4zWIrfwsoHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/Original+TGAN-aug/orig-TGANaug-16166.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"1G6B3CyDsoHo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"ew3knbnhsoHo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"XhlMC29ksoHo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"2cJUKQErsoHo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"XYu1ftu4soHo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"UZPbfhW1soHp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"89PaijKjsoHp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"NzXJPtbYsoHp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"739d6ed2-94a0-4d7c-f78f-afe8553d311b","executionInfo":{"status":"ok","timestamp":1662902529957,"user_tz":-540,"elapsed":231168,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"id":"4UfDjx4RsoHp"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 733735.962 - ||grad||^2 = 874609.03463 - ||diff_w|| = 19.05403\n"," * Iteration #2 - Loss = 192389.902 - ||grad||^2 = 463493.59858 - ||diff_w|| = 8.52304\n"," * Iteration #3 - Loss = 64031.121 - ||grad||^2 = 280672.36129 - ||diff_w|| = 4.55430\n"," * Iteration #4 - Loss = 24698.105 - ||grad||^2 = 172643.10239 - ||diff_w|| = 2.11839\n"," * Iteration #5 - Loss = 13853.343 - ||grad||^2 = 71197.35839 - ||diff_w|| = 0.72252\n"," * Iteration #6 - Loss = 12005.294 - ||grad||^2 = 21421.86008 - ||diff_w|| = 0.29737\n"," * Iteration #7 - Loss = 11835.187 - ||grad||^2 = 9165.96154 - ||diff_w|| = 0.14320\n"," * Iteration #8 - Loss = 11824.487 - ||grad||^2 = 4233.94120 - ||diff_w|| = 0.07220\n"," * Iteration #9 - Loss = 11823.003 - ||grad||^2 = 2105.14529 - ||diff_w|| = 0.03719\n"," * Iteration #10 - Loss = 11822.556 - ||grad||^2 = 1086.68866 - ||diff_w|| = 0.01959\n"," * Iteration #11 - Loss = 11822.384 - ||grad||^2 = 571.75856 - ||diff_w|| = 0.01055\n"," * Iteration #12 - Loss = 11822.325 - ||grad||^2 = 304.30146 - ||diff_w|| = 0.00573\n"," * Iteration #13 - Loss = 11822.320 - ||grad||^2 = 164.26245 - ||diff_w|| = 0.00313\n"," * Iteration #14 - Loss = 11822.322 - ||grad||^2 = 88.62675 - ||diff_w|| = 0.00171\n"," * Iteration #15 - Loss = 11822.326 - ||grad||^2 = 48.17601 - ||diff_w|| = 0.00094\n"," * Iteration #16 - Loss = 11822.328 - ||grad||^2 = 26.29173 - ||diff_w|| = 0.00051\n"," * Iteration #17 - Loss = 11822.328 - ||grad||^2 = 14.31045 - ||diff_w|| = 0.00028\n"," * Iteration #18 - Loss = 11822.328 - ||grad||^2 = 7.73485 - ||diff_w|| = 0.00015\n"," * Iteration #19 - Loss = 11822.330 - ||grad||^2 = 4.24431 - ||diff_w|| = 0.00008\n"," * Iteration #20 - Loss = 11822.329 - ||grad||^2 = 2.33633 - ||diff_w|| = 0.00005\n"," * Iteration #21 - Loss = 11822.330 - ||grad||^2 = 1.26258 - ||diff_w|| = 0.00003\n"," * Iteration #22 - Loss = 11822.329 - ||grad||^2 = 0.68200 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 11822.330 - ||grad||^2 = 0.37807 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 11822.330 - ||grad||^2 = 0.21968 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 11822.329 - ||grad||^2 = 0.10201 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 11822.330 - ||grad||^2 = 0.07106 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 11822.329 - ||grad||^2 = 0.04063 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 11822.330 - ||grad||^2 = 0.04106 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 11822.329 - ||grad||^2 = 0.02916 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 11822.330 - ||grad||^2 = 0.02639 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 11822.330 - ||grad||^2 = 0.01839 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 11822.330 - ||grad||^2 = 0.02651 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 11822.329 - ||grad||^2 = 0.03062 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 11822.330 - ||grad||^2 = 0.02456 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 11822.330 - ||grad||^2 = 0.01812 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 11822.330 - ||grad||^2 = 0.02537 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 11822.329 - ||grad||^2 = 0.03081 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 11822.330 - ||grad||^2 = 0.02443 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 11822.329 - ||grad||^2 = 0.02853 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 11822.330 - ||grad||^2 = 0.02697 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 11822.329 - ||grad||^2 = 0.02865 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 11822.330 - ||grad||^2 = 0.02579 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 11822.330 - ||grad||^2 = 0.01782 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 11822.330 - ||grad||^2 = 0.02530 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 11822.329 - ||grad||^2 = 0.03060 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 11822.330 - ||grad||^2 = 0.02455 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 11822.330 - ||grad||^2 = 0.01807 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 11822.330 - ||grad||^2 = 0.02527 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 11822.329 - ||grad||^2 = 0.03081 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 11822.330 - ||grad||^2 = 0.02443 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 11822.329 - ||grad||^2 = 0.02853 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 11822.330 - ||grad||^2 = 0.02696 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 11822.329 - ||grad||^2 = 0.02865 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 11822.330 - ||grad||^2 = 0.02579 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 11822.330 - ||grad||^2 = 0.01782 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 11822.330 - ||grad||^2 = 0.02530 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 11822.329 - ||grad||^2 = 0.03060 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 11822.330 - ||grad||^2 = 0.02455 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 11822.330 - ||grad||^2 = 0.01807 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 11822.330 - ||grad||^2 = 0.02527 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 11822.329 - ||grad||^2 = 0.03081 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 11822.330 - ||grad||^2 = 0.02443 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 11822.329 - ||grad||^2 = 0.02853 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 11822.330 - ||grad||^2 = 0.02696 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 11822.329 - ||grad||^2 = 0.02865 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 11822.330 - ||grad||^2 = 0.02579 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 11822.330 - ||grad||^2 = 0.01782 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 11822.330 - ||grad||^2 = 0.02530 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 11822.329 - ||grad||^2 = 0.03060 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 11822.330 - ||grad||^2 = 0.02455 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 11822.330 - ||grad||^2 = 0.01807 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 11822.330 - ||grad||^2 = 0.02527 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 11822.329 - ||grad||^2 = 0.03081 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 11822.330 - ||grad||^2 = 0.02443 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 11822.329 - ||grad||^2 = 0.02853 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 11822.330 - ||grad||^2 = 0.02696 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 11822.329 - ||grad||^2 = 0.02865 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 11822.330 - ||grad||^2 = 0.02579 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 11822.330 - ||grad||^2 = 0.01782 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 11822.330 - ||grad||^2 = 0.02530 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 11822.329 - ||grad||^2 = 0.03060 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 11822.330 - ||grad||^2 = 0.02455 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 11822.330 - ||grad||^2 = 0.01807 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 11822.330 - ||grad||^2 = 0.02527 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 11822.329 - ||grad||^2 = 0.03081 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 11822.330 - ||grad||^2 = 0.02443 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 11822.329 - ||grad||^2 = 0.02853 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 11822.330 - ||grad||^2 = 0.02696 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 11822.329 - ||grad||^2 = 0.02865 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 11822.330 - ||grad||^2 = 0.02579 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 11822.330 - ||grad||^2 = 0.01782 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 11822.330 - ||grad||^2 = 0.02530 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 11822.329 - ||grad||^2 = 0.03060 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 11822.330 - ||grad||^2 = 0.02455 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 11822.330 - ||grad||^2 = 0.01807 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 11822.330 - ||grad||^2 = 0.02527 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 11822.329 - ||grad||^2 = 0.03081 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 11822.330 - ||grad||^2 = 0.02443 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 11822.329 - ||grad||^2 = 0.02853 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 11822.330 - ||grad||^2 = 0.02696 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662902529957,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"e3534d7a-fb93-4b77-d9d7-f4b23c500bda","id":"4iICoWQksoHp"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.832634\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"kJkjqMF_soHq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-16166.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662902529958,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"599bcd24-6117-4e30-fe23-7b8bcc018020","id":"zhqH61VXsoHq"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-16166.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# orig+tgan-aug-21616"],"metadata":{"id":"n4QLF-0Ss1kz"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"qXfpVh_js1kz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/Original+TGAN-aug/orig-TGANaug-21616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"UQCkYZKts1kz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"u4TuUomts1kz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"6cNmxRDls1kz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"9ECRyQz3s1k0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"wCZRgYPts1k0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"PpKaE3Evs1k0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"GosgR86Qs1k0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"gEr_-5VWs1k0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"23f47569-01fe-49a4-d6a8-f2dd6452a46e","executionInfo":{"status":"ok","timestamp":1662903015910,"user_tz":-540,"elapsed":386329,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"id":"3hnDshiNs1k0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 1321147.832 - ||grad||^2 = 2397796.93459 - ||diff_w|| = 17.28983\n"," * Iteration #2 - Loss = 341179.952 - ||grad||^2 = 1225498.35268 - ||diff_w|| = 7.74826\n"," * Iteration #3 - Loss = 110377.819 - ||grad||^2 = 691004.98276 - ||diff_w|| = 4.15735\n"," * Iteration #4 - Loss = 40604.686 - ||grad||^2 = 366791.41837 - ||diff_w|| = 1.93078\n"," * Iteration #5 - Loss = 22757.238 - ||grad||^2 = 153094.52122 - ||diff_w|| = 0.62442\n"," * Iteration #6 - Loss = 20058.036 - ||grad||^2 = 69108.75158 - ||diff_w|| = 0.25452\n"," * Iteration #7 - Loss = 19774.622 - ||grad||^2 = 29532.02916 - ||diff_w|| = 0.11913\n"," * Iteration #8 - Loss = 19761.490 - ||grad||^2 = 12220.69139 - ||diff_w|| = 0.05684\n"," * Iteration #9 - Loss = 19759.280 - ||grad||^2 = 5484.26635 - ||diff_w|| = 0.02821\n"," * Iteration #10 - Loss = 19757.920 - ||grad||^2 = 2623.68521 - ||diff_w|| = 0.01473\n"," * Iteration #11 - Loss = 19757.397 - ||grad||^2 = 1312.49394 - ||diff_w|| = 0.00786\n"," * Iteration #12 - Loss = 19757.211 - ||grad||^2 = 673.05725 - ||diff_w|| = 0.00423\n"," * Iteration #13 - Loss = 19757.156 - ||grad||^2 = 353.32938 - ||diff_w|| = 0.00229\n"," * Iteration #14 - Loss = 19757.118 - ||grad||^2 = 187.47465 - ||diff_w|| = 0.00125\n"," * Iteration #15 - Loss = 19757.110 - ||grad||^2 = 100.18118 - ||diff_w|| = 0.00068\n"," * Iteration #16 - Loss = 19757.113 - ||grad||^2 = 53.69684 - ||diff_w|| = 0.00037\n"," * Iteration #17 - Loss = 19757.114 - ||grad||^2 = 29.12156 - ||diff_w|| = 0.00020\n"," * Iteration #18 - Loss = 19757.116 - ||grad||^2 = 15.73332 - ||diff_w|| = 0.00011\n"," * Iteration #19 - Loss = 19757.114 - ||grad||^2 = 8.53201 - ||diff_w|| = 0.00006\n"," * Iteration #20 - Loss = 19757.117 - ||grad||^2 = 4.65409 - ||diff_w|| = 0.00003\n"," * Iteration #21 - Loss = 19757.115 - ||grad||^2 = 2.57156 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 19757.117 - ||grad||^2 = 1.38175 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 19757.115 - ||grad||^2 = 0.73962 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 19757.116 - ||grad||^2 = 0.41991 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 19757.116 - ||grad||^2 = 0.20459 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 19757.116 - ||grad||^2 = 0.13676 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 19757.116 - ||grad||^2 = 0.06372 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 19757.116 - ||grad||^2 = 0.04513 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 19757.115 - ||grad||^2 = 0.03008 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 19757.116 - ||grad||^2 = 0.03444 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 19757.115 - ||grad||^2 = 0.02922 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 19757.117 - ||grad||^2 = 0.03645 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 19757.115 - ||grad||^2 = 0.03529 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 19757.117 - ||grad||^2 = 0.04963 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 19757.115 - ||grad||^2 = 0.04819 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 19757.117 - ||grad||^2 = 0.04179 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 19757.115 - ||grad||^2 = 0.03512 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 19757.117 - ||grad||^2 = 0.04448 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 19757.115 - ||grad||^2 = 0.03294 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 19757.117 - ||grad||^2 = 0.03829 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 19757.115 - ||grad||^2 = 0.03433 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 19757.117 - ||grad||^2 = 0.04851 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 19757.115 - ||grad||^2 = 0.04886 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 19757.117 - ||grad||^2 = 0.04177 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 19757.115 - ||grad||^2 = 0.04166 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 19757.117 - ||grad||^2 = 0.04451 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 19757.115 - ||grad||^2 = 0.03791 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 19757.117 - ||grad||^2 = 0.04712 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 19757.115 - ||grad||^2 = 0.03649 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 19757.116 - ||grad||^2 = 0.02950 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 19757.115 - ||grad||^2 = 0.02963 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 19757.116 - ||grad||^2 = 0.02297 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 19757.115 - ||grad||^2 = 0.02578 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 19757.117 - ||grad||^2 = 0.03719 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 19757.115 - ||grad||^2 = 0.03371 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 19757.117 - ||grad||^2 = 0.03788 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 19757.114 - ||grad||^2 = 0.04671 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 19757.117 - ||grad||^2 = 0.04612 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 19757.115 - ||grad||^2 = 0.03506 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 19757.116 - ||grad||^2 = 0.02655 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 19757.116 - ||grad||^2 = 0.02235 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 19757.115 - ||grad||^2 = 0.02703 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 19757.116 - ||grad||^2 = 0.03426 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 19757.115 - ||grad||^2 = 0.02926 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 19757.116 - ||grad||^2 = 0.03904 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 19757.115 - ||grad||^2 = 0.03247 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 19757.116 - ||grad||^2 = 0.02684 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 19757.116 - ||grad||^2 = 0.03053 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 19757.115 - ||grad||^2 = 0.03714 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 19757.117 - ||grad||^2 = 0.05356 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 19757.115 - ||grad||^2 = 0.03985 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 19757.117 - ||grad||^2 = 0.04157 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 19757.115 - ||grad||^2 = 0.04216 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 19757.117 - ||grad||^2 = 0.04434 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 19757.115 - ||grad||^2 = 0.03809 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 19757.117 - ||grad||^2 = 0.04714 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 19757.115 - ||grad||^2 = 0.03647 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 19757.116 - ||grad||^2 = 0.02948 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 19757.115 - ||grad||^2 = 0.02964 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 19757.116 - ||grad||^2 = 0.02297 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 19757.115 - ||grad||^2 = 0.02578 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 19757.117 - ||grad||^2 = 0.03719 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 19757.115 - ||grad||^2 = 0.03371 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 19757.117 - ||grad||^2 = 0.03788 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 19757.114 - ||grad||^2 = 0.04671 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 19757.117 - ||grad||^2 = 0.04612 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 19757.115 - ||grad||^2 = 0.03506 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 19757.116 - ||grad||^2 = 0.02655 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 19757.116 - ||grad||^2 = 0.02235 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 19757.115 - ||grad||^2 = 0.02703 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 19757.116 - ||grad||^2 = 0.03426 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 19757.115 - ||grad||^2 = 0.02926 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 19757.116 - ||grad||^2 = 0.03904 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 19757.115 - ||grad||^2 = 0.03247 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 19757.116 - ||grad||^2 = 0.02684 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 19757.116 - ||grad||^2 = 0.03053 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 19757.115 - ||grad||^2 = 0.03714 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 19757.117 - ||grad||^2 = 0.05356 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 19757.115 - ||grad||^2 = 0.03985 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 19757.117 - ||grad||^2 = 0.04157 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662903015910,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"c3b766ed-6720-403e-8749-d3d0364f1d55","id":"0N0bX59ls1k0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.832625\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"K-FwdcI-s1k0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-21616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662903015910,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"77a68f5c-4005-437a-afd5-5e1a606df229","id":"4mFI5g1ns1k0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-21616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# orig+tgan-aug-26616"],"metadata":{"id":"VOrlCCZo2YKr"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"5QqfG8i02YKs","executionInfo":{"status":"ok","timestamp":1662972198172,"user_tz":-540,"elapsed":3855,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/Original+TGAN-aug/orig-TGANaug-26616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"3616jiIS2YKs","executionInfo":{"status":"ok","timestamp":1662972198519,"user_tz":-540,"elapsed":354,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"D9uGExgR2YKt","executionInfo":{"status":"ok","timestamp":1662972198804,"user_tz":-540,"elapsed":290,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"TfZmONIk2YKt","executionInfo":{"status":"ok","timestamp":1662972198804,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"ICnCT3W82YKt","executionInfo":{"status":"ok","timestamp":1662972198804,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"YENdWnf02YKt","executionInfo":{"status":"ok","timestamp":1662972198804,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"LmTNi8tc2YKt","executionInfo":{"status":"ok","timestamp":1662972198805,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"BdFDgkX32YKt","executionInfo":{"status":"ok","timestamp":1662972198806,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"Er8g6bPc2YKu","executionInfo":{"status":"ok","timestamp":1662972198807,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"db2d903f-b492-4400-fc65-124345c62c4f","executionInfo":{"status":"ok","timestamp":1662972843425,"user_tz":-540,"elapsed":644625,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"id":"0LYbLeMH2YKu"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 3449698.175 - ||grad||^2 = 5994436.20057 - ||diff_w|| = 15.85622\n"," * Iteration #2 - Loss = 875554.650 - ||grad||^2 = 3058129.77052 - ||diff_w|| = 7.11267\n"," * Iteration #3 - Loss = 271159.067 - ||grad||^2 = 1718999.17896 - ||diff_w|| = 3.85047\n"," * Iteration #4 - Loss = 88963.886 - ||grad||^2 = 939673.61012 - ||diff_w|| = 1.96270\n"," * Iteration #5 - Loss = 40422.500 - ||grad||^2 = 485183.60818 - ||diff_w|| = 0.95902\n"," * Iteration #6 - Loss = 30280.687 - ||grad||^2 = 229258.82186 - ||diff_w|| = 0.50062\n"," * Iteration #7 - Loss = 29148.860 - ||grad||^2 = 93201.13263 - ||diff_w|| = 0.24420\n"," * Iteration #8 - Loss = 29328.064 - ||grad||^2 = 33093.35967 - ||diff_w|| = 0.10483\n"," * Iteration #9 - Loss = 29391.734 - ||grad||^2 = 11864.77023 - ||diff_w|| = 0.04680\n"," * Iteration #10 - Loss = 29402.348 - ||grad||^2 = 4890.16957 - ||diff_w|| = 0.02306\n"," * Iteration #11 - Loss = 29404.352 - ||grad||^2 = 2131.38659 - ||diff_w|| = 0.01214\n"," * Iteration #12 - Loss = 29404.798 - ||grad||^2 = 988.93873 - ||diff_w|| = 0.00654\n"," * Iteration #13 - Loss = 29404.927 - ||grad||^2 = 497.99078 - ||diff_w|| = 0.00356\n"," * Iteration #14 - Loss = 29404.915 - ||grad||^2 = 261.85731 - ||diff_w|| = 0.00194\n"," * Iteration #15 - Loss = 29404.963 - ||grad||^2 = 139.81779 - ||diff_w|| = 0.00106\n"," * Iteration #16 - Loss = 29404.957 - ||grad||^2 = 75.46566 - ||diff_w|| = 0.00058\n"," * Iteration #17 - Loss = 29404.955 - ||grad||^2 = 40.92988 - ||diff_w|| = 0.00032\n"," * Iteration #18 - Loss = 29404.956 - ||grad||^2 = 22.42153 - ||diff_w|| = 0.00017\n"," * Iteration #19 - Loss = 29404.959 - ||grad||^2 = 12.26047 - ||diff_w|| = 0.00010\n"," * Iteration #20 - Loss = 29404.956 - ||grad||^2 = 6.66523 - ||diff_w|| = 0.00005\n"," * Iteration #21 - Loss = 29404.958 - ||grad||^2 = 3.63292 - ||diff_w|| = 0.00003\n"," * Iteration #22 - Loss = 29404.957 - ||grad||^2 = 1.94002 - ||diff_w|| = 0.00002\n"," * Iteration #23 - Loss = 29404.958 - ||grad||^2 = 1.06761 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 29404.957 - ||grad||^2 = 0.59775 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 29404.958 - ||grad||^2 = 0.30813 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 29404.957 - ||grad||^2 = 0.17892 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 29404.957 - ||grad||^2 = 0.09662 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 29404.957 - ||grad||^2 = 0.06047 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 29404.957 - ||grad||^2 = 0.03499 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 29404.958 - ||grad||^2 = 0.03018 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 29404.957 - ||grad||^2 = 0.02535 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 29404.958 - ||grad||^2 = 0.02000 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 29404.957 - ||grad||^2 = 0.02800 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 29404.957 - ||grad||^2 = 0.01794 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 29404.957 - ||grad||^2 = 0.02199 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 29404.957 - ||grad||^2 = 0.01902 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 29404.958 - ||grad||^2 = 0.01630 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 29404.957 - ||grad||^2 = 0.01409 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 29404.957 - ||grad||^2 = 0.02387 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 29404.957 - ||grad||^2 = 0.03960 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 29404.957 - ||grad||^2 = 0.02308 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 29404.957 - ||grad||^2 = 0.01269 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 29404.957 - ||grad||^2 = 0.02503 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 29404.957 - ||grad||^2 = 0.01759 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 29404.957 - ||grad||^2 = 0.02258 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 29404.957 - ||grad||^2 = 0.01870 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 29404.957 - ||grad||^2 = 0.02160 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 29404.957 - ||grad||^2 = 0.02942 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 29404.958 - ||grad||^2 = 0.01795 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 29404.957 - ||grad||^2 = 0.01158 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 29404.957 - ||grad||^2 = 0.01392 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 29404.958 - ||grad||^2 = 0.03026 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 29404.957 - ||grad||^2 = 0.03378 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 29404.958 - ||grad||^2 = 0.03042 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 29404.957 - ||grad||^2 = 0.02297 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 29404.957 - ||grad||^2 = 0.01000 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 29404.958 - ||grad||^2 = 0.01529 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 29404.957 - ||grad||^2 = 0.01616 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 29404.957 - ||grad||^2 = 0.03641 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 29404.958 - ||grad||^2 = 0.02900 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 29404.957 - ||grad||^2 = 0.02261 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 29404.958 - ||grad||^2 = 0.02183 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 29404.957 - ||grad||^2 = 0.02226 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 29404.958 - ||grad||^2 = 0.01798 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 29404.957 - ||grad||^2 = 0.01860 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 29404.958 - ||grad||^2 = 0.02380 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 29404.957 - ||grad||^2 = 0.02606 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 29404.957 - ||grad||^2 = 0.01517 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 29404.957 - ||grad||^2 = 0.02489 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 29404.958 - ||grad||^2 = 0.03320 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 29404.957 - ||grad||^2 = 0.02646 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 29404.958 - ||grad||^2 = 0.01712 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 29404.957 - ||grad||^2 = 0.01475 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 29404.957 - ||grad||^2 = 0.01388 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 29404.957 - ||grad||^2 = 0.03634 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 29404.958 - ||grad||^2 = 0.02932 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 29404.957 - ||grad||^2 = 0.02218 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 29404.958 - ||grad||^2 = 0.02212 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 29404.957 - ||grad||^2 = 0.02217 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 29404.958 - ||grad||^2 = 0.01803 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 29404.957 - ||grad||^2 = 0.01857 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 29404.958 - ||grad||^2 = 0.02381 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 29404.957 - ||grad||^2 = 0.02606 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 29404.957 - ||grad||^2 = 0.01517 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 29404.957 - ||grad||^2 = 0.02489 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 29404.958 - ||grad||^2 = 0.03320 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 29404.957 - ||grad||^2 = 0.02646 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 29404.958 - ||grad||^2 = 0.01712 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 29404.957 - ||grad||^2 = 0.01475 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 29404.957 - ||grad||^2 = 0.01388 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 29404.957 - ||grad||^2 = 0.03634 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 29404.958 - ||grad||^2 = 0.02932 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 29404.957 - ||grad||^2 = 0.02218 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 29404.958 - ||grad||^2 = 0.02212 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 29404.957 - ||grad||^2 = 0.02217 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 29404.958 - ||grad||^2 = 0.01803 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 29404.957 - ||grad||^2 = 0.01857 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 29404.958 - ||grad||^2 = 0.02381 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 29404.957 - ||grad||^2 = 0.02606 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 29404.957 - ||grad||^2 = 0.01517 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662972843425,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"c2cb8247-19e9-4a7d-e580-23c332c9f3c1","id":"O8vHOGp62YKu"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.831772\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"vSzmFJwu2YKu","executionInfo":{"status":"ok","timestamp":1662972843426,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-26616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662972843426,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"1328594a-4917-4102-8158-031611e89173","id":"3thvvp7Z2YKu"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-26616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# orig+tgan-aug-31616"],"metadata":{"id":"Hl4d2tOY2fkL"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"FJbIG20B2fkM","executionInfo":{"status":"ok","timestamp":1662974242770,"user_tz":-540,"elapsed":1768,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/Original+TGAN-aug/orig-TGANaug-31616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"Yno2i46j2fkM","executionInfo":{"status":"ok","timestamp":1662974243212,"user_tz":-540,"elapsed":462,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"aCNRFy_f2fkM","executionInfo":{"status":"ok","timestamp":1662974243212,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"dpDWg3_U2fkM","executionInfo":{"status":"ok","timestamp":1662974243212,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"XOaHw1PC2fkM","executionInfo":{"status":"ok","timestamp":1662974243213,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"B6qXH6GF2fkM","executionInfo":{"status":"ok","timestamp":1662974243213,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"IqMOyvDa2fkM","executionInfo":{"status":"ok","timestamp":1662974243213,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"f4cT3HZ52fkN","executionInfo":{"status":"ok","timestamp":1662974243213,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"YFhKvDJN2fkN","executionInfo":{"status":"ok","timestamp":1662974243562,"user_tz":-540,"elapsed":353,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8567cbc7-ff77-4333-b164-aa5656bb00bb","executionInfo":{"status":"ok","timestamp":1662975130853,"user_tz":-540,"elapsed":887293,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"id":"EECa0BW12fkN"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 5595516.228 - ||grad||^2 = 7219684.39350 - ||diff_w|| = 18.36435\n"," * Iteration #2 - Loss = 1440413.458 - ||grad||^2 = 3720661.68984 - ||diff_w|| = 8.24042\n"," * Iteration #3 - Loss = 460004.013 - ||grad||^2 = 2159669.90794 - ||diff_w|| = 4.47607\n"," * Iteration #4 - Loss = 156523.985 - ||grad||^2 = 1278670.33249 - ||diff_w|| = 2.30719\n"," * Iteration #5 - Loss = 64433.127 - ||grad||^2 = 647903.02848 - ||diff_w|| = 0.94541\n"," * Iteration #6 - Loss = 43025.751 - ||grad||^2 = 211343.79531 - ||diff_w|| = 0.30925\n"," * Iteration #7 - Loss = 40613.676 - ||grad||^2 = 82586.48331 - ||diff_w|| = 0.12323\n"," * Iteration #8 - Loss = 40611.470 - ||grad||^2 = 30498.16986 - ||diff_w|| = 0.05230\n"," * Iteration #9 - Loss = 40642.020 - ||grad||^2 = 11562.41282 - ||diff_w|| = 0.02316\n"," * Iteration #10 - Loss = 40650.803 - ||grad||^2 = 4847.20146 - ||diff_w|| = 0.01137\n"," * Iteration #11 - Loss = 40653.434 - ||grad||^2 = 2176.07860 - ||diff_w|| = 0.00576\n"," * Iteration #12 - Loss = 40654.182 - ||grad||^2 = 1035.63556 - ||diff_w|| = 0.00297\n"," * Iteration #13 - Loss = 40654.372 - ||grad||^2 = 514.96250 - ||diff_w|| = 0.00157\n"," * Iteration #14 - Loss = 40654.491 - ||grad||^2 = 264.00537 - ||diff_w|| = 0.00084\n"," * Iteration #15 - Loss = 40654.524 - ||grad||^2 = 136.88898 - ||diff_w|| = 0.00045\n"," * Iteration #16 - Loss = 40654.545 - ||grad||^2 = 72.23024 - ||diff_w|| = 0.00024\n"," * Iteration #17 - Loss = 40654.548 - ||grad||^2 = 38.40869 - ||diff_w|| = 0.00013\n"," * Iteration #18 - Loss = 40654.550 - ||grad||^2 = 20.36752 - ||diff_w|| = 0.00007\n"," * Iteration #19 - Loss = 40654.553 - ||grad||^2 = 10.92311 - ||diff_w|| = 0.00004\n"," * Iteration #20 - Loss = 40654.555 - ||grad||^2 = 5.91580 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 40654.552 - ||grad||^2 = 3.19515 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 40654.553 - ||grad||^2 = 1.74189 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 40654.552 - ||grad||^2 = 0.93260 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 40654.553 - ||grad||^2 = 0.50913 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 40654.552 - ||grad||^2 = 0.28049 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 40654.554 - ||grad||^2 = 0.16249 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 40654.552 - ||grad||^2 = 0.09327 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 40654.554 - ||grad||^2 = 0.07060 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 40654.552 - ||grad||^2 = 0.04708 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 40654.554 - ||grad||^2 = 0.04703 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 40654.552 - ||grad||^2 = 0.05222 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 40654.554 - ||grad||^2 = 0.04817 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 40654.552 - ||grad||^2 = 0.04577 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 40654.554 - ||grad||^2 = 0.04115 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 40654.552 - ||grad||^2 = 0.04772 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 40654.554 - ||grad||^2 = 0.04304 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 40654.552 - ||grad||^2 = 0.03890 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 40654.554 - ||grad||^2 = 0.04661 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 40654.552 - ||grad||^2 = 0.05108 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 40654.554 - ||grad||^2 = 0.05447 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 40654.552 - ||grad||^2 = 0.05651 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 40654.554 - ||grad||^2 = 0.04817 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 40654.552 - ||grad||^2 = 0.04575 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 40654.554 - ||grad||^2 = 0.04075 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 40654.552 - ||grad||^2 = 0.04812 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 40654.554 - ||grad||^2 = 0.04287 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 40654.552 - ||grad||^2 = 0.03886 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 40654.554 - ||grad||^2 = 0.04661 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 40654.552 - ||grad||^2 = 0.05109 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 40654.554 - ||grad||^2 = 0.05446 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 40654.552 - ||grad||^2 = 0.05650 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 40654.554 - ||grad||^2 = 0.04817 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 40654.552 - ||grad||^2 = 0.04575 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 40654.554 - ||grad||^2 = 0.04075 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 40654.552 - ||grad||^2 = 0.04812 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 40654.554 - ||grad||^2 = 0.04286 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 40654.552 - ||grad||^2 = 0.03886 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 40654.554 - ||grad||^2 = 0.04661 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 40654.552 - ||grad||^2 = 0.05109 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 40654.554 - ||grad||^2 = 0.05446 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 40654.552 - ||grad||^2 = 0.05650 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 40654.554 - ||grad||^2 = 0.04817 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 40654.552 - ||grad||^2 = 0.04575 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 40654.554 - ||grad||^2 = 0.04075 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 40654.552 - ||grad||^2 = 0.04812 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 40654.554 - ||grad||^2 = 0.04286 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 40654.552 - ||grad||^2 = 0.03886 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 40654.554 - ||grad||^2 = 0.04661 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 40654.552 - ||grad||^2 = 0.05109 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 40654.554 - ||grad||^2 = 0.05446 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 40654.552 - ||grad||^2 = 0.05650 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 40654.554 - ||grad||^2 = 0.04817 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 40654.552 - ||grad||^2 = 0.04575 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 40654.554 - ||grad||^2 = 0.04075 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 40654.552 - ||grad||^2 = 0.04812 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 40654.554 - ||grad||^2 = 0.04286 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 40654.552 - ||grad||^2 = 0.03886 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 40654.554 - ||grad||^2 = 0.04661 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 40654.552 - ||grad||^2 = 0.05109 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 40654.554 - ||grad||^2 = 0.05446 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 40654.552 - ||grad||^2 = 0.05650 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 40654.554 - ||grad||^2 = 0.04817 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 40654.552 - ||grad||^2 = 0.04575 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 40654.554 - ||grad||^2 = 0.04075 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 40654.552 - ||grad||^2 = 0.04812 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 40654.554 - ||grad||^2 = 0.04286 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 40654.552 - ||grad||^2 = 0.03886 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 40654.554 - ||grad||^2 = 0.04661 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 40654.552 - ||grad||^2 = 0.05109 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 40654.554 - ||grad||^2 = 0.05446 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 40654.552 - ||grad||^2 = 0.05650 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 40654.554 - ||grad||^2 = 0.04817 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 40654.552 - ||grad||^2 = 0.04575 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 40654.554 - ||grad||^2 = 0.04075 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 40654.552 - ||grad||^2 = 0.04812 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 40654.554 - ||grad||^2 = 0.04286 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 40654.552 - ||grad||^2 = 0.03886 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 40654.554 - ||grad||^2 = 0.04661 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 40654.552 - ||grad||^2 = 0.05109 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 40654.554 - ||grad||^2 = 0.05446 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662975130854,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"afa45cd2-e36e-4162-b166-6c8503c00d01","id":"TPCqgHU-2fkN"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.832190\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"d7v5mM502fkN","executionInfo":{"status":"ok","timestamp":1662975130854,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-31616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662975130854,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"6620a24a-09a4-4857-b1db-8d762f93bf19","id":"IEGCATVv2fkN"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-31616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# orig+tgan-aug-36616"],"metadata":{"id":"ruZmQh402l2y"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"tImLUue42l2z","executionInfo":{"status":"ok","timestamp":1662975724887,"user_tz":-540,"elapsed":1482,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/Original+TGAN-aug/orig-TGANaug-36616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"PKYlhkvg2l2z","executionInfo":{"status":"ok","timestamp":1662975725269,"user_tz":-540,"elapsed":388,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"ztd2vic92l20","executionInfo":{"status":"ok","timestamp":1662975725269,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"MdMJsa9n2l20","executionInfo":{"status":"ok","timestamp":1662975725269,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"W9ApP_WV2l20","executionInfo":{"status":"ok","timestamp":1662975725270,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"r9LXVuYi2l20","executionInfo":{"status":"ok","timestamp":1662975725270,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"9hY7-T8e2l21","executionInfo":{"status":"ok","timestamp":1662975725270,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"NDmdty9S2l21","executionInfo":{"status":"ok","timestamp":1662975725270,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"EOHmHYuh2l21","executionInfo":{"status":"ok","timestamp":1662975725271,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b1ea0c03-dbb9-4ee4-d41f-cc0e8eb86c47","executionInfo":{"status":"ok","timestamp":1662976926562,"user_tz":-540,"elapsed":1201295,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"id":"F8YHgvl72l21"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 5282882.784 - ||grad||^2 = 9505055.43098 - ||diff_w|| = 14.39728\n"," * Iteration #2 - Loss = 1341747.562 - ||grad||^2 = 4842934.19695 - ||diff_w|| = 6.45116\n"," * Iteration #3 - Loss = 417612.809 - ||grad||^2 = 2718853.35357 - ||diff_w|| = 3.46729\n"," * Iteration #4 - Loss = 140015.033 - ||grad||^2 = 1451349.42903 - ||diff_w|| = 1.66951\n"," * Iteration #5 - Loss = 69186.511 - ||grad||^2 = 686537.43885 - ||diff_w|| = 0.69851\n"," * Iteration #6 - Loss = 56598.129 - ||grad||^2 = 323069.28156 - ||diff_w|| = 0.32725\n"," * Iteration #7 - Loss = 55068.947 - ||grad||^2 = 134903.55994 - ||diff_w|| = 0.14049\n"," * Iteration #8 - Loss = 55129.120 - ||grad||^2 = 51872.82999 - ||diff_w|| = 0.05540\n"," * Iteration #9 - Loss = 55179.657 - ||grad||^2 = 20740.92624 - ||diff_w|| = 0.02422\n"," * Iteration #10 - Loss = 55187.177 - ||grad||^2 = 8752.62313 - ||diff_w|| = 0.01147\n"," * Iteration #11 - Loss = 55188.807 - ||grad||^2 = 3918.49295 - ||diff_w|| = 0.00565\n"," * Iteration #12 - Loss = 55189.058 - ||grad||^2 = 1811.69884 - ||diff_w|| = 0.00287\n"," * Iteration #13 - Loss = 55189.186 - ||grad||^2 = 883.76312 - ||diff_w|| = 0.00151\n"," * Iteration #14 - Loss = 55189.241 - ||grad||^2 = 443.15406 - ||diff_w|| = 0.00080\n"," * Iteration #15 - Loss = 55189.254 - ||grad||^2 = 224.99904 - ||diff_w|| = 0.00043\n"," * Iteration #16 - Loss = 55189.286 - ||grad||^2 = 116.20422 - ||diff_w|| = 0.00023\n"," * Iteration #17 - Loss = 55189.291 - ||grad||^2 = 61.15386 - ||diff_w|| = 0.00012\n"," * Iteration #18 - Loss = 55189.286 - ||grad||^2 = 32.16380 - ||diff_w|| = 0.00007\n"," * Iteration #19 - Loss = 55189.295 - ||grad||^2 = 17.13326 - ||diff_w|| = 0.00004\n"," * Iteration #20 - Loss = 55189.294 - ||grad||^2 = 9.20720 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 55189.295 - ||grad||^2 = 5.02892 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 55189.294 - ||grad||^2 = 2.70712 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 55189.295 - ||grad||^2 = 1.49174 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 55189.293 - ||grad||^2 = 0.78855 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 55189.295 - ||grad||^2 = 0.43945 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 55189.294 - ||grad||^2 = 0.23577 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 55189.294 - ||grad||^2 = 0.13489 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 55189.294 - ||grad||^2 = 0.08698 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 55189.294 - ||grad||^2 = 0.05524 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 55189.294 - ||grad||^2 = 0.04090 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 55189.294 - ||grad||^2 = 0.02943 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 55189.293 - ||grad||^2 = 0.05070 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 55189.296 - ||grad||^2 = 0.10454 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 55189.292 - ||grad||^2 = 0.10691 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 55189.296 - ||grad||^2 = 0.09804 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 55189.293 - ||grad||^2 = 0.09798 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 55189.296 - ||grad||^2 = 0.12130 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 55189.292 - ||grad||^2 = 0.12239 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 55189.295 - ||grad||^2 = 0.10260 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 55189.293 - ||grad||^2 = 0.08303 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 55189.295 - ||grad||^2 = 0.07944 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 55189.293 - ||grad||^2 = 0.09366 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 55189.296 - ||grad||^2 = 0.10656 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 55189.292 - ||grad||^2 = 0.10953 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 55189.296 - ||grad||^2 = 0.13042 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 55189.292 - ||grad||^2 = 0.11971 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 55189.295 - ||grad||^2 = 0.07329 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 55189.293 - ||grad||^2 = 0.06190 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 55189.295 - ||grad||^2 = 0.07604 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 55189.293 - ||grad||^2 = 0.06053 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 55189.294 - ||grad||^2 = 0.04880 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 55189.293 - ||grad||^2 = 0.06097 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 55189.295 - ||grad||^2 = 0.07388 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 55189.293 - ||grad||^2 = 0.09376 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 55189.296 - ||grad||^2 = 0.12252 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 55189.292 - ||grad||^2 = 0.11446 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 55189.295 - ||grad||^2 = 0.08484 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 55189.293 - ||grad||^2 = 0.07189 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 55189.295 - ||grad||^2 = 0.06233 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 55189.293 - ||grad||^2 = 0.05410 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 55189.294 - ||grad||^2 = 0.04483 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 55189.293 - ||grad||^2 = 0.04543 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 55189.295 - ||grad||^2 = 0.04899 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 55189.294 - ||grad||^2 = 0.04874 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 55189.295 - ||grad||^2 = 0.06867 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 55189.293 - ||grad||^2 = 0.08741 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 55189.296 - ||grad||^2 = 0.10861 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 55189.292 - ||grad||^2 = 0.09779 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 55189.296 - ||grad||^2 = 0.10519 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 55189.292 - ||grad||^2 = 0.11122 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 55189.296 - ||grad||^2 = 0.10954 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 55189.293 - ||grad||^2 = 0.11238 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 55189.296 - ||grad||^2 = 0.12391 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 55189.292 - ||grad||^2 = 0.11481 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 55189.296 - ||grad||^2 = 0.10481 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 55189.292 - ||grad||^2 = 0.11049 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 55189.296 - ||grad||^2 = 0.11827 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 55189.292 - ||grad||^2 = 0.11463 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 55189.296 - ||grad||^2 = 0.11021 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 55189.292 - ||grad||^2 = 0.11232 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 55189.296 - ||grad||^2 = 0.10601 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 55189.292 - ||grad||^2 = 0.10933 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 55189.296 - ||grad||^2 = 0.10044 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 55189.293 - ||grad||^2 = 0.07225 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 55189.295 - ||grad||^2 = 0.03865 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 55189.293 - ||grad||^2 = 0.05735 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 55189.296 - ||grad||^2 = 0.09081 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 55189.292 - ||grad||^2 = 0.11601 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 55189.296 - ||grad||^2 = 0.11951 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 55189.292 - ||grad||^2 = 0.11042 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 55189.296 - ||grad||^2 = 0.11154 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 55189.293 - ||grad||^2 = 0.08084 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 55189.295 - ||grad||^2 = 0.04868 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 55189.293 - ||grad||^2 = 0.05596 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 55189.295 - ||grad||^2 = 0.07990 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 55189.293 - ||grad||^2 = 0.09397 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 55189.296 - ||grad||^2 = 0.10409 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 55189.292 - ||grad||^2 = 0.10825 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 55189.296 - ||grad||^2 = 0.11877 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 55189.292 - ||grad||^2 = 0.11438 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662976926563,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"b8767237-d15e-479a-b81e-04cffa9e6804","id":"yt7-AIo_2l21"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.832821\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"_FuUQTNP2l22","executionInfo":{"status":"ok","timestamp":1662976926563,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-36616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662976926563,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"abcc8f95-173d-4a3a-900d-d6a6dd87109e","id":"sPuqYOcp2l22"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-36616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# orig+tgan-aug-41616"],"metadata":{"id":"eVigFDH72t95"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"W60aoT8K2t95","executionInfo":{"status":"ok","timestamp":1662977439667,"user_tz":-540,"elapsed":932,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/Original+TGAN-aug/orig-TGANaug-41616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"DfYkonuc2t96","executionInfo":{"status":"ok","timestamp":1662977440267,"user_tz":-540,"elapsed":605,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"UdTTEBCR2t96","executionInfo":{"status":"ok","timestamp":1662977440267,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"57FR2wfC2t96","executionInfo":{"status":"ok","timestamp":1662977440268,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"RPXsie3b2t96","executionInfo":{"status":"ok","timestamp":1662977440268,"user_tz":-540,"elapsed":10,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"mevmDzGr2t96","executionInfo":{"status":"ok","timestamp":1662977440268,"user_tz":-540,"elapsed":7,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"qj4yBDzI2t96","executionInfo":{"status":"ok","timestamp":1662977440268,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"VVCI3XQI2t97","executionInfo":{"status":"ok","timestamp":1662977440268,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"m_RBgAK02t97","executionInfo":{"status":"ok","timestamp":1662977440268,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7b76ee8a-7e44-40dc-c5d7-effd2a64c644","executionInfo":{"status":"ok","timestamp":1662978990201,"user_tz":-540,"elapsed":1549937,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"id":"mENo3TnV2t97"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 8405249.369 - ||grad||^2 = 16152578.61603 - ||diff_w|| = 14.62285\n"," * Iteration #2 - Loss = 2142794.589 - ||grad||^2 = 8207031.45745 - ||diff_w|| = 6.55328\n"," * Iteration #3 - Loss = 671152.154 - ||grad||^2 = 4598609.01085 - ||diff_w|| = 3.54283\n"," * Iteration #4 - Loss = 223331.250 - ||grad||^2 = 2512358.55358 - ||diff_w|| = 1.78431\n"," * Iteration #5 - Loss = 99369.693 - ||grad||^2 = 1280801.36078 - ||diff_w|| = 0.77960\n"," * Iteration #6 - Loss = 74709.966 - ||grad||^2 = 597434.91661 - ||diff_w|| = 0.38560\n"," * Iteration #7 - Loss = 72624.406 - ||grad||^2 = 208236.46323 - ||diff_w|| = 0.18087\n"," * Iteration #8 - Loss = 73045.267 - ||grad||^2 = 62479.84276 - ||diff_w|| = 0.07508\n"," * Iteration #9 - Loss = 73168.923 - ||grad||^2 = 20615.38668 - ||diff_w|| = 0.03130\n"," * Iteration #10 - Loss = 73193.930 - ||grad||^2 = 8272.44652 - ||diff_w|| = 0.01426\n"," * Iteration #11 - Loss = 73199.811 - ||grad||^2 = 3577.25790 - ||diff_w|| = 0.00733\n"," * Iteration #12 - Loss = 73201.196 - ||grad||^2 = 1626.85356 - ||diff_w|| = 0.00395\n"," * Iteration #13 - Loss = 73201.694 - ||grad||^2 = 766.19134 - ||diff_w|| = 0.00216\n"," * Iteration #14 - Loss = 73201.829 - ||grad||^2 = 379.24084 - ||diff_w|| = 0.00118\n"," * Iteration #15 - Loss = 73201.883 - ||grad||^2 = 193.11829 - ||diff_w|| = 0.00065\n"," * Iteration #16 - Loss = 73201.908 - ||grad||^2 = 100.12238 - ||diff_w|| = 0.00036\n"," * Iteration #17 - Loss = 73201.908 - ||grad||^2 = 52.54882 - ||diff_w|| = 0.00020\n"," * Iteration #18 - Loss = 73201.906 - ||grad||^2 = 27.97211 - ||diff_w|| = 0.00011\n"," * Iteration #19 - Loss = 73201.909 - ||grad||^2 = 14.95618 - ||diff_w|| = 0.00006\n"," * Iteration #20 - Loss = 73201.906 - ||grad||^2 = 8.04726 - ||diff_w|| = 0.00003\n"," * Iteration #21 - Loss = 73201.907 - ||grad||^2 = 4.31878 - ||diff_w|| = 0.00002\n"," * Iteration #22 - Loss = 73201.907 - ||grad||^2 = 2.34090 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 73201.906 - ||grad||^2 = 1.27236 - ||diff_w|| = 0.00001\n"," * Iteration #24 - Loss = 73201.908 - ||grad||^2 = 0.67855 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 73201.906 - ||grad||^2 = 0.38803 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 73201.908 - ||grad||^2 = 0.18507 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 73201.905 - ||grad||^2 = 0.16128 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 73201.909 - ||grad||^2 = 0.09667 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 73201.904 - ||grad||^2 = 0.12193 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 73201.909 - ||grad||^2 = 0.10597 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 73201.905 - ||grad||^2 = 0.10038 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 73201.909 - ||grad||^2 = 0.08005 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 73201.905 - ||grad||^2 = 0.07802 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 73201.908 - ||grad||^2 = 0.06847 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 73201.905 - ||grad||^2 = 0.07260 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 73201.909 - ||grad||^2 = 0.08970 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 73201.905 - ||grad||^2 = 0.09384 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 73201.909 - ||grad||^2 = 0.09385 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 73201.905 - ||grad||^2 = 0.08389 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 73201.909 - ||grad||^2 = 0.09893 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 73201.904 - ||grad||^2 = 0.11320 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 73201.909 - ||grad||^2 = 0.10246 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 73201.905 - ||grad||^2 = 0.08654 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 73201.909 - ||grad||^2 = 0.07743 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 73201.905 - ||grad||^2 = 0.08674 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 73201.909 - ||grad||^2 = 0.08894 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 73201.905 - ||grad||^2 = 0.08951 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 73201.909 - ||grad||^2 = 0.09555 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 73201.904 - ||grad||^2 = 0.10476 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 73201.910 - ||grad||^2 = 0.12662 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 73201.905 - ||grad||^2 = 0.10949 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 73201.908 - ||grad||^2 = 0.07849 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 73201.905 - ||grad||^2 = 0.07956 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 73201.909 - ||grad||^2 = 0.07871 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 73201.905 - ||grad||^2 = 0.10183 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 73201.909 - ||grad||^2 = 0.11506 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 73201.904 - ||grad||^2 = 0.10516 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 73201.909 - ||grad||^2 = 0.10120 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 73201.905 - ||grad||^2 = 0.09485 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 73201.909 - ||grad||^2 = 0.11382 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 73201.904 - ||grad||^2 = 0.12033 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 73201.909 - ||grad||^2 = 0.09799 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 73201.905 - ||grad||^2 = 0.08491 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 73201.908 - ||grad||^2 = 0.06528 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 73201.905 - ||grad||^2 = 0.08530 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 73201.909 - ||grad||^2 = 0.10401 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 73201.904 - ||grad||^2 = 0.10103 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 73201.909 - ||grad||^2 = 0.09417 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 73201.905 - ||grad||^2 = 0.08470 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 73201.909 - ||grad||^2 = 0.10406 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 73201.904 - ||grad||^2 = 0.12866 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 73201.909 - ||grad||^2 = 0.11674 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 73201.905 - ||grad||^2 = 0.10147 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 73201.909 - ||grad||^2 = 0.10841 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 73201.904 - ||grad||^2 = 0.11608 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 73201.909 - ||grad||^2 = 0.11822 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 73201.904 - ||grad||^2 = 0.11609 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 73201.909 - ||grad||^2 = 0.09389 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 73201.905 - ||grad||^2 = 0.08641 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 73201.909 - ||grad||^2 = 0.08919 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 73201.905 - ||grad||^2 = 0.08970 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 73201.909 - ||grad||^2 = 0.08672 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 73201.905 - ||grad||^2 = 0.07945 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 73201.909 - ||grad||^2 = 0.09050 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 73201.904 - ||grad||^2 = 0.11291 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 73201.909 - ||grad||^2 = 0.11440 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 73201.905 - ||grad||^2 = 0.10074 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 73201.909 - ||grad||^2 = 0.08844 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 73201.905 - ||grad||^2 = 0.08473 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 73201.909 - ||grad||^2 = 0.09879 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 73201.904 - ||grad||^2 = 0.11311 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 73201.909 - ||grad||^2 = 0.11272 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 73201.905 - ||grad||^2 = 0.09142 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 73201.908 - ||grad||^2 = 0.07501 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 73201.905 - ||grad||^2 = 0.08906 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 73201.909 - ||grad||^2 = 0.09965 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 73201.904 - ||grad||^2 = 0.11194 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 73201.909 - ||grad||^2 = 0.11566 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 73201.904 - ||grad||^2 = 0.11686 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 73201.909 - ||grad||^2 = 0.10365 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662978990202,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"d2eb5380-6142-424a-9387-eb206bc12e84","id":"OGyLnPFB2t97"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.831746\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"BNQi6atd2t97","executionInfo":{"status":"ok","timestamp":1662978990202,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-41616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662978990202,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"44502dfa-2468-4f9e-d315-525d10837378","id":"W_s1cfoO2t98"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-41616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# orig+tgan-aug-46616"],"metadata":{"id":"wt_w7vSb23m0"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"TknsBq0b23m2","executionInfo":{"status":"ok","timestamp":1662979529879,"user_tz":-540,"elapsed":1251,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/Original+TGAN-aug/orig-TGANaug-46616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"mTvemtsE23m2","executionInfo":{"status":"ok","timestamp":1662979529879,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"rh7qDUQq23m2","executionInfo":{"status":"ok","timestamp":1662979530319,"user_tz":-540,"elapsed":443,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"mP4AcxcA23m2","executionInfo":{"status":"ok","timestamp":1662979530319,"user_tz":-540,"elapsed":15,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"zqB29L_u23m3","executionInfo":{"status":"ok","timestamp":1662979530319,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"1uoF2SIL23m3","executionInfo":{"status":"ok","timestamp":1662979530319,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"ADky-79s23m3","executionInfo":{"status":"ok","timestamp":1662979530320,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"GDfDEYBX23m3","executionInfo":{"status":"ok","timestamp":1662979530320,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"6PP5aVcJ23m3","executionInfo":{"status":"ok","timestamp":1662979530320,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fd88e213-546f-404f-d76c-c5e91ffe3f8e","executionInfo":{"status":"ok","timestamp":1662981600949,"user_tz":-540,"elapsed":2070634,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"id":"oh7CynZl23m4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 9402512.367 - ||grad||^2 = 23424228.11724 - ||diff_w|| = 10.63407\n"," * Iteration #2 - Loss = 2395303.016 - ||grad||^2 = 11969087.70567 - ||diff_w|| = 4.74872\n"," * Iteration #3 - Loss = 746906.862 - ||grad||^2 = 6734278.89914 - ||diff_w|| = 2.52633\n"," * Iteration #4 - Loss = 250006.195 - ||grad||^2 = 3666822.40956 - ||diff_w|| = 1.20144\n"," * Iteration #5 - Loss = 117680.747 - ||grad||^2 = 1921456.43595 - ||diff_w|| = 0.53960\n"," * Iteration #6 - Loss = 89054.932 - ||grad||^2 = 900482.66008 - ||diff_w|| = 0.28914\n"," * Iteration #7 - Loss = 88464.422 - ||grad||^2 = 265603.81430 - ||diff_w|| = 0.14691\n"," * Iteration #8 - Loss = 89575.190 - ||grad||^2 = 67351.91870 - ||diff_w|| = 0.05761\n"," * Iteration #9 - Loss = 89623.634 - ||grad||^2 = 22742.59830 - ||diff_w|| = 0.02243\n"," * Iteration #10 - Loss = 89626.860 - ||grad||^2 = 8637.61283 - ||diff_w|| = 0.00900\n"," * Iteration #11 - Loss = 89627.748 - ||grad||^2 = 3470.47562 - ||diff_w|| = 0.00378\n"," * Iteration #12 - Loss = 89628.298 - ||grad||^2 = 1469.32259 - ||diff_w|| = 0.00170\n"," * Iteration #13 - Loss = 89628.574 - ||grad||^2 = 661.13382 - ||diff_w|| = 0.00081\n"," * Iteration #14 - Loss = 89628.654 - ||grad||^2 = 313.30875 - ||diff_w|| = 0.00041\n"," * Iteration #15 - Loss = 89628.696 - ||grad||^2 = 153.01536 - ||diff_w|| = 0.00021\n"," * Iteration #16 - Loss = 89628.708 - ||grad||^2 = 75.61954 - ||diff_w|| = 0.00011\n"," * Iteration #17 - Loss = 89628.718 - ||grad||^2 = 38.47751 - ||diff_w|| = 0.00006\n"," * Iteration #18 - Loss = 89628.720 - ||grad||^2 = 19.76260 - ||diff_w|| = 0.00003\n"," * Iteration #19 - Loss = 89628.716 - ||grad||^2 = 10.27880 - ||diff_w|| = 0.00002\n"," * Iteration #20 - Loss = 89628.718 - ||grad||^2 = 5.32059 - ||diff_w|| = 0.00001\n"," * Iteration #21 - Loss = 89628.715 - ||grad||^2 = 2.84253 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 89628.717 - ||grad||^2 = 1.46669 - ||diff_w|| = 0.00000\n"," * Iteration #23 - Loss = 89628.716 - ||grad||^2 = 0.79774 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 89628.717 - ||grad||^2 = 0.42537 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 89628.716 - ||grad||^2 = 0.24634 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 89628.717 - ||grad||^2 = 0.13148 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 89628.716 - ||grad||^2 = 0.07564 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 89628.716 - ||grad||^2 = 0.05009 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 89628.717 - ||grad||^2 = 0.05581 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 89628.716 - ||grad||^2 = 0.04346 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 89628.716 - ||grad||^2 = 0.06249 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 89628.717 - ||grad||^2 = 0.07782 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 89628.717 - ||grad||^2 = 0.05568 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 89628.716 - ||grad||^2 = 0.03269 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 89628.716 - ||grad||^2 = 0.03135 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 89628.716 - ||grad||^2 = 0.02708 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 89628.717 - ||grad||^2 = 0.02831 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 89628.716 - ||grad||^2 = 0.02772 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 89628.717 - ||grad||^2 = 0.02404 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 89628.716 - ||grad||^2 = 0.02128 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 89628.717 - ||grad||^2 = 0.03299 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 89628.716 - ||grad||^2 = 0.04016 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 89628.717 - ||grad||^2 = 0.04869 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 89628.716 - ||grad||^2 = 0.05192 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 89628.716 - ||grad||^2 = 0.03724 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 89628.717 - ||grad||^2 = 0.04601 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 89628.716 - ||grad||^2 = 0.04696 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 89628.717 - ||grad||^2 = 0.05206 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 89628.716 - ||grad||^2 = 0.07118 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 89628.717 - ||grad||^2 = 0.07744 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 89628.717 - ||grad||^2 = 0.05521 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 89628.716 - ||grad||^2 = 0.03082 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 89628.716 - ||grad||^2 = 0.03110 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 89628.716 - ||grad||^2 = 0.04733 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 89628.717 - ||grad||^2 = 0.05081 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 89628.717 - ||grad||^2 = 0.05446 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 89628.716 - ||grad||^2 = 0.07206 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 89628.717 - ||grad||^2 = 0.06043 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 89628.716 - ||grad||^2 = 0.04009 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 89628.717 - ||grad||^2 = 0.02707 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 89628.716 - ||grad||^2 = 0.03892 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 89628.717 - ||grad||^2 = 0.04403 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 89628.716 - ||grad||^2 = 0.03933 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 89628.717 - ||grad||^2 = 0.04525 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 89628.716 - ||grad||^2 = 0.05021 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 89628.717 - ||grad||^2 = 0.04861 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 89628.716 - ||grad||^2 = 0.02750 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 89628.716 - ||grad||^2 = 0.03131 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 89628.716 - ||grad||^2 = 0.02608 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 89628.717 - ||grad||^2 = 0.02217 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 89628.717 - ||grad||^2 = 0.04602 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 89628.717 - ||grad||^2 = 0.07304 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 89628.716 - ||grad||^2 = 0.07109 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 89628.717 - ||grad||^2 = 0.05426 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 89628.716 - ||grad||^2 = 0.05273 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 89628.716 - ||grad||^2 = 0.03153 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 89628.717 - ||grad||^2 = 0.04076 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 89628.716 - ||grad||^2 = 0.04708 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 89628.716 - ||grad||^2 = 0.05133 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 89628.717 - ||grad||^2 = 0.05842 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 89628.716 - ||grad||^2 = 0.03887 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 89628.716 - ||grad||^2 = 0.04390 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 89628.717 - ||grad||^2 = 0.04785 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 89628.717 - ||grad||^2 = 0.05752 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 89628.716 - ||grad||^2 = 0.07067 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 89628.717 - ||grad||^2 = 0.05882 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 89628.716 - ||grad||^2 = 0.06033 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 89628.717 - ||grad||^2 = 0.05844 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 89628.716 - ||grad||^2 = 0.03518 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 89628.716 - ||grad||^2 = 0.03046 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 89628.717 - ||grad||^2 = 0.02982 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 89628.716 - ||grad||^2 = 0.03203 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 89628.717 - ||grad||^2 = 0.04344 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 89628.716 - ||grad||^2 = 0.04441 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 89628.716 - ||grad||^2 = 0.06122 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 89628.717 - ||grad||^2 = 0.07758 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 89628.717 - ||grad||^2 = 0.05555 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 89628.716 - ||grad||^2 = 0.03033 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 89628.716 - ||grad||^2 = 0.03095 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 89628.716 - ||grad||^2 = 0.04730 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662981600949,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"2651ba6d-8d54-45eb-9704-7b9b6ab1e95d","id":"Do23G4Qr23m4"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.832670\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"goOKvGwW23m4","executionInfo":{"status":"ok","timestamp":1662981600949,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-46616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662981600949,"user_tz":-540,"elapsed":5,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"6159088a-998f-47d4-9465-ed727c1c0013","id":"cI2vHNCk23m4"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-46616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]},{"cell_type":"markdown","source":["# orig+tgan-aug-51616"],"metadata":{"id":"DxK9eW0_29SW"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from pysurvival.models.svm import LinearSVMModel\n","from pysurvival.models.simulations import SimulationModel\n","from pysurvival.utils.metrics import concordance_index\n","from sklearn.model_selection import train_test_split\n","from scipy.stats.stats import pearsonr"],"metadata":{"id":"XlkqD8AW29SX","executionInfo":{"status":"ok","timestamp":1662981850468,"user_tz":-540,"elapsed":1460,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/result data/for-survival-analysis/Original+TGAN-aug/orig-TGANaug-51616.csv')\n","test_df = pd.read_csv('/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/data/8. test_data_73.csv')"],"metadata":{"id":"6cYnLbiR29SY","executionInfo":{"status":"ok","timestamp":1662981851299,"user_tz":-540,"elapsed":836,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#train smoker df one hot encoding\n","Smoker_df = train_df['Smoker']\n","\n","from sklearn.preprocessing import OneHotEncoder\n","Smoker_df= np.array(Smoker_df).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df)\n","ohe_encoded = ohe.transform(Smoker_df)\n","\n","smoker_df2= pd.DataFrame(ohe_encoded)\n","\n","new_train_df = pd.concat([train_df, smoker_df2], axis=1)\n","new_train_df=new_train_df.drop(['Smoker'], axis=1)\n","\n","new_train_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"Gz86Rzed29SY","executionInfo":{"status":"ok","timestamp":1662981851299,"user_tz":-540,"elapsed":13,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#test dataset one-hot-encoding\n","Smoker_df_test = test_df['Smoker']\n","\n","\n","Smoker_df_test= np.array(Smoker_df_test).reshape(-1, 1)\n","ohe = OneHotEncoder(sparse=False)\n","ohe.fit(Smoker_df_test)\n","ohe_encoded = ohe.transform(Smoker_df_test)\n","\n","new_smoker_df_test= pd.DataFrame(ohe_encoded)\n","\n","new_test_df = pd.concat([test_df, new_smoker_df_test], axis=1)\n","\n","new_test_df=new_test_df.drop(['Smoker'], axis=1)\n","\n","new_test_df.columns =['a_year_time','a_year_event','gender','age','HEIGHT','WEIGHT','PackYear','ECOG','FVC','FEV1','DLCO',\n","                       'DLCO_PERCENT','SCell','Aden','LCell','Positive_EGFR_Mutation','Positive_ALK_IHC','Positive_ALK_FISH',\n","                       'STAGE_simple','OP_Curative','RT','Chemo_curative','Chemo_Palliative','Smoker1', 'Smoker2', 'Smoker3']"],"metadata":{"id":"w_iwzcyX29SY","executionInfo":{"status":"ok","timestamp":1662981851299,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["data_train = new_train_df\n","data_test = new_test_df"],"metadata":{"id":"bF48dd8129SY","executionInfo":{"status":"ok","timestamp":1662981851300,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["sim = SimulationModel( survival_distribution = 'exponential',\n","                       risk_type = 'linear',\n","                       censored_parameter = 1,\n","                       alpha = 3)"],"metadata":{"id":"Yg0KBgA529SY","executionInfo":{"status":"ok","timestamp":1662981851300,"user_tz":-540,"elapsed":9,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["features = [f for f in data_train.columns if f not in ['a_year_time', 'a_year_event']]\n","\n","time_column = 'a_year_time'\n","event_column = 'a_year_event'"],"metadata":{"id":"_GhPa3d029SY","executionInfo":{"status":"ok","timestamp":1662981851300,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["X_train, X_test = data_train[features], data_test[features]\n","T_train, T_test = data_train['a_year_time'].values, data_test['a_year_time'].values\n","E_train, E_test = data_train['a_year_event'].values, data_test['a_year_event'].values"],"metadata":{"id":"7e87X2gh29SZ","executionInfo":{"status":"ok","timestamp":1662981851301,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","X_scaler = StandardScaler().fit(X_train)\n","X_train = X_scaler.transform(X_train)\n","X_test = X_scaler.transform(X_test)"],"metadata":{"id":"f6TkaHwz29SZ","executionInfo":{"status":"ok","timestamp":1662981851301,"user_tz":-540,"elapsed":8,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["svm_model = LinearSVMModel()\n","svm_model.fit(X_train, T_train, E_train, init_method='he_uniform',\n","    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8a6299da-9790-4691-b81a-d27fbbbf71bf","executionInfo":{"status":"ok","timestamp":1662985977628,"user_tz":-540,"elapsed":4126334,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"id":"rBzZ0S_G29SZ"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Performing Newton-Raphson optimization: \n"," * Iteration #1 - Loss = 10979665.926 - ||grad||^2 = 14575378.58158 - ||diff_w|| = 17.62634\n"," * Iteration #2 - Loss = 2815585.369 - ||grad||^2 = 7428780.43163 - ||diff_w|| = 7.90143\n"," * Iteration #3 - Loss = 896015.125 - ||grad||^2 = 4191577.48229 - ||diff_w|| = 4.26512\n"," * Iteration #4 - Loss = 311619.113 - ||grad||^2 = 2300436.78093 - ||diff_w|| = 2.09840\n"," * Iteration #5 - Loss = 147477.649 - ||grad||^2 = 1086431.11265 - ||diff_w|| = 0.78616\n"," * Iteration #6 - Loss = 113727.088 - ||grad||^2 = 509064.71934 - ||diff_w|| = 0.29305\n"," * Iteration #7 - Loss = 109546.777 - ||grad||^2 = 209133.68839 - ||diff_w|| = 0.11998\n"," * Iteration #8 - Loss = 109611.638 - ||grad||^2 = 76989.62238 - ||diff_w|| = 0.05204\n"," * Iteration #9 - Loss = 109703.213 - ||grad||^2 = 29764.21341 - ||diff_w|| = 0.02379\n"," * Iteration #10 - Loss = 109728.047 - ||grad||^2 = 12239.17638 - ||diff_w|| = 0.01164\n"," * Iteration #11 - Loss = 109734.555 - ||grad||^2 = 5321.25332 - ||diff_w|| = 0.00602\n"," * Iteration #12 - Loss = 109736.804 - ||grad||^2 = 2428.32277 - ||diff_w|| = 0.00323\n"," * Iteration #13 - Loss = 109737.283 - ||grad||^2 = 1158.18657 - ||diff_w|| = 0.00174\n"," * Iteration #14 - Loss = 109737.557 - ||grad||^2 = 571.20711 - ||diff_w|| = 0.00094\n"," * Iteration #15 - Loss = 109737.562 - ||grad||^2 = 287.94163 - ||diff_w|| = 0.00051\n"," * Iteration #16 - Loss = 109737.597 - ||grad||^2 = 148.76907 - ||diff_w|| = 0.00028\n"," * Iteration #17 - Loss = 109737.625 - ||grad||^2 = 78.24838 - ||diff_w|| = 0.00015\n"," * Iteration #18 - Loss = 109737.624 - ||grad||^2 = 41.34991 - ||diff_w|| = 0.00008\n"," * Iteration #19 - Loss = 109737.626 - ||grad||^2 = 22.12164 - ||diff_w|| = 0.00005\n"," * Iteration #20 - Loss = 109737.630 - ||grad||^2 = 11.81956 - ||diff_w|| = 0.00002\n"," * Iteration #21 - Loss = 109737.625 - ||grad||^2 = 6.33924 - ||diff_w|| = 0.00001\n"," * Iteration #22 - Loss = 109737.626 - ||grad||^2 = 3.45426 - ||diff_w|| = 0.00001\n"," * Iteration #23 - Loss = 109737.626 - ||grad||^2 = 1.86732 - ||diff_w|| = 0.00000\n"," * Iteration #24 - Loss = 109737.627 - ||grad||^2 = 1.00081 - ||diff_w|| = 0.00000\n"," * Iteration #25 - Loss = 109737.626 - ||grad||^2 = 0.53664 - ||diff_w|| = 0.00000\n"," * Iteration #26 - Loss = 109737.628 - ||grad||^2 = 0.31080 - ||diff_w|| = 0.00000\n"," * Iteration #27 - Loss = 109737.626 - ||grad||^2 = 0.16849 - ||diff_w|| = 0.00000\n"," * Iteration #28 - Loss = 109737.627 - ||grad||^2 = 0.10109 - ||diff_w|| = 0.00000\n"," * Iteration #29 - Loss = 109737.626 - ||grad||^2 = 0.04860 - ||diff_w|| = 0.00000\n"," * Iteration #30 - Loss = 109737.627 - ||grad||^2 = 0.04404 - ||diff_w|| = 0.00000\n"," * Iteration #31 - Loss = 109737.627 - ||grad||^2 = 0.02280 - ||diff_w|| = 0.00000\n"," * Iteration #32 - Loss = 109737.627 - ||grad||^2 = 0.03724 - ||diff_w|| = 0.00000\n"," * Iteration #33 - Loss = 109737.627 - ||grad||^2 = 0.02676 - ||diff_w|| = 0.00000\n"," * Iteration #34 - Loss = 109737.627 - ||grad||^2 = 0.03394 - ||diff_w|| = 0.00000\n"," * Iteration #35 - Loss = 109737.626 - ||grad||^2 = 0.04182 - ||diff_w|| = 0.00000\n"," * Iteration #36 - Loss = 109737.627 - ||grad||^2 = 0.03634 - ||diff_w|| = 0.00000\n"," * Iteration #37 - Loss = 109737.626 - ||grad||^2 = 0.04732 - ||diff_w|| = 0.00000\n"," * Iteration #38 - Loss = 109737.628 - ||grad||^2 = 0.06385 - ||diff_w|| = 0.00000\n"," * Iteration #39 - Loss = 109737.626 - ||grad||^2 = 0.04993 - ||diff_w|| = 0.00000\n"," * Iteration #40 - Loss = 109737.627 - ||grad||^2 = 0.03617 - ||diff_w|| = 0.00000\n"," * Iteration #41 - Loss = 109737.626 - ||grad||^2 = 0.04038 - ||diff_w|| = 0.00000\n"," * Iteration #42 - Loss = 109737.627 - ||grad||^2 = 0.03735 - ||diff_w|| = 0.00000\n"," * Iteration #43 - Loss = 109737.626 - ||grad||^2 = 0.04659 - ||diff_w|| = 0.00000\n"," * Iteration #44 - Loss = 109737.628 - ||grad||^2 = 0.06412 - ||diff_w|| = 0.00000\n"," * Iteration #45 - Loss = 109737.626 - ||grad||^2 = 0.04984 - ||diff_w|| = 0.00000\n"," * Iteration #46 - Loss = 109737.627 - ||grad||^2 = 0.03624 - ||diff_w|| = 0.00000\n"," * Iteration #47 - Loss = 109737.626 - ||grad||^2 = 0.04035 - ||diff_w|| = 0.00000\n"," * Iteration #48 - Loss = 109737.627 - ||grad||^2 = 0.03738 - ||diff_w|| = 0.00000\n"," * Iteration #49 - Loss = 109737.626 - ||grad||^2 = 0.04657 - ||diff_w|| = 0.00000\n"," * Iteration #50 - Loss = 109737.628 - ||grad||^2 = 0.06413 - ||diff_w|| = 0.00000\n"," * Iteration #51 - Loss = 109737.626 - ||grad||^2 = 0.04983 - ||diff_w|| = 0.00000\n"," * Iteration #52 - Loss = 109737.627 - ||grad||^2 = 0.03625 - ||diff_w|| = 0.00000\n"," * Iteration #53 - Loss = 109737.626 - ||grad||^2 = 0.04035 - ||diff_w|| = 0.00000\n"," * Iteration #54 - Loss = 109737.627 - ||grad||^2 = 0.03738 - ||diff_w|| = 0.00000\n"," * Iteration #55 - Loss = 109737.626 - ||grad||^2 = 0.04657 - ||diff_w|| = 0.00000\n"," * Iteration #56 - Loss = 109737.628 - ||grad||^2 = 0.06413 - ||diff_w|| = 0.00000\n"," * Iteration #57 - Loss = 109737.626 - ||grad||^2 = 0.04983 - ||diff_w|| = 0.00000\n"," * Iteration #58 - Loss = 109737.627 - ||grad||^2 = 0.03625 - ||diff_w|| = 0.00000\n"," * Iteration #59 - Loss = 109737.626 - ||grad||^2 = 0.04035 - ||diff_w|| = 0.00000\n"," * Iteration #60 - Loss = 109737.627 - ||grad||^2 = 0.03738 - ||diff_w|| = 0.00000\n"," * Iteration #61 - Loss = 109737.626 - ||grad||^2 = 0.04657 - ||diff_w|| = 0.00000\n"," * Iteration #62 - Loss = 109737.628 - ||grad||^2 = 0.06413 - ||diff_w|| = 0.00000\n"," * Iteration #63 - Loss = 109737.626 - ||grad||^2 = 0.04983 - ||diff_w|| = 0.00000\n"," * Iteration #64 - Loss = 109737.627 - ||grad||^2 = 0.03625 - ||diff_w|| = 0.00000\n"," * Iteration #65 - Loss = 109737.626 - ||grad||^2 = 0.04035 - ||diff_w|| = 0.00000\n"," * Iteration #66 - Loss = 109737.627 - ||grad||^2 = 0.03738 - ||diff_w|| = 0.00000\n"," * Iteration #67 - Loss = 109737.626 - ||grad||^2 = 0.04657 - ||diff_w|| = 0.00000\n"," * Iteration #68 - Loss = 109737.628 - ||grad||^2 = 0.06413 - ||diff_w|| = 0.00000\n"," * Iteration #69 - Loss = 109737.626 - ||grad||^2 = 0.04983 - ||diff_w|| = 0.00000\n"," * Iteration #70 - Loss = 109737.627 - ||grad||^2 = 0.03625 - ||diff_w|| = 0.00000\n"," * Iteration #71 - Loss = 109737.626 - ||grad||^2 = 0.04035 - ||diff_w|| = 0.00000\n"," * Iteration #72 - Loss = 109737.627 - ||grad||^2 = 0.03738 - ||diff_w|| = 0.00000\n"," * Iteration #73 - Loss = 109737.626 - ||grad||^2 = 0.04657 - ||diff_w|| = 0.00000\n"," * Iteration #74 - Loss = 109737.628 - ||grad||^2 = 0.06413 - ||diff_w|| = 0.00000\n"," * Iteration #75 - Loss = 109737.626 - ||grad||^2 = 0.04983 - ||diff_w|| = 0.00000\n"," * Iteration #76 - Loss = 109737.627 - ||grad||^2 = 0.03625 - ||diff_w|| = 0.00000\n"," * Iteration #77 - Loss = 109737.626 - ||grad||^2 = 0.04035 - ||diff_w|| = 0.00000\n"," * Iteration #78 - Loss = 109737.627 - ||grad||^2 = 0.03738 - ||diff_w|| = 0.00000\n"," * Iteration #79 - Loss = 109737.626 - ||grad||^2 = 0.04657 - ||diff_w|| = 0.00000\n"," * Iteration #80 - Loss = 109737.628 - ||grad||^2 = 0.06413 - ||diff_w|| = 0.00000\n"," * Iteration #81 - Loss = 109737.626 - ||grad||^2 = 0.04983 - ||diff_w|| = 0.00000\n"," * Iteration #82 - Loss = 109737.627 - ||grad||^2 = 0.03625 - ||diff_w|| = 0.00000\n"," * Iteration #83 - Loss = 109737.626 - ||grad||^2 = 0.04035 - ||diff_w|| = 0.00000\n"," * Iteration #84 - Loss = 109737.627 - ||grad||^2 = 0.03738 - ||diff_w|| = 0.00000\n"," * Iteration #85 - Loss = 109737.626 - ||grad||^2 = 0.04657 - ||diff_w|| = 0.00000\n"," * Iteration #86 - Loss = 109737.628 - ||grad||^2 = 0.06413 - ||diff_w|| = 0.00000\n"," * Iteration #87 - Loss = 109737.626 - ||grad||^2 = 0.04983 - ||diff_w|| = 0.00000\n"," * Iteration #88 - Loss = 109737.627 - ||grad||^2 = 0.03625 - ||diff_w|| = 0.00000\n"," * Iteration #89 - Loss = 109737.626 - ||grad||^2 = 0.04035 - ||diff_w|| = 0.00000\n"," * Iteration #90 - Loss = 109737.627 - ||grad||^2 = 0.03738 - ||diff_w|| = 0.00000\n"," * Iteration #91 - Loss = 109737.626 - ||grad||^2 = 0.04657 - ||diff_w|| = 0.00000\n"," * Iteration #92 - Loss = 109737.628 - ||grad||^2 = 0.06413 - ||diff_w|| = 0.00000\n"," * Iteration #93 - Loss = 109737.626 - ||grad||^2 = 0.04983 - ||diff_w|| = 0.00000\n"," * Iteration #94 - Loss = 109737.627 - ||grad||^2 = 0.03625 - ||diff_w|| = 0.00000\n"," * Iteration #95 - Loss = 109737.626 - ||grad||^2 = 0.04035 - ||diff_w|| = 0.00000\n"," * Iteration #96 - Loss = 109737.627 - ||grad||^2 = 0.03738 - ||diff_w|| = 0.00000\n"," * Iteration #97 - Loss = 109737.626 - ||grad||^2 = 0.04657 - ||diff_w|| = 0.00000\n"," * Iteration #98 - Loss = 109737.628 - ||grad||^2 = 0.06413 - ||diff_w|| = 0.00000\n"," * Iteration #99 - Loss = 109737.626 - ||grad||^2 = 0.04983 - ||diff_w|| = 0.00000\n"," * Iteration #100 - Loss = 109737.627 - ||grad||^2 = 0.03625 - ||diff_w|| = 0.00000\n","Optimization reached max number of iterations.\n"]},{"output_type":"execute_result","data":{"text/plain":["LinearSVMModel"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["c_index = concordance_index(svm_model, X_test, T_test, E_test) #0.93\n","print('C-index: {:f}'.format(c_index))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662985977938,"user_tz":-540,"elapsed":12,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"71372b2d-f6d0-4b42-9ac4-600e78141225","id":"fCQHqSvU29SZ"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["C-index: 0.831115\n"]}]},{"cell_type":"code","source":["from pysurvival.utils import save_model"],"metadata":{"id":"8e00TNAH29SZ","executionInfo":{"status":"ok","timestamp":1662985977939,"user_tz":-540,"elapsed":6,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["save_model(svm_model,'/content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-51616.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662985977939,"user_tz":-540,"elapsed":4,"user":{"displayName":"Hayejin Kang","userId":"13638321481328458267"}},"outputId":"a681fbe1-7c15-4d79-8507-4fc429846b4b","id":"2VOHPTOm29SZ"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Saving the model to disk as /content/drive/MyDrive/PAPER/진행연구/tabular deep learning/폐암병기/modeling/SSVM/SSVM_new(onehot)_tgan-org+imbalnonar-51616.zip\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pysurvival/utils/__init__.py:132: FutureWarning: 'pyarrow.serialize' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n","  model.save(path_file)\n"]}]}]}